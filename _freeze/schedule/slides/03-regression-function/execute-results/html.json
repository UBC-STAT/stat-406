{
  "hash": "d41b6f2c5e0e8102f579823e6981f723",
  "result": {
    "markdown": "---\nlecture: \"03 The regression function\"\nformat: revealjs\nmetadata-files: \n  - _metadata.yml\n---\n---\n---\n\n## {{< meta lecture >}} {.large background-image=\"gfx/smooths.svg\" background-opacity=\"0.3\"}\n\n[Stat 406]{.secondary}\n\n[{{< meta author >}}]{.secondary}\n\nLast modified -- 30 August 2023\n\n\n\n$$\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\find}{find}\n\\DeclareMathOperator{\\st}{subject\\,\\,to}\n\\newcommand{\\E}{E}\n\\newcommand{\\Expect}[1]{\\E\\left[ #1 \\right]}\n\\newcommand{\\Var}[1]{\\mathrm{Var}\\left[ #1 \\right]}\n\\newcommand{\\Cov}[2]{\\mathrm{Cov}\\left[#1,\\ #2\\right]}\n\\newcommand{\\given}{\\ \\vert\\ }\n\\newcommand{\\X}{\\mathbf{X}}\n\\newcommand{\\x}{\\mathbf{x}}\n\\newcommand{\\y}{\\mathbf{y}}\n\\newcommand{\\P}{\\mathcal{P}}\n\\newcommand{\\R}{\\mathbb{R}}\n$$\n\n\n\n\n\n## Mean squared error (MSE)\n\nLast time... .secondary[Ordinary Least Squares]\n\n$$\\widehat\\beta = \\argmin_\\beta \\sum_{i=1}^n ( y_i - x_i^\\top \\beta )^2.$$\n\n\n\"Find the $\\beta$ which minimizes the sum of squared errors.\"\n\n$$\\widehat\\beta = \\arg\\min_\\beta \\frac{1}{n}\\sum_{i=1}^n ( y_i - x_i^\\top \\beta )^2.$$\n\n\"Find the beta which minimizes the mean squared error.\"\n\n\n## Forget all that...\n\nThat's \"stuff that seems like a good idea\"\n\nAnd it is for many reasons\n\nThis class is about those reasons, and the \"statistics\" behind it\n\n<br><br>\n\n#### Methods for \"Statistical\" Learning\n\n\nStarts with \"what is a model?\"\n\n## What is a model?\n\nIn statistics, \"model\" has a mathematical meaning.\n\nDistinct from \"algorithm\" or \"procedure\".\n\nDefining a model often leads to a procedure/algorithm with good properties.\n\nSometimes procedure/algorithm $\\Rightarrow$ a specific model.\n\n> Statistics (the field) tells me how to understand when different procedures\n> are desirable. \n\nWhen are certain models appropriate?\n\n> One definition of \"Statistical Learning\" is the \"statistics behind the procedure\".\n\n## Statistical models 101\n\nWe observe data $Z_1,\\ Z_2,\\ \\ldots,\\ Z_n$ generated by some probability\ndistribution $P$. We want to use the data to learn about $P$. \n\n> A [statistical model]{.secondary} is a set of distributions $\\mathcal{P}$.\n\n\nSome examples:\n\n  1. $\\P = \\{ 0 < p < 1 : P(z=1)=p,\\ P(z=0)=1-p\\}$.\n  2. $\\P = \\{ \\beta \\in \\R^p, \\sigma>0 : Y \\sim N(X^\\top\\beta,\\sigma^2),\\  X\\mbox{ fixed}\\}$.\n  2. $\\P = \\{\\mbox{all CDF's }F\\}$.\n  3. $\\P = \\{\\mbox{all smooth functions } f\\mapsto \\R^p \\rightarrow \\R : Z_i = (X_i, Y_i),\\ Y_i = f(X_i) + \\epsilon_i \\}$\n  \n## Statistical models \n\nWe want to use the data to learn about $P$. \n\n$$\n\\P = \\{ P(z=1)=p,\\ P(z=0)=1-p,\\ 0 < p < 1 \\}\n$$\n  \n* To completely characterize $P$, I just need to estimate $p$.\n\n* Need to assume that $P \\in \\P$. \n\n* This assumption is mostly empty: __need independent, can't see $z=12$.__\n\n## Statistical models \n\nWe observe data $Z_i=(Y_i,X_i)$ generated by some probability\ndistribution $P$. We want to use the data to learn about $P$. \n\n$$\n\\P = \\{ \\beta \\in \\R^p, \\sigma>0 : Y \\sim N(X^\\top\\beta,\\ \\sigma^2),\\  X\\mbox{ fixed} \\}.\n$$\n\n  \n* To completely characterize $P$, I just need to estimate $\\beta$ and $\\sigma$.\n\n* Need to assume that $P\\in\\P$.\n\n* This time, I have to assume a lot more: \n_Linearity, independence, Gaussian noise, no ignored variables, no collinearity, etc._\n\n\n## \n\nLet's look at the population version, and let's forget about the linear model.\n\n\nSuppose we think that there is __some__ function which relates $y$ and $x$.\n\nLet's call this function $f$ for the moment.\n\nHow do we estimate $f$? What is $f$?\n\n\n\n\n\n\n## Minimizing MSE\n\nLet's try to minimize the __expected__ squared error (MSE).\n\n\nClaim: $\\mu(X) = \\Expect{Y\\ \\vert\\ X}$ minimizes MSE. \nThat is, for any $r(X)$, $\\Expect{(Y - \\mu(X))^2} \\leq \\Expect{(Y-r(X))^2}$.\n\n\n\n. . .\n\nProof of Claim:\n\n\n\\begin{aligned}\n\\Expect{(Y-r(X))^2} \n&= \\Expect{(Y- \\mu(X) + \\mu(X) - r(X))^2}\\\\\n&= \\Expect{(Y- \\mu(X))^2} + \\Expect{(\\mu(X) - r(X))^2} + \n2\\Expect{(Y- \\mu(X))(\\mu(X) - r(X))}\\\\\n&=\\Expect{(Y- \\mu(X))^2} + \\Expect{(\\mu(X) - r(X))^2} + \n2(\\mu(X) - r(X))\\Expect{(Y- \\mu(X))}\\\\\n&=\\Expect{(Y- \\mu(X))^2} + \\Expect{(\\mu(X) - r(X))^2} + 0\\\\\n&\\geq \\Expect{(Y- \\mu(X))^2}\n\\end{aligned}\n\n\n\n\n## The regression function\n\nWe call this solution:\n\n\n$$\\mu(X) = \\Expect{Y \\ \\vert\\  X}$$\n\n\nthe regression function.\n\nIf we __assume__ that $\\mu(x) = \\Expect{Y \\ \\vert\\  X=x} = x^\\top \\beta$, then we get back exactly OLS.\n\n. . .\n\nBut why should we assume $\\mu(x) = x^\\top \\beta$?\n\n\n\n## The regression function\n\n\nIn mathematics: $\\mu(x) = \\Expect{Y \\ \\vert\\  X=x}$.\n\nIn words: \n\n{Regression is really about estimating the mean.}[.secondary]\n\n1. If $Y\\sim \\textrm{N}(\\mu,\\ 1)$, our best guess for a __new__ $Y$ is $\\mu$.  \n\n2. For regression, we let the mean $(\\mu)$ __depend__ on $X$.  \n3. Think of $Y\\sim \\textrm{N}(\\mu(X),\\ 1)$, then conditional on $X=x$, our best guess for a __new__ $Y$ is $\\mu(x)$ \n\n[whatever this function $\\mu$ is]\n\n\n## Anything strange?\n\nFor any two variables $Y$ and $X$, we can __always__ write\n\n$$Y \\ \\vert\\  X = \\mu(X) + \\eta(X)$$\n\nsuch that $\\Expect{\\eta(X)}=0$.\n\n. . .\n\n* Suppose, $\\mu(X)=\\mu_0$ (constant in $X$), are $Y$ and $X$ independent?\n\n. . .\n\n* Suppose $Y$ and $X$ are independent, is $\\mu(X)=\\mu_0$?\n\n. . .\n\n* For more practice on this see the \"Fun Worksheet on Theory\" in Module 1 on Canvas.\n\n* In this course, I do not expect you to be able to create this math, but understanding and explaining it .secondary.hand[is] important.\n\n\n# Making predictions\n\n\n\n## What do we mean by good predictions?\n\n\nWe make observations and then attempt to \"predict\" new, unobserved data.\n\nSometimes this is the same as estimating the mean. \n  \nMostly, we observe $(y_1,x_1),\\ldots,(y_n,x_n)$, and we want some way to predict $Y$ from $X$.\n\n\n## Evaluating predictions\n\n\nOf course, both $Y$ and $\\widehat{Y}$ are __random__\n\nI want to know how well I can predict __on average__\n\nLet $\\widehat{f}$ be some way of making predictions $\\widehat{Y}$ of $Y$ using covariates $X$\n\nIn fact, suppose I observe a dataset $\\{(y_1,x_1,),\\ldots,(y_n,x_n)\\}$.  \n\nThen I want to __choose__ some $\\widehat{f}$ using the data\n\nIs $\\widehat{f}$ good on average?\n  \n  \n\n\n## Evaluating predictions\n\n  \nChoose some __loss function__ that measures prediction quality.\n\nWe predict $y$ with $\\widehat{y}$\n\n. . .\n\nExamples:\n\n* __Squared-error:__   \n$\\ell(y,\\widehat{y}) = (y-\\widehat{y})^2$\n\n* __Absolute-error:__  \n$\\ell(y,\\widehat{y}) = |y-\\widehat{y}|$\n\n* __Zero-One:__         \n$\\ell(y,\\widehat{y}) = I(y\\neq\\widehat{y})=\\begin{cases} 0 & y=\\widehat{y}\\\\1 & \\mbox{else}\\end{cases}$\n\n  \nCan be generalized to $y$ in arbitrary spaces.\n\n\n\n## Expected test MSE \n\n\nFor __regression__ applications, we will use squared-error loss:\n\n$R_n(\\widehat{f}) = \\Expect{(Y-\\widehat{f}(X))^2}$\n\n. . .\n\nI'm giving this a name, $R_n$ for ease. \n\nDifferent than text.\n\nThis is __expected test MSE__.\n\n\n\n## Example: Estimating the mean\n\n\nSuppose we know that we want to predict a quantity $Y$, \n\nwhere $\\Expect{Y}= \\mu \\in \\mathbb{R}$ and $\\Var{Y} = 1$.  \n\n\nOur data is $\\{y_1,\\ldots,y_n\\}$\n\nWe want to estimate $\\mu$ \n\n\n## Estimating the mean\n\n* Let $\\widehat{Y}=\\overline{Y}_n$ be the sample mean.  \n* We can ask about the __estimation risk__ (since we're estimating $\\mu$):\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n  \n\\begin{aligned}\n    R_n(\\overline{Y}_n; \\mu) \n    &= \\E[(\\overline{Y}_n-\\mu)^2] \\\\ \n    &= \\E[\\overline{Y}_n^2]\n    -2\\mu\\E[\\overline{Y}_n] + \\mu^2 \\\\ \n    &= \\mu^2 + \\frac{1}{n} - 2\\mu^2 +\n    \\mu^2\\\\ &= \\frac{1}{n}\n\\end{aligned}\n\n:::\n\n::: {.column width=\"50%\"}\n\n**Useful trick**\n\nFor any $Z$,\n\n$\\Var{Z} = \\Expect{Z^2} - \\Expect{Z}^2$.\n\nTherefore:\n\n$\\Expect{Z^2} = \\Var{Z} + \\Expect{Z}^2$.\n\n:::\n::::\n  \n\n\n## Predicting new Y's\n\n* Let $\\widehat{Y}=\\overline{Y}_n$ be the sample mean.\n* What is the __prediction risk__ of $\\overline{Y}$?\n\n\n\\begin{aligned}\n  R_n(\\overline{Y}_n) \n  &= \\E[(\\overline{Y}_n-Y)^2]\\\\ \n  &= \\E[\\overline{Y}_n^2] -2\\E[\\overline{Y}_n Y] + \\E[Y^2] \\\\ \n  &= \\mu^2 + \\frac{1}{n} - 2\\mu^2 + \\mu^2 + 1 \\\\ \n  &= 1 + \\frac{1}{n} \n\\end{aligned}\n\n##\n\n**Tricks:**\n\nUsed the variance thing again.\n\nIf $X$ and $Z$ are independent, then $\\Expect{XZ} = \\Expect{X}\\Expect{Z}$\n\n\n\n## Predicting new Y's\n\n  \n* What is the prediction risk of guessing $Y=0$?\n\n* You can probably guess that this is a stupid idea.\n\n* Let's show why it's stupid.\n\n\\begin{aligned}\n        R_n(0) &= \\E[(0-Y)^2] = 1 + \\mu^2\n\\end{aligned}\n\n\n\n## Predicting new Y's\n\n\nWhat is the prediction risk of guessing $Y=\\mu$?\n\n\nThis is a great idea, but we don't know $\\mu$.\n\nLet's see what happens anyway.\n\n\\begin{aligned}\n        R_n(\\mu) &= \\E[(Y-\\mu)^2]= 1\n\\end{aligned}\n\n\n\n## Estimating the mean\n\n  \nPrediction risk: $R_n(\\overline{Y}_n) = 1 + \\frac{1}{n}$    \n\nEstimation risk: $R_n(\\overline{Y}_n;\\mu) =  \\frac{1}{n}$  \n\nThere is actually a nice interpretation here:\n\n1. The common $1/n$ term is $\\Var{\\overline{Y}_n}$  \n2. The extra factor of $1$ in the prediction risk is __irreducible error__ \n\n    * $Y$ is a random variable, and hence noisy. \n    * We can never eliminate it's intrinsic variance.  \n    * In other words, even if we knew $\\mu$, we could never get closer than $1$, on average.\n\nIntuitively, $\\overline{Y}_n$ is the obvious thing to do.\n \nBut what about unintuitive things...\n\n\n# Next time...\n\nTrading bias and variance",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}