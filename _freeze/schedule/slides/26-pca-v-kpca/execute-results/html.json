{
  "hash": "3c6efa61621262936459bca104128e54",
  "result": {
    "markdown": "---\nlecture: \"26 PCA v KPCA\"\nformat: revealjs\nmetadata-files: \n  - _metadata.yml\n---\n---\n---\n\n## {{< meta lecture >}} {.large background-image=\"gfx/smooths.svg\" background-opacity=\"0.3\"}\n\n[Stat 406]{.secondary}\n\n[{{< meta author >}}]{.secondary}\n\nLast modified -- 24 November 2023\n\n\n\n$$\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\find}{find}\n\\DeclareMathOperator{\\st}{subject\\,\\,to}\n\\newcommand{\\E}{E}\n\\newcommand{\\Expect}[1]{\\E\\left[ #1 \\right]}\n\\newcommand{\\Var}[1]{\\mathrm{Var}\\left[ #1 \\right]}\n\\newcommand{\\Cov}[2]{\\mathrm{Cov}\\left[#1,\\ #2\\right]}\n\\newcommand{\\given}{\\ \\vert\\ }\n\\newcommand{\\X}{\\mathbf{X}}\n\\newcommand{\\x}{\\mathbf{x}}\n\\newcommand{\\y}{\\mathbf{y}}\n\\newcommand{\\P}{\\mathcal{P}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\n\\newcommand{\\snorm}[1]{\\lVert #1 \\rVert}\n\\newcommand{\\tr}[1]{\\mbox{tr}(#1)}\n\\newcommand{\\brt}{\\widehat{\\beta}^R_{s}}\n\\newcommand{\\brl}{\\widehat{\\beta}^R_{\\lambda}}\n\\newcommand{\\bls}{\\widehat{\\beta}_{ols}}\n\\newcommand{\\blt}{\\widehat{\\beta}^L_{s}}\n\\newcommand{\\bll}{\\widehat{\\beta}^L_{\\lambda}}\n\\newcommand{\\U}{\\mathbf{U}}\n\\newcommand{\\D}{\\mathbf{D}}\n\\newcommand{\\V}{\\mathbf{V}}\n$$\n\n\n\n\n## PCA v KPCA \n\n(We assume $\\X$ is already centered/scaled, $n$ rows, $p$ columns)\n\n::: flex\n::: w-50\n\n[PCA:]{.secondary}\n\n1. Decompose $\\X=\\U\\D\\V^\\top$ (SVD). \n2. Embed into $M\\leq p$ dimensions: \n$$\\U_M \\D_M = \\X\\V_M$$\n\nThe \"embedding\" is $\\U_M \\D_M$.\n\n(called the \"Principal Components\" or the \"scores\" or occasionally the \"factors\")\n\nThe \"loadings\" or \"weights\" are $\\V_M$\n:::\n\n::: w-50\n\n[KPCA:]{.secondary}\n\n1. Choose $k(x_i, x_{i'})$. Create $\\mathbf{K}$.\n1. Double center $\\mathbf{K} = \\mathbf{PKP}$.\n1. Decompose $\\mathbf{K} = \\U \\D^2 \\U^\\top$ (eigendecomposition).\n1. Embed into $M\\leq p$ dimensions:\n$$\\U_M \\D_M$$\n\nThe \"embedding\" is $\\U_M \\D_M$.\n\nThere are no \"loadings\"  \n($\\not\\exists\\ \\mathbf{B}$ such that $\\X\\mathbf{B} = \\U_M \\D_M$)\n\n:::\n:::\n\n\n## Why is this the solution?\n\nThe \"maximize variance\" version of PCA:\n\n$$\\max_\\alpha \\Var{\\X\\alpha} \\quad \\textrm{ subject to } \\quad \\left|\\left| \\alpha \\right|\\right|_2^2 = 1$$\n\n( $\\Var{\\X\\alpha} = \\alpha^\\top\\X^\\top\\X\\alpha$ )\n\nThis is equivalent to solving (Lagrangian):\n\n$$\\max_\\alpha \\alpha^\\top\\X^\\top\\X\\alpha - \\lambda\\left|\\left| \\alpha \\right|\\right|_2^2$$\n\nTake derivative wrt $\\alpha$ and set to 0:\n\n$$0 = 2\\X^\\top\\X\\alpha - 2\\lambda\\alpha$$\n\nThis is the equation for an eigenproblem. The solution is $\\alpha=\\V_1$ and the maximum is $\\D_1^2$.\n\n\n## Example (not real unless there's code)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nX <- Stat406::mobility |>\n  select(Black:Married) |>\n  as.matrix()\nnot_missing <- complete.cases(X)\nX <- scale(X[not_missing, ], center = TRUE, scale = TRUE)\ncolors <- Stat406::mobility$Mobility[not_missing]\nM <- 2 # embedding dimension\nP <- diag(nrow(X)) - 1 / nrow(X)\n```\n:::\n\n\n\n::: flex\n::: w-50\n\n[PCA:]{.secondary} (all 3 are equivalent)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ns <- svd(X) # use svd\npca_loadings <- s$v[, 1:M]\npca_scores <- X %*% pca_loadings\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ns <- eigen(t(X) %*% X) # V D^2 V'\npca_loadings <- s$vectors[, 1:M]\npca_scores <- X %*% pca_loadings\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ns <- eigen(X %*% t(X)) # U D^2 U'\nD <- sqrt(diag(s$values[1:M]))\nU <- s$vectors[, 1:M]\npca_scores <- U %*% D\npca_loadings <- (1 / D) %*% t(U) %*% X\n```\n:::\n\n\n:::\n\n::: w-50\n[KPCA:]{.secondary}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- 2\nK <- P %*% (1 + X %*% t(X))^d %*% P # polynomial\ne <- eigen(K) # U D^2 U'\n# (different from the PCA one, K /= XX')\nU <- e$vectors[, 1:M]\nD <- diag(sqrt(e$values[1:M]))\nkpca_poly <- U %*% D\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nK <- P %*% tanh(1 + X %*% t(X)) %*% P # sigmoid kernel\ne <- eigen(K) # U D^2 U'\n# (different from the PCA one, K /= XX')\nU <- e$vectors[, 1:M]\nD <- diag(sqrt(e$values[1:M]))\nkpca_sigmoid <- U %*% D\n```\n:::\n\n\n:::\n:::\n\n## Plotting\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](26-pca-v-kpca_files/figure-revealjs/unnamed-chunk-7-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## PCA loadings\n\nShowing the first 10 PCA loadings:\n\n* First column are the weights on the first score\n* each number corresponds to a variable in the original data\n* How much does that variable contribute to that score?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(round(pca_loadings, 2), 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       [,1]  [,2]\n [1,]  0.25  0.07\n [2,]  0.13 -0.14\n [3,]  0.17 -0.34\n [4,]  0.18 -0.33\n [5,]  0.16 -0.34\n [6,] -0.24  0.11\n [7,] -0.04 -0.35\n [8,]  0.28  0.00\n [9,]  0.13 -0.14\n[10,]  0.29  0.10\n```\n:::\n:::\n\n\n\n## KPCA, feature map version\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np <- ncol(X)\nwidth <- p * (p - 1) / 2 + p # = 630\nZ <- matrix(NA, nrow(X), width)\nk <- 0\nfor (i in 1:p) {\n  for (j in i:p) {\n    k <- k + 1\n    Z[, k] <- X[, i] * X[, j]\n  }\n}\nwideX <- scale(cbind(X, Z))\ns <- RSpectra::svds(wideX, 2) # the whole svd would be super slow\nfkpca_scores <- s$u %*% diag(s$d)\n```\n:::\n\n\n* Unfortunately, can't easily compare to check whether the result is the same\n* Also can cause numerical issues\n* But should be the \"same\" (assuming I didn't screw up...)\n* Would also allow me to get the loadings, though they'd depend on polynomials\n\n## Other manifold learning methods\n\nTo name a few\n\n* Hessian maps\n* Laplacian eigenmaps\n* Classical Multidimensional Scaling\n* tSNE\n* UMAP\n* Locally linear embeddings\n* Diffusion maps\n* Local tangent space alignment\n* Isomap\n\n## Issues with nonlinear techniques\n\n::: flex\n\n::: w-40\n\n1. Need to choose $M$ (also with linear)\n2. Also other tuning parameters.\n3. These others can have __huge__ effects\n4. The difference between the data lying [on]{.hand} the manifold and the \ndata lying [near]{.hand} the manifold is important\n\n:::\n\n::: w-60\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nelephant <- function(eye = TRUE) {\n  tib <- tibble(\n    tt = -100:500 / 100,\n    y = -(12 * cos(3 * tt) - 14 * cos(5 * tt) + 50 * sin(tt) + 18 * sin(2 * tt)),\n    x = -30 * sin(tt) + 8 * sin(2 * tt) - 10 * sin(3 * tt) - 60 * cos(tt)\n  )\n  if (eye) tib <- add_row(tib, y = 20, x = 20)\n  tib\n}\nele <- elephant(FALSE)\nnoisy_ele <- ele |>\n  mutate(y = y + rnorm(n(), 0, 5), x = x + rnorm(n(), 0, 5))\nggplot(noisy_ele, aes(x, y, colour = tt)) +\n  geom_point() +\n  scale_color_viridis_c() +\n  theme(legend.position = \"none\") +\n  geom_path(data = ele, colour = \"black\", linewidth = 2)\n```\n\n::: {.cell-output-display}\n![](26-pca-v-kpca_files/figure-revealjs/unnamed-chunk-10-1.svg){fig-align='center'}\n:::\n:::\n\n\n:::\n:::\n\n# Next time...\n\nClustering\n",
    "supporting": [
      "26-pca-v-kpca_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}