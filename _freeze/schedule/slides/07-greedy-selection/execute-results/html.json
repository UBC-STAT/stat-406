{
  "hash": "901c042175f5946b5d30295db3fb59d9",
  "result": {
    "engine": "knitr",
    "markdown": "---\nlecture: \"07 practical model/variable selection\"\nformat: revealjs\nmetadata-files: \n  - _metadata.yml\n---\n\n\n## {{< meta lecture >}} {.large background-image=\"gfx/smooths.svg\" background-opacity=\"0.3\"}\n\n[Stat 406]{.secondary}\n\n[{{< meta author >}}]{.secondary}\n\nLast modified -- 25 September 2024\n\n\n\n\n\n$$\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\find}{find}\n\\DeclareMathOperator{\\st}{subject\\,\\,to}\n\\newcommand{\\E}{E}\n\\newcommand{\\Expect}[1]{\\E\\left[ #1 \\right]}\n\\newcommand{\\Var}[1]{\\mathrm{Var}\\left[ #1 \\right]}\n\\newcommand{\\Cov}[2]{\\mathrm{Cov}\\left[#1,\\ #2\\right]}\n\\newcommand{\\given}{\\ \\vert\\ }\n\\newcommand{\\X}{\\mathbf{X}}\n\\newcommand{\\x}{\\mathbf{x}}\n\\newcommand{\\y}{\\mathbf{y}}\n\\newcommand{\\P}{\\mathcal{P}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\n\\newcommand{\\snorm}[1]{\\lVert #1 \\rVert}\n\\newcommand{\\tr}[1]{\\mbox{tr}(#1)}\n\\newcommand{\\brt}{\\widehat{\\beta}^R_{s}}\n\\newcommand{\\brl}{\\widehat{\\beta}^R_{\\lambda}}\n\\newcommand{\\bls}{\\widehat{\\beta}_{ols}}\n\\newcommand{\\blt}{\\widehat{\\beta}^L_{s}}\n\\newcommand{\\bll}{\\widehat{\\beta}^L_{\\lambda}}\n\\newcommand{\\U}{\\mathbf{U}}\n\\newcommand{\\D}{\\mathbf{D}}\n\\newcommand{\\V}{\\mathbf{V}}\n$$\n\n\n\n\n## Model Selection\n\nModel Selection means [select the best distributions to describe your data]{.secondary}.\\\n[(I.e. the model with the smallest risk $R_n$.)]{.small}\n\n. . .\n\n### The procedure\n\n1. Generate a list of (comparable) candidate models ($\\mathcal M = \\{ \\mathcal P_1, \\mathcal P_2, \\ldots \\}$)\n2. Choose a procedure for estimating risk (e.g. $C_p$)\n3. Train each model and estimate its risk\n4. Choose the model with the lowest risk (e.g. $\\argmin_{\\mathcal P \\in \\mathcal M} C_p(\\mathcal P)$)\n\n\n## Example\n\nThe truth:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- tibble(\n  x1 = rnorm(100), \n  x2 = rnorm(100),\n  y = 3 + x1 - 5 * x2 + sin(x1 * x2 / (2 * pi)) + rnorm(100, sd = 5)\n)\n```\n:::\n\n\n\nModel 1: `y ~ x1 + x2`\n\nModel 2: `y ~ x1 + x2 + x1*x2`\n\nModel 3: `y ~ x2 + sin(x1 * x2)`\n\n. . .\n\n[The models above are written in short hand. In full statistical glory...]{.secondary}\n\n$$\n\\text{Model 1} = \\left\\{ Y|X  \\sim \\mathcal N\\left( \\:( \\beta_0 + \\beta_1 X^{(1)} + \\beta_2X^{(2)}), \\: \\sigma^2 \\right) \\quad \\text{for some } \\beta_0, \\beta_1, \\beta_2, \\sigma \\right\\}\n$$\n\n\n## Fit each model and estimate $R_n$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nforms <- list(\"y ~ x1 + x2\", \"y ~ x1 * x2\", \"y ~ x2 + sin(x1*x2)\") |> \n  map(as.formula)\nfits <- map(forms, ~ lm(.x, data = dat))\nmap(fits, ~ tibble(\n  R2 = summary(.x)$r.sq,\n  training_error = mean(residuals(.x)^2),\n  loocv = mean( (residuals(.x) / (1 - hatvalues(.x)))^2 ),\n  AIC = AIC(.x),\n  BIC = BIC(.x)\n)) |> list_rbind()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 √ó 5\n     R2 training_error loocv   AIC   BIC\n  <dbl>          <dbl> <dbl> <dbl> <dbl>\n1 0.589           21.3  22.9  598.  608.\n2 0.595           21.0  23.4  598.  611.\n3 0.586           21.4  23.0  598.  609.\n```\n\n\n:::\n:::\n\n\n\n## Model Selection vs. Variable Selection\n\nVariable selection is a subset of model selection.\n\n> Assume we have 2 predictors (`x1`, `x2`) and we're trying to choose which to include in a linear regressor:\n>\n> Model 1: `y ~ x1` [ (i.e. $\\left\\{ Y|X  \\sim \\mathcal N\\left( \\:( \\beta_0 + \\beta_1 X^{(1)} ), \\: \\sigma^2 \\right) \\right\\}$) ]{.small} \\\n> Model 2: `y ~ x2` [ (i.e. $\\left\\{ Y|X  \\sim \\mathcal N\\left( \\:( \\beta_0 + \\beta_1X^{(2)}), \\: \\sigma^2 \\right)  \\right\\}$) ]{.small} \\\n> Model 3: `y ~ x1 + x2` [ (i.e. $\\left\\{ Y|X  \\sim \\mathcal N\\left( \\:( \\beta_0 + \\beta_1 X^{(1)} + \\beta_2X^{(2)}), \\: \\sigma^2 \\right)  \\right\\}$) ]{.small}\n\n*Choosing which predictors to include is implicitly selecting a model.*\n\n. . .\n\n::: callout-note\nNote that $\\mathrm{Model 1}, \\mathrm{Model 2} \\subset \\mathrm{Model 3}$ \\\nWe say that these models are **nested**.\n:::\n\n## Selecting variables / predictors with linear methods\n\n::: flex\n::: w-40\n\nSuppose we have a set of predictors.\n\nWe estimate models with different subsets of predictors and use CV / Cp / AIC \n/ BIC to decide which is preferred.\n\nHow do we choose which variable subsets to consider?\n:::\n\n::: w-60\nAll subsets\n: estimate model based on every possible subset of size $|\\mathcal{S}| \\leq \\min\\{n, p\\}$, use one with \nlowest risk estimate\n\nForward selection\n: start with $\\mathcal{S}=\\varnothing$, add predictors greedily\n\nBackward selection\n: start with $\\mathcal{S}=\\{1,\\ldots,p\\}$, remove greedily\n\nHybrid\n: combine forward and backward smartly\n:::\n:::\n\n. . .\n\n::: callout-caution\nWithin each procedure, we're comparing _nested_ models.\nThis is important.\n:::\n\n\n## Costs and benefits\n\n\nAll subsets\n: üëç estimates each subset  \nüí£ takes $2^p$ model fits when $p<n$. If $p=50$, this is about $10^{15}$ models. \n\n. . .\n\nForward selection\n: üëç computationally feasible  \nüí£ ignores some models, correlated predictors means bad performance\n\nBackward selection\n: üëç computationally feasible  \nüí£ ignores some models, correlated predictors means bad performance  \nüí£ doesn't work if $p>n$\n\n. . .\n\nHybrid\n: üëç visits more models than forward/backward  \nüí£ slower\n\n\n## Synthetic example\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 406\ndf <- tibble( # like data.frame, but columns can be functions of preceding\n  x1 = rnorm(n),\n  x2 = rnorm(n, mean = 2, sd = 1),\n  x3 = rexp(n, rate = 1),\n  x4 = x2 + rnorm(n, sd = .1), # correlated with x2\n  x5 = x1 + rnorm(n, sd = .1), # correlated with x1\n  x6 = x1 - x2 + rnorm(n, sd = .1), # correlated with x2 and x1 (and others)\n  x7 = x1 + x3 + rnorm(n, sd = .1), # correlated with x1 and x3 (and others)\n  y = x1 * 3 + x2 / 3 + rnorm(n, sd = 2.2) # function of x1 and x2 only\n)\n```\n:::\n\n\n\n. . .\n\n$\\mathbf{x}_1$ and $\\mathbf{x}_2$ are the true predictors\n\nBut the rest are correlated with them\n\n\n## Full model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfull <- lm(y ~ ., data = df)\nsummary(full)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ ., data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.7739 -1.4283 -0.0929  1.4257  7.5869 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  0.03383    0.27700   0.122  0.90287   \nx1           6.70481    2.06743   3.243  0.00128 **\nx2          -0.43945    1.71650  -0.256  0.79807   \nx3           1.37293    1.11524   1.231  0.21903   \nx4          -1.19911    1.17850  -1.017  0.30954   \nx5          -0.53918    1.07089  -0.503  0.61490   \nx6          -1.88547    1.21652  -1.550  0.12196   \nx7          -1.25245    1.10743  -1.131  0.25876   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.231 on 398 degrees of freedom\nMultiple R-squared:  0.6411,\tAdjusted R-squared:  0.6347 \nF-statistic: 101.5 on 7 and 398 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n## True model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntruth <- lm(y ~ x1 + x2, data = df)\nsummary(truth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x1 + x2, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4519 -1.3873 -0.1941  1.3498  7.5533 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.1676     0.2492   0.673   0.5015    \nx1            3.0316     0.1146  26.447   <2e-16 ***\nx2            0.2447     0.1109   2.207   0.0279 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.233 on 403 degrees of freedom\nMultiple R-squared:  0.6357,\tAdjusted R-squared:  0.6339 \nF-statistic: 351.6 on 2 and 403 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n## All subsets\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(leaps)\ntrythemall <- regsubsets(y ~ ., data = df)\nsummary(trythemall)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSubset selection object\nCall: regsubsets.formula(y ~ ., data = df)\n7 Variables  (and intercept)\n   Forced in Forced out\nx1     FALSE      FALSE\nx2     FALSE      FALSE\nx3     FALSE      FALSE\nx4     FALSE      FALSE\nx5     FALSE      FALSE\nx6     FALSE      FALSE\nx7     FALSE      FALSE\n1 subsets of each size up to 7\nSelection Algorithm: exhaustive\n         x1  x2  x3  x4  x5  x6  x7 \n1  ( 1 ) \"*\" \" \" \" \" \" \" \" \" \" \" \" \"\n2  ( 1 ) \"*\" \" \" \" \" \" \" \" \" \"*\" \" \"\n3  ( 1 ) \"*\" \" \" \" \" \"*\" \" \" \"*\" \" \"\n4  ( 1 ) \"*\" \" \" \"*\" \"*\" \" \" \"*\" \" \"\n5  ( 1 ) \"*\" \" \" \"*\" \"*\" \" \" \"*\" \"*\"\n6  ( 1 ) \"*\" \" \" \"*\" \"*\" \"*\" \"*\" \"*\"\n7  ( 1 ) \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"\n```\n\n\n:::\n:::\n\n\n\n\n## BIC and Cp\n\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ntibble(\n  BIC = summary(trythemall)$bic, \n  Cp = summary(trythemall)$cp,\n  size = 1:7\n) |>\n  pivot_longer(-size) |>\n  ggplot(aes(size, value, colour = name)) + \n  geom_point() + \n  geom_line() + \n  facet_wrap(~name, scales = \"free_y\") + \n  ylab(\"\") +\n  scale_colour_manual(\n    values = c(blue, orange), \n    guide = \"none\"\n  )\n```\n\n::: {.cell-output-display}\n![](07-greedy-selection_files/figure-revealjs/more-all-subsets1-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Forward stepwise\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstepup <- regsubsets(y ~ ., data = df, method = \"forward\")\nsummary(stepup)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSubset selection object\nCall: regsubsets.formula(y ~ ., data = df, method = \"forward\")\n7 Variables  (and intercept)\n   Forced in Forced out\nx1     FALSE      FALSE\nx2     FALSE      FALSE\nx3     FALSE      FALSE\nx4     FALSE      FALSE\nx5     FALSE      FALSE\nx6     FALSE      FALSE\nx7     FALSE      FALSE\n1 subsets of each size up to 7\nSelection Algorithm: forward\n         x1  x2  x3  x4  x5  x6  x7 \n1  ( 1 ) \"*\" \" \" \" \" \" \" \" \" \" \" \" \"\n2  ( 1 ) \"*\" \" \" \" \" \" \" \" \" \"*\" \" \"\n3  ( 1 ) \"*\" \" \" \" \" \"*\" \" \" \"*\" \" \"\n4  ( 1 ) \"*\" \" \" \"*\" \"*\" \" \" \"*\" \" \"\n5  ( 1 ) \"*\" \" \" \"*\" \"*\" \" \" \"*\" \"*\"\n6  ( 1 ) \"*\" \" \" \"*\" \"*\" \"*\" \"*\" \"*\"\n7  ( 1 ) \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"\n```\n\n\n:::\n:::\n\n\n\n\n## BIC and Cp\n\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ntibble(\n  BIC = summary(stepup)$bic,\n  Cp = summary(stepup)$cp,\n  size = 1:7\n) |>\n  pivot_longer(-size) |>\n  ggplot(aes(size, value, colour = name)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~name, scales = \"free_y\") +\n  ylab(\"\") +\n  scale_colour_manual(\n    values = c(blue, orange),\n    guide = \"none\"\n  )\n```\n\n::: {.cell-output-display}\n![](07-greedy-selection_files/figure-revealjs/more-step-forward-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Backward selection\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstepdown <- regsubsets(y ~ ., data = df, method = \"backward\")\nsummary(stepdown)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSubset selection object\nCall: regsubsets.formula(y ~ ., data = df, method = \"backward\")\n7 Variables  (and intercept)\n   Forced in Forced out\nx1     FALSE      FALSE\nx2     FALSE      FALSE\nx3     FALSE      FALSE\nx4     FALSE      FALSE\nx5     FALSE      FALSE\nx6     FALSE      FALSE\nx7     FALSE      FALSE\n1 subsets of each size up to 7\nSelection Algorithm: backward\n         x1  x2  x3  x4  x5  x6  x7 \n1  ( 1 ) \"*\" \" \" \" \" \" \" \" \" \" \" \" \"\n2  ( 1 ) \"*\" \" \" \" \" \" \" \" \" \"*\" \" \"\n3  ( 1 ) \"*\" \" \" \" \" \"*\" \" \" \"*\" \" \"\n4  ( 1 ) \"*\" \" \" \"*\" \"*\" \" \" \"*\" \" \"\n5  ( 1 ) \"*\" \" \" \"*\" \"*\" \" \" \"*\" \"*\"\n6  ( 1 ) \"*\" \" \" \"*\" \"*\" \"*\" \"*\" \"*\"\n7  ( 1 ) \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\"\n```\n\n\n:::\n:::\n\n\n\n\n## BIC and Cp\n\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ntibble(\n  BIC = summary(stepdown)$bic,\n  Cp = summary(stepdown)$cp,\n  size = 1:7\n) |>\n  pivot_longer(-size) |>\n  ggplot(aes(size, value, colour = name)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~name, scales = \"free_y\") +\n  ylab(\"\") +\n  scale_colour_manual(\n    values = c(blue, orange), \n    guide = \"none\"\n  )\n```\n\n::: {.cell-output-display}\n![](07-greedy-selection_files/figure-revealjs/more-step-backward-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n\n##\n\n<br><br><br><br>\n\n::: r-stack\n[for this dataset, everything is the same]{.secondary .large}\n:::\n\n## What algorithm should you use in practice?\n\nEach algorithm (forward selection, backward selection, etc.) produces a series of models. \\\nFor a given algorithm, we know how to choose amongst the models in a principled way (model selection!)\n\n[How do we choose which algorithm to use?]{.secondary}\n\n. . .\n\n### As a practicioner\n\nDetermine how big your computational budget is, make an educated guess.\n\n### As a researcher\n\nWe can systematically compare the different algorithms by simulating multiple data sets\nand comparing the prediction error of the models produced by each algorithm.\n\n\n## Comparing algorithms through simulation\n\n::: callout-note\n- For each algorithm (forward selection, backward selection, all subsets), do:\n   - For $i \\in [1, 100]$, do\n        1. Generate a samples of training data\n        1. Selected a model (e.g. based on $C_p$) generated by the algorithm\n        1. Make predictions on held-out set data\n        1. Examine prediction MSE (on held-out set)\n\nCompare the average MSE (across the 100 simulations) for each algorithm.\n:::\n\n. . .\n\nWhy are we using held-out MSE to compare [forward selection vs. backward selection vs. all subsets]{.secondary}?\nWhy not use $C_p$ of the selected model?\n\n\n\n\n## Code for simulation\n\n... Annoyingly, no predict method for `regsubsets`, so we make one.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\npredict.regsubsets <- function(object, newdata, risk_estimate = c(\"cp\", \"bic\"), ...) {\n  risk_estimate <- match.arg(risk_estimate)\n  chosen <- coef(object, which.min(summary(object)[[risk_estimate]]))\n  predictors <- names(chosen)\n  if (object$intercept) predictors <- predictors[-1]\n  X <- newdata[, predictors]\n  if (object$intercept) X <- cbind2(1, X)\n  drop(as.matrix(X) %*% chosen)\n}\n```\n:::\n\n\n\n##\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimulate_and_estimate_them_all <- function(n = 406) {\n  N <- 2 * n # generate 2x the amount of data (half train, half test)\n  df <- tibble( # generate data\n    x1 = rnorm(N), \n    x2 = rnorm(N, mean = 2), \n    x3 = rexp(N),\n    x4 = x2 + rnorm(N, sd = .1), \n    x5 = x1 + rnorm(N, sd = .1),\n    x6 = x1 - x2 + rnorm(N, sd = .1), \n    x7 = x1 + x3 + rnorm(N, sd = .1),\n    y = x1 * 3 + x2 / 3 + rnorm(N, sd = 2.2)\n  )\n  train <- df[1:n, ] # half the data for training\n  test <- df[(n + 1):N, ] # half the data for evaluation\n  \n  oracle <- lm(y ~ x1 + x2 - 1, data = train) # knowing the right model, not the coefs\n  full <- lm(y ~ ., data = train)\n  stepup <- regsubsets(y ~ ., data = train, method = \"forward\")\n  stepdown <- regsubsets(y ~ ., data = train, method = \"backward\")\n  \n  tibble(\n    y = test$y,\n    oracle = predict(oracle, newdata = test),\n    full = predict(full, newdata = test),\n    stepup = predict(stepup, newdata = test),\n    stepdown = predict(stepdown, newdata = test),\n    truth = drop(as.matrix(test[, c(\"x1\", \"x2\")]) %*% c(3, 1/3))\n  )\n}\n\nset.seed(12345)\nour_sim <- map(1:50, ~ simulate_and_estimate_them_all(406)) |>\n  list_rbind(names_to = \"sim\")\n```\n:::\n\n\n\n<!--\n## What is \"Oracle\"\n\n::: flex\n::: w-70\n<a title=\"Helen Simonsson, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Delfi_Apollons_tempel.jpg\"><img width=\"800\" alt=\"Delfi Apollons tempel\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Delfi_Apollons_tempel.jpg/512px-Delfi_Apollons_tempel.jpg\"></a>\n:::\n\n::: w-30\n![](https://www.worldhistory.org/img/r/p/750x750/186.jpg.webp?v=1628028003)\n:::\n:::\n-->\n\n## Results\n\n\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\nour_sim |> \n  group_by(sim) %>%\n  summarise(\n    across(oracle:truth, ~ mean((y - .)^2)), \n    .groups = \"drop\"\n  ) %>%\n  transmute(across(oracle:stepdown, ~ . / truth - 1)) |> \n  pivot_longer(\n    everything(), \n    names_to = \"method\", \n    values_to = \"mse\"\n  ) |> \n  ggplot(aes(method, mse, fill = method)) +\n  geom_boxplot(notch = TRUE) +\n  geom_hline(yintercept = 0, linewidth = 2) +\n  scale_fill_viridis_d() +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(\n    labels = scales::label_percent()\n  ) +\n  ylab(\"% increase in mse relative\\n to the truth\")\n```\n\n::: {.cell-output-display}\n![](07-greedy-selection_files/figure-revealjs/synth-results-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n\n\n\n\n# Next time...\n\n[Module 2]{.large}\n\n[regularization, constraints, and nonparametrics]{.secondary}\n",
    "supporting": [
      "07-greedy-selection_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}