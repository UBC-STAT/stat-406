<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Geoff Pleiss">
<meta name="dcterms.date" content="2025-12-02">

<title>Lecture 17: Boosting – UBC Stat406 2025 W1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c405cde16e26c16f7328135cb468beb9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><i class="fa-solid fa-chart-column" aria-label="chart-column"></i> UBC Stat406 (2025 W1)</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../schedule/index.html"> 
<span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../computing/index.html"> 
<span class="menu-text">Computing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://ubc-stat.github.io/stat-406-rpackage/"> 
<span class="menu-text">{Rpkg} Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/stat-406-2025"> 
<span class="menu-text"><i class="fa-brands fa-github" aria-label="github"></i> Github</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#motivation-high-bias-ensembles" id="toc-motivation-high-bias-ensembles" class="nav-link" data-scroll-target="#motivation-high-bias-ensembles">Motivation: High-Bias Ensembles</a></li>
  <li><a href="#weak-learners-versus-strong-learners" id="toc-weak-learners-versus-strong-learners" class="nav-link" data-scroll-target="#weak-learners-versus-strong-learners">Weak Learners versus Strong Learners</a>
  <ul class="collapse">
  <li><a href="#definitions" id="toc-definitions" class="nav-link" data-scroll-target="#definitions">Definitions</a></li>
  <li><a href="#can-we-turn-weak-learners-into-strong-learners" id="toc-can-we-turn-weak-learners-into-strong-learners" class="nav-link" data-scroll-target="#can-we-turn-weak-learners-into-strong-learners">Can We Turn Weak Learners into Strong Learners?</a></li>
  <li><a href="#high-level-idea" id="toc-high-level-idea" class="nav-link" data-scroll-target="#high-level-idea">High-Level Idea</a></li>
  <li><a href="#intuition-a-weak-golfer" id="toc-intuition-a-weak-golfer" class="nav-link" data-scroll-target="#intuition-a-weak-golfer">Intuition: A “Weak” Golfer</a></li>
  </ul></li>
  <li><a href="#algorithm-1-forward-stagewise-additive-modelling" id="toc-algorithm-1-forward-stagewise-additive-modelling" class="nav-link" data-scroll-target="#algorithm-1-forward-stagewise-additive-modelling">Algorithm 1: Forward Stagewise Additive Modelling</a>
  <ul class="collapse">
  <li><a href="#the-core-algorithm" id="toc-the-core-algorithm" class="nav-link" data-scroll-target="#the-core-algorithm">The Core Algorithm</a></li>
  </ul></li>
  <li><a href="#adaboost-adaptive-boosting-for-binary-classification" id="toc-adaboost-adaptive-boosting-for-binary-classification" class="nav-link" data-scroll-target="#adaboost-adaptive-boosting-for-binary-classification">AdaBoost: Adaptive Boosting for Binary Classification</a>
  <ul class="collapse">
  <li><a href="#deriving-adaboost" id="toc-deriving-adaboost" class="nav-link" data-scroll-target="#deriving-adaboost">Deriving AdaBoost</a></li>
  </ul></li>
  <li><a href="#gradient-boosting-a-more-general-framework" id="toc-gradient-boosting-a-more-general-framework" class="nav-link" data-scroll-target="#gradient-boosting-a-more-general-framework">Gradient Boosting: A More General Framework</a>
  <ul class="collapse">
  <li><a href="#the-core-idea" id="toc-the-core-idea" class="nav-link" data-scroll-target="#the-core-idea">The Core Idea</a></li>
  <li><a href="#the-gradient-boosting-algorithm" id="toc-the-gradient-boosting-algorithm" class="nav-link" data-scroll-target="#the-gradient-boosting-algorithm">The Gradient Boosting Algorithm</a></li>
  <li><a href="#why-gradient-boosting" id="toc-why-gradient-boosting" class="nav-link" data-scroll-target="#why-gradient-boosting">Why “Gradient” Boosting?</a></li>
  </ul></li>
  <li><a href="#properties-of-boosting" id="toc-properties-of-boosting" class="nav-link" data-scroll-target="#properties-of-boosting">Properties of Boosting</a>
  <ul class="collapse">
  <li><a href="#bias-and-variance" id="toc-bias-and-variance" class="nav-link" data-scroll-target="#bias-and-variance">Bias and Variance</a></li>
  <li><a href="#advantages-and-disadvantages" id="toc-advantages-and-disadvantages" class="nav-link" data-scroll-target="#advantages-and-disadvantages">Advantages and Disadvantages</a></li>
  <li><a href="#risk-of-overfitting" id="toc-risk-of-overfitting" class="nav-link" data-scroll-target="#risk-of-overfitting">Risk of Overfitting</a></li>
  </ul></li>
  <li><a href="#boosting-vs-bagging" id="toc-boosting-vs-bagging" class="nav-link" data-scroll-target="#boosting-vs-bagging">Boosting vs Bagging</a>
  <ul class="collapse">
  <li><a href="#can-boosting-rely-on-independent-weak-learners" id="toc-can-boosting-rely-on-independent-weak-learners" class="nav-link" data-scroll-target="#can-boosting-rely-on-independent-weak-learners">Can Boosting Rely on Independent Weak Learners?</a></li>
  <li><a href="#when-to-use-boosting-vs.-baggingrandom-forests" id="toc-when-to-use-boosting-vs.-baggingrandom-forests" class="nav-link" data-scroll-target="#when-to-use-boosting-vs.-baggingrandom-forests">When to Use Boosting vs.&nbsp;Bagging/Random Forests</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ubc-stat/stat-406/blob/main/schedule/lectures/lecture_17_boosting.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ubc-stat/stat-406/issues/new/" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/ubc-stat/stat-406/edit/main/schedule/lectures/lecture_17_boosting.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 17: Boosting</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Geoff Pleiss </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 2, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="learning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>By the end of this lecture, you should be able to:</p>
<ol type="1">
<li>Differentiate strong learners from weak learners</li>
<li>Connect weak learners and strong learners through the lens of boosting</li>
<li>Derive the AdaBoost algorithm in pseudocode</li>
<li>Identify the settings in which boosting is likely beneficial</li>
<li>Articulate advantages and disadvantages of boosted (small) trees versus bagged (large) trees beyond accuracy</li>
</ol>
</section>
<section id="motivation-high-bias-ensembles" class="level2">
<h2 class="anchored" data-anchor-id="motivation-high-bias-ensembles">Motivation: High-Bias Ensembles</h2>
<ul>
<li>In the last lecture, we saw that high-variance/low-bias models (such as full-depth decision trees) can be ensembled using bagging/random forests to produce low-variance/low-bias predictions.</li>
<li>In this lecture, we are going to explore an orthogonal ensembling strategy called <strong>boosting</strong>, which aims to combine many <strong>high-bias/low-variance</strong> models into a single <strong>low-bias/low-variance</strong> prediction.</li>
</ul>
</section>
<section id="weak-learners-versus-strong-learners" class="level2">
<h2 class="anchored" data-anchor-id="weak-learners-versus-strong-learners">Weak Learners versus Strong Learners</h2>
<p>Before we dive into the boosting algorithm, let’s first define what we mean by “weak learners” and “strong learners”.</p>
<section id="definitions" class="level3">
<h3 class="anchored" data-anchor-id="definitions">Definitions</h3>
<ul>
<li><p>A <strong>strong learner</strong> is a predictive model that can achieve arbitrarily low error on any learning problem, given enough data. In other words, a strong learner can learn any target function to arbitrary accuracy.</p>
<ul>
<li>Examples: Non-parametric models, deep decision trees, etc.</li>
</ul></li>
<li><p>A <strong>weak learner</strong> is a predictive model that can only achieve slightly better than random guessing on any learning problem. Specifically, for a binary classification problem where random guessing would achieve 50% accuracy, a weak learner can achieve <span class="math inline">\(50\% + \epsilon\)</span> accuracy for some small <span class="math inline">\(\epsilon &gt; 0\)</span>.</p>
<ul>
<li>Examples: Depth-1 decision trees (stumps).</li>
</ul></li>
<li><p>A weak learner is <strong>limited</strong> in its ability to fit complex functions (e.g.&nbsp;high bias), while a strong learner is <strong>flexible</strong> enough to fit any function (e.g.&nbsp;low bias, and low variance given enough data).</p></li>
</ul>
</section>
<section id="can-we-turn-weak-learners-into-strong-learners" class="level3">
<h3 class="anchored" data-anchor-id="can-we-turn-weak-learners-into-strong-learners">Can We Turn Weak Learners into Strong Learners?</h3>
<ul>
<li>In 1988, Michael Kearns posed the fundamental question: <strong>“Can a set of weak learners be combined to create a single strong learner?”</strong></li>
<li>In 1990, Robert Schapire proved that the answer to this question is “yes,” by introducing the <strong>boosting</strong> algorithm and proving that it yields strong learners from weak learners.</li>
</ul>
</section>
<section id="high-level-idea" class="level3">
<h3 class="anchored" data-anchor-id="high-level-idea">High-Level Idea</h3>
<p>Let’s consider a simple 1D example to illustrate how boosting can combine weak learners into a strong learner:</p>
<ul>
<li><p>Suppose our weak (high-bias) learner is a “step function” with a single learnable parameter: <span class="math inline">\(t\)</span> (the location of the step):</p>
<p><span class="math display">\[
\hat h(x) = \begin{cases}
0 &amp; x &lt; t \\
1 &amp; x \geq t
\end{cases}
\]</span></p></li>
<li><p>With just a single step function, we have no hope of approximating any complex target function (high bias).</p></li>
<li><p>However, a linear combination of multiple step functions <span class="math inline">\(\hat h_1, \ldots, \hat h_m\)</span> will yield a piecewise constant function. Assuming the functions are ordered by their step locations <span class="math inline">\(t_1 &lt; t_2 &lt; \ldots &lt; t_m\)</span>, we get:</p>
<p><span class="math display">\[
\sum_{j=1}^m \beta_j \hat h_j(x) = \begin{cases}
0 &amp; x &lt; t_1 \\
\beta_1 &amp; t_1 \leq x &lt; t_2 \\
\beta_1 + \beta_2 &amp; t_2 \leq x &lt; t_3 \\
\vdots \\
\sum_{j=1}^m \beta_j &amp; x \geq t_m
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\beta_j\)</span> are the linear combination weights. As <span class="math inline">\(m \to \infty\)</span>, we have enough step locations to approximate any continuous function arbitrarily well!</p></li>
<li><p>Boosting will learn the step locations <span class="math inline">\(t_j\)</span> / weights <span class="math inline">\(\beta_j\)</span> in a sequential manner, where each new step function is trained to correct the errors made by the current ensemble.</p></li>
</ul>
</section>
<section id="intuition-a-weak-golfer" class="level3">
<h3 class="anchored" data-anchor-id="intuition-a-weak-golfer">Intuition: A “Weak” Golfer</h3>
<ul>
<li>Imagine you are a golfer who is not very skilled (a weak learner).</li>
<li>Your goal is to hit the golf ball into the target <span class="math inline">\((Y_1, Y_2)\)</span> from your current location: <span class="math inline">\((0, 0)\)</span></li>
<li>You begin by taking your first swing in the direction <span class="math inline">\(t_1\)</span> and you hit the ball with strength <span class="math inline">\(\beta_1\)</span>, landing at location <span class="math inline">\(( \hat Y^{(1)}_1, \hat Y^{(1)}_2 )\)</span>.</li>
<li>If we recenter our coordinate system to this new location, our new task is to hit the ball from <span class="math inline">\((0, 0)\)</span> to the new target <span class="math inline">\((Y_1 - \hat Y^{(1)}_1, Y_2 - \hat Y^{(1)}_2)\)</span>.</li>
<li>We take our second swing in direction <span class="math inline">\(t_2\)</span> with strength <span class="math inline">\(\beta_2\)</span>, landing at location <span class="math inline">\(( \hat Y^{(2)}_1, \hat Y^{(2)}_2 )\)</span> in our new coordinate system.</li>
<li>Again, if we recenter our coordinate system to this new location, our new task is to hit the ball from <span class="math inline">\((0, 0)\)</span> to the new target <span class="math inline">\((Y_1 - (\hat Y^{(1)}_1 + \hat Y^{(2)}_1), Y_2 - (\hat Y^{(1)}_2 + \hat Y^{(2)}_2))\)</span>.</li>
<li>If we repeat this process enough times, we will eventually hit the target exactly!</li>
</ul>
</section>
</section>
<section id="algorithm-1-forward-stagewise-additive-modelling" class="level2">
<h2 class="anchored" data-anchor-id="algorithm-1-forward-stagewise-additive-modelling">Algorithm 1: Forward Stagewise Additive Modelling</h2>
<p>Let’s take this golf analogy and translate it into a mathematical algorithm. We are going to sequentially learn a series of weak learners <span class="math inline">\(\hat h^{(1)}, \hat h^{(2)}, \ldots, \hat h^{(m)}\)</span> and corresponding weights <span class="math inline">\(\beta^{(1)}, \beta^{(2)}, \ldots, \beta^{(m)}\)</span> to form an ensemble predictor:</p>
<p><span class="math display">\[\hat f^{(m)}(X) = \sum_{t=1}^m \beta^{(t)} \hat h^{(t)}(X) \]</span></p>
<ul>
<li>Boosting works by training weak learners <strong>sequentially</strong>, where each new weak learner is trained to correct the errors made by the previous ensemble.</li>
</ul>
<section id="the-core-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="the-core-algorithm">The Core Algorithm</h3>
<p>We will use a recursive procedure to sequentially learn the ensemble models <span class="math inline">\(\hat h^{(t)}\)</span> and weights <span class="math inline">\(\beta^{(t)}\)</span>.</p>
<section id="regression-problems" class="level4">
<h4 class="anchored" data-anchor-id="regression-problems">Regression Problems</h4>
<ul>
<li><p>Let <span class="math inline">\(\hat h^{(t)}\)</span> be a weak learner (e.g.&nbsp;our step function from before) and <span class="math inline">\(\beta^{(t)}\)</span> be a corresponding weight term.</p></li>
<li><p>To have <span class="math inline">\(\beta^{(t)} \hat h^{(t)}\)</span> correct the errors of the previous ensemble <span class="math inline">\(\hat f^{(t-1)}\)</span>, we can train <span class="math inline">\(\beta^{(t)} \hat h^{(t)}\)</span> to predict the <strong>residuals</strong> (errors) of the current ensemble on the training data:</p>
<p><span class="math display">\[
R_i^{(t)} = Y_i - \hat f^{(t-1)}(X_i) = Y_i - \sum_{j=1}^{t-1} \beta^{(j)} \hat h^{(j)}(X_i)
\]</span></p></li>
<li><p>We then simultaneously select <span class="math inline">\(\beta^{(t)}\)</span> and <span class="math inline">\(\hat h^{(t)}\)</span> to minimize the squared error on these residuals</p>
<p><span class="math display">\[
\hat h^{(t)}, \beta^{(t)} = \arg\min_{h, \beta} \sum_{i=1}^n (R_i^{(t)} - \beta h(X_i))^2
\]</span></p></li>
<li><p>This is similar to empirical risk minimization (ERM), except we are minimizing the loss on the residuals rather than the original response variables <span class="math inline">\(Y_i\)</span>.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="What is the Purpose of the Weight $\beta^{(t)}$?">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>What is the Purpose of the Weight <span class="math inline">\(\beta^{(t)}\)</span>?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p>We could incorporate the weight <span class="math inline">\(\beta^{(t)}\)</span> into the weak learner <span class="math inline">\(\hat h^{(t)}\)</span> itself, e.g.&nbsp;by defining our weak learner to be scaled step functions with two learned parameters: <span class="math inline">\(t\)</span> (step location) and <span class="math inline">\(\beta\)</span> (step height).</p>
<p><span class="math display">\[\hat h(x) = \begin{cases}
0 &amp; x &lt; t \\
\beta &amp; x \geq t
\end{cases}.\]</span></p></li>
<li><p>In practice, it is not always natural to incorporate the weight into the weak learner itself. For example, decision trees typically do not have a natural scaling parameter.</p></li>
<li><p>More importantly, having an explicit weight term allows us to control the contribution of each weak learner to the ensemble. If we simply add each weak learner’s prediction to the ensemble without any weighting, the ensemble might oscillate or diverge rather than converging to a good solution.</p></li>
<li><p>In the golf example, we want our swings to get lighter (i.e.&nbsp;<span class="math inline">\(\beta^{(t)}\)</span> to get smaller) as we get closer to the target. Otherwise, we might overshoot the target and end up further away than before.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="generic-problems" class="level4">
<h4 class="anchored" data-anchor-id="generic-problems">Generic Problems</h4>
<ul>
<li><p>The above procedure can be generalized to arbitrary loss functions <span class="math inline">\(\ell(Y, \hat f(X))\)</span> (not just squared error).</p></li>
<li><p>For the squared error, note that:</p>
<p><span class="math display">\[
\begin{aligned}
\left( \underbrace{R_i^{(t)}}_{Y_i - \hat f^{(t-1)}(X_i)} - \beta^{(t)} \hat h^{(t)}(X_i) \right)^2
&amp;= \left(Y_i - \left( \hat f^{(t-1)}(X_i) - \beta^{(t)} \hat h^{(t)}(X_i) \right) \right)^2 \\
&amp;= \ell( Y_i, \hat f^{(t-1)}(X_i) + \beta^{(t)} \hat h^{(t)}(X_i) )
\end{aligned}
\]</span></p></li>
<li><p>Therefore, we can train the weak learners to minimize the loss on the updated ensemble predictions directly:</p>
<p><span class="math display">\[
(\hat h^{(t)}, \beta^{(t)}) = \arg\min_{h, \beta} \sum_{i=1}^n \ell( Y_i, \hat f^{(t-1)}(X_i) + \beta h(X_i) )
\]</span></p></li>
<li><p>This procedure yields the following generic boosting algorithm:</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Forward Stagewise Additive Modelling">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Forward Stagewise Additive Modelling
</div>
</div>
<div class="callout-body-container callout-body">
<p>Given:</p>
<ul>
<li>A training sample <span class="math inline">\(\mathcal{D} = \{(X_i, Y_i)\}_{i=1}^n\)</span> for some regression problem</li>
<li>A weak learning algorithm (e.g., depth-1 decision trees)</li>
<li>The number of boosting rounds <span class="math inline">\(m\)</span></li>
</ul>
<p>Initialize the ensemble predictor:</p>
<p><span class="math display">\[ \hat f^{(0)}(X) = 0 \quad \text{for all } X\]</span></p>
<p>For <span class="math inline">\(t = 1, 2, \ldots, m\)</span>:</p>
<ul>
<li><p>Choose a weak learner <span class="math inline">\(\hat h^{(t)}\)</span> that fits the current residuals:</p>
<p><span class="math display">\[
\hat h^{(t)}, \beta^{(t)} = \arg\min_{h, \beta} \sum_{i=1}^n \ell \left( Y_i, \hat f^{(t-1)}(X_i) + \beta h(X_i) \right)
\]</span></p></li>
<li><p>Update the ensemble predictor:</p>
<p><span class="math display">\[
\hat f^{(t)}(X) = \hat f^{(t-1)}(X) + \beta^{(t)} \hat h^{(t)}(X)
\]</span></p></li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/boosting_demo.svg" class="img-fluid figure-img"></p>
<figcaption>Forward Stagewise Additive Modelling on 1D Data</figcaption>
</figure>
</div>
<ul>
<li><p>In general, the simultaneous optimization over <span class="math inline">\(\hat h^{(t)}\)</span> and <span class="math inline">\(\beta^{(t)}\)</span> can be computationally expensive, depending on the weak learner and loss function used.</p></li>
<li><p>Fortunately, there are specific settings where this optimization can be done efficiently. One such setting is binary classification with exponential loss, which leads to the popular AdaBoost algorithm.</p></li>
</ul>
</section>
</section>
</section>
<section id="adaboost-adaptive-boosting-for-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="adaboost-adaptive-boosting-for-binary-classification">AdaBoost: Adaptive Boosting for Binary Classification</h2>
<ul>
<li>AdaBoost (Adaptive Boosting) was introduced by Freund and Schapire in 1996.</li>
<li>It is designed for binary classification problems and uses <strong>exponential loss</strong>, and it is a rare example where the optimization problem above can be solved efficiently in closed form.</li>
<li>AdaBoost has remarkable theoretical properties: it can drive training error to zero in <span class="math inline">\(O(\log n)\)</span> iterations.</li>
</ul>
<section id="deriving-adaboost" class="level3">
<h3 class="anchored" data-anchor-id="deriving-adaboost">Deriving AdaBoost</h3>
<ul>
<li><p>Assume that <span class="math inline">\(Y_i \in \{-1, +1\}\)</span> for all <span class="math inline">\(i\)</span> (binary classification), and assume that each weak learner <span class="math inline">\(\hat h^{(t)}\)</span> also outputs predictions in <span class="math inline">\(\{-1, +1\}\)</span>.</p></li>
<li><p>The <strong>exponential loss</strong> is given by:</p>
<p><span class="math display">\[ \ell(Y, \hat Y) = \exp(-Y \hat Y) \]</span></p>
<ul>
<li>If <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat Y\)</span> have the same sign (correct classification), then the term inside the exponential is negative (low loss)</li>
<li>If <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat Y\)</span> have opposite signs (incorrect classification), then the term inside the exponential is positive (high loss)</li>
<li>We can view the exponential loss as an approximation to the 0-1 loss that <strong>really</strong> penalizes large/incorrect <span class="math inline">\(\hat Y\)</span> values.</li>
</ul></li>
<li><p>Let’s apply this loss (and the fact that <span class="math inline">\(\hat h^{(t)}(X_i) \in \{-1, +1\}\)</span>) to the generic boosting optimization problem:</p>
<p><span class="math display">\[
\begin{align*}
(\hat h^{(t)}, \beta^{(t)}) &amp;= \arg\min_{h, \beta} \sum_{i=1}^n \ell \left( Y_i, \hat f^{(t-1)}(X_i) + \beta h(X_i) \right)
\\
&amp;= \arg\min_{h, \beta} \sum_{i=1}^n \exp\left( -Y_i \left( \hat f^{(t-1)}(X_i) + \beta h(X_i) \right) \right)
\\
&amp;= \arg\min_{h, \beta} \sum_{i=1}^n \underbrace{\exp\left( -Y_i \hat f^{(t-1)}(X_i) \right)}_{W_i} \exp\left( -\beta Y_i h(X_i) \right)
\end{align*}
\]</span></p></li>
<li><p>We can interpret the <span class="math inline">\(W_i = \exp\left( -Y_i \hat f^{(t-1)}(X_i) \right)\)</span> terms as <strong>weights</strong> on each training example <span class="math inline">\(i\)</span>, which depend on how well the current ensemble <span class="math inline">\(\hat f^{(t-1)}\)</span> classifies that example. Misclassified points will have larger weights, while correctly classified points will have smaller weights.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Interpreting the Weights">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Interpreting the Weights
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The optimization problem</p>
<p><span class="math display">\[\min_{h, \beta} \sum_{i=1}^n W_i \exp\left( -\beta Y_i h(X_i) \right) \]</span></p>
<p>can be interpreted as training the weak learner <span class="math inline">\(h\)</span> to minimize a <strong>weighted version</strong> of the exponential loss.</p>
<ul>
<li>If <span class="math inline">\(W_i = 1\)</span> for all <span class="math inline">\(i\)</span>, then this is just the ERM problem for exponential loss.</li>
<li>However, if some <span class="math inline">\(W_i\)</span> are larger than others, then the weak learner will focus more on correctly classifying those points with larger weights.</li>
<li>By setting <span class="math inline">\(W_i\)</span> to be proportional to how poorly the current ensemble classifies point <span class="math inline">\(i\)</span>, we are effectively training the weak learner to focus on the “hard” points that the current ensemble misclassifies.</li>
</ul>
</div>
</div>
</div></li>
<li><p>Note that, for any fixed <span class="math inline">\(\beta\)</span> and <span class="math inline">\(h\)</span>, the rightmost term can take on only two possible values:</p>
<p><span class="math display">\[
\exp\left( -\beta Y_i h(X_i) \right) = \begin{cases}
\exp(-\beta) &amp; \text{if } Y_i = h(X_i) \text{ (correct classification)} \\
\exp(\beta) &amp; \text{if } Y_i \neq h(X_i) \text{ (incorrect classification)}
\end{cases}
\]</span></p></li>
<li><p>We can thus subdivide the above summation into points that <span class="math inline">\(h\)</span> correctly classifies and points that it misclassifies:</p>
<p><span class="math display">\[
\begin{align*}
(\hat h^{(t)}, \beta^{(t)}) &amp;= \arg\min_{h, \beta} \left[ \sum_{i: Y_i = h(X_i)} W_i \exp \left( -\beta \underbrace{Y_i h(X_i)}_{=+1} \right) + \sum_{i: Y_i \neq h(X_i)} W_i \exp \left( -\beta \underbrace{Y_i h(X_i)}_{=-1} \right) \right] \\
&amp;= \arg\min_{h, \beta} \left[ \exp(-\beta) \sum_{i: Y_i = h(X_i)} W_i + \exp(\beta) \sum_{i: Y_i \neq h(X_i)} W_i \right]
\end{align*}
\]</span></p></li>
<li><p>By inspection (and assuming that <span class="math inline">\(\beta &gt; 0\)</span>), we can see that the optimal weak learner <span class="math inline">\(\hat h^{(t)}\)</span> is the one that minimizes the <strong>weighted classification error</strong>:</p>
<p><span class="math display">\[
\hat h^{(t)} = \arg\min_h \sum_{i=1}^n W_i \mathbb{I}(Y_i \neq h(X_i))
\]</span></p>
<p>regardless of the value of <span class="math inline">\(\beta\)</span>.</p></li>
<li><p>Moreover, for any fixed <span class="math inline">\(h\)</span>, we can find the optimal <span class="math inline">\(\beta\)</span> by differentiating the above expression, which yields:</p>
<p><span class="math display">\[
\beta^{(t)} = \frac{1}{2} \log \left( \frac{\sum_{i: Y_i = \hat h^{(t)}(X_i)} W_i}{\sum_{i: Y_i \neq \hat h^{(t)}(X_i)} W_i} \right)
\]</span></p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="The AdaBoost Algorithm">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>The AdaBoost Algorithm
</div>
</div>
<div class="callout-body-container callout-body">
<p>Given: - A training sample <span class="math inline">\(\mathcal{D} = \{(X_i, Y_i)\}_{i=1}^n\)</span> with <span class="math inline">\(Y_i \in \{-1, +1\}\)</span> - A weak learning algorithm that outputs predictions in <span class="math inline">\(\{-1, +1\}\)</span> - The number of boosting rounds <span class="math inline">\(m\)</span></p>
<p>Initialize weights: Set <span class="math inline">\(W_i = 1\)</span> for all <span class="math inline">\(i = 1, \ldots, n\)</span></p>
<p>For <span class="math inline">\(t = 1, 2, \ldots, m\)</span>:</p>
<ul>
<li><p>Train a weak learner <span class="math inline">\(\hat h^{(t)}\)</span> to minimize the weighted classification error:</p>
<p><span class="math display">\[
\hat h^{(t)} = \arg\min_h \sum_{i=1}^n W_i \mathbb{I}(Y_i \neq h(X_i))
\]</span></p></li>
<li><p>Compute the weight for the weak learner:</p>
<p><span class="math display">\[
\beta^{(t)} = \frac{1}{2} \log \left( \frac{\sum_{i: Y_i = \hat h^{(t)}(X_i)} W_i}{\sum_{i: Y_i \neq \hat h^{(t)}(X_i)} W_i} \right)
\]</span></p></li>
<li><p>Update the ensemble:</p>
<p><span class="math display">\[
\hat f^{(t)}(X) = \hat f^{(t-1)}(X) + \beta^{(t)} \hat h^{(t)}(X)
\]</span></p></li>
<li><p>Update the training example weights:</p>
<p><span class="math display">\[
W_i \gets W_i \exp\left( -\beta^{(t)} Y_i \hat h^{(t)}(X_i) \right) = \exp\left( -Y_i \hat f^{(t)}(X_i) \right)
\]</span></p></li>
</ul>
</div>
</div>
<p>AdaBoost will decrease the training error exponentially fast in the number of boosting rounds <span class="math inline">\(m\)</span>, regardless of how “weak” the base learners are. We can see an example of this convergence in the figure below, which applies boosted decision stumps (depth=1) to the <code>mobility</code> dataset. The resulting boosted ensemble is better than an optimally-tuned single decision tree after just a few boosting rounds!</p>
<div id="fig:boosted_stumps_mobility" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="../figures/boosting.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Boosted Decision Stumps on Mobility Data</figcaption>
</figure>
</div>
</section>
</section>
<section id="gradient-boosting-a-more-general-framework" class="level2">
<h2 class="anchored" data-anchor-id="gradient-boosting-a-more-general-framework">Gradient Boosting: A More General Framework</h2>
<p>What about other settings beyond binary classification with exponential loss? It turns out that a slight relaxation to the forward stagewise additive modelling framework, known as <strong>gradient boosting</strong>, provides a computationally efficient boosting approach that can be applied to essentially any (differentiable) loss function and weak learner. Its generality and efficiency make it the most widely used boosting algorithm in practice today.</p>
<p>Applying the gradient boosting framework to <strong>decision stumps</strong> (i.e.&nbsp;depth-1 or depth-2 decision trees) is one of the most popular machine learning algorithms in practice today. A popular implementation is <a href="https://xgboost.readthedocs.io/en/stable/">XGBoost</a>, which has been used to win a non-trivial portion of machine learning competitions on <a href="https://www.kaggle.com/">Kaggle</a>.</p>
<div class="callout callout-style-default callout-warning callout-titled" title="Advanced Material Below!">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Advanced Material Below!
</div>
</div>
<div class="callout-body-container callout-body">
<p>You will not have to know the details of gradient boosting for this course/the final exam. You will only need to know of its existence, and that it is a more general/computationally efficient boosting algorithm than the forward stagewise additive modelling framework.</p>
</div>
</div>
<section id="the-core-idea" class="level3">
<h3 class="anchored" data-anchor-id="the-core-idea">The Core Idea</h3>
<ul>
<li>Recall that in the basic boosting algorithm, at each iteration we train a weak learner to predict the residuals <span class="math inline">\(R_i^{(t)} = Y_i - \hat f^{(t-1)}(X_i)\)</span>.</li>
<li>These residuals can be viewed as the <strong>negative gradient</strong> of the squared loss function: <span class="math display">\[
R_i^{(t)} = Y_i - \hat f^{(t-1)}(X_i) = -\frac{\partial}{\partial \hat f^{(t-1)}(X_i)} \frac{1}{2}(Y_i - \hat f^{(t-1)}(X_i))^2
\]</span></li>
<li>Gradient boosting generalizes this idea to any differentiable loss function <span class="math inline">\(\ell (Y, \hat f(X))\)</span> by training each weak learner to predict the <strong>negative gradient</strong> of the loss: <span class="math display">\[
G_i^{(t)} = -\frac{\partial \ell(Y_i, \hat f(X_i))}{\partial \hat f(X_i)} \bigg|_{\hat f = \hat f^{(t-1)}}
\]</span></li>
</ul>
</section>
<section id="the-gradient-boosting-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="the-gradient-boosting-algorithm">The Gradient Boosting Algorithm</h3>
<div class="callout callout-style-default callout-note callout-titled" title="The Gradient Boosting Algorithm">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>The Gradient Boosting Algorithm
</div>
</div>
<div class="callout-body-container callout-body">
<p>Given:</p>
<ul>
<li>A training sample <span class="math inline">\(\mathcal{D} = \{(X_i, Y_i)\}_{i=1}^n\)</span></li>
<li>A differentiable loss function <span class="math inline">\(\ell(Y, \hat f(X))\)</span></li>
<li>A weak learning algorithm (e.g., depth-2 decision trees)</li>
<li>The number of boosting rounds <span class="math inline">\(m\)</span></li>
</ul>
<p>Initialize: Set <span class="math inline">\(\hat f^{(0)}(X) = \arg\min_c \sum_{i=1}^n \ell(Y_i, c)\)</span> (constant initial prediction)</p>
<p>For <span class="math inline">\(t = 1, 2, \ldots, m\)</span>:</p>
<ol type="1">
<li>Compute the negative gradient (pseudo-residuals) for each training example: <span class="math display">\[
G_i^{(t)} = -\frac{\partial \ell(Y_i, \hat f^{(t-1)}(X_i))}{\partial \hat f^{(t-1)}(X_i)}
\]</span></li>
<li>Train a weak learner <span class="math inline">\(\hat h^{(t)}\)</span> to predict the pseudo-residuals: <span class="math display">\[
\hat h^{(t)} = \arg\min_h \sum_{i=1}^n \ell (G_i^{(t)}, h(X_i))
\]</span></li>
<li>Find the optimal weight for the weak learner: <span class="math display">\[
\beta^{(t)} = \arg\min_\beta \sum_{i=1}^n \ell(Y_i, \hat f^{(t-1)}(X_i) + \beta \hat h^{(t)}(X_i))
\]</span></li>
<li>Update the ensemble: <span class="math display">\[
\hat f^{(t)}(X) = \hat f^{(t-1)}(X) + \beta^{(t)} \hat h^{(t)}(X)
\]</span></li>
</ol>
<p>Return the final predictor: <span class="math inline">\(\hat f^{(m)}(X)\)</span></p>
</div>
</div>
</section>
<section id="why-gradient-boosting" class="level3">
<h3 class="anchored" data-anchor-id="why-gradient-boosting">Why “Gradient” Boosting?</h3>
<ul>
<li><p>Let <span class="math inline">\(\boldsymbol G^{(t)} \in \mathbb R^n\)</span> be the concatenation of the gradients and let <span class="math inline">\(\boldsymbol{\hat h}^{(t)} \in \mathbb R^n\)</span> be the predictions of the weak learner on the training data.</p>
<p><span class="math display">\[ \boldsymbol G^{(t)} = \begin{bmatrix} G_1^{(t)} \\ G_2^{(t)} \\ \vdots \\ G_n^{(t)} \end{bmatrix} \quad , \quad \boldsymbol{\hat h}^{(t)} = \begin{bmatrix} \hat h^{(t)}(X_1) \\ \hat h^{(t)}(X_2) \\ \vdots \\ \hat h^{(t)}(X_n) \end{bmatrix} \]</span></p></li>
<li><p>In Step 2 of the algorithm, our goal is to minimize the loss between the gradients and the weak learner predictions:</p>
<p><span class="math display">\[ \hat h^{(t)} = \arg\min_h \sum_{i=1}^n \left( G_i^{(t)} - h(X_i) \right)^2, \]</span></p>
<p>i.e.&nbsp;we want to make each <span class="math inline">\(\hat h^{(t)}(X_i)\)</span> as close as possible to <span class="math inline">\(G_i^{(t)}\)</span>.</p></li>
<li><p>We can view this idea as wanting the <span class="math inline">\(\boldsymbol{\hat h}^{(t)}\)</span> vector to point in the opposite direction as the <span class="math inline">\(\boldsymbol G^{(t)}\)</span> vector. In other words, we want to <strong>minimize the cosine similarity</strong> between these two vectors:</p>
<p><span class="math display">\[ \min_{\hat h^{(t)}} \frac{\langle \boldsymbol G^{(t)}, \boldsymbol{\hat h}^{(t)} \rangle}{\|\boldsymbol G^{(t)}\|_2 \|\boldsymbol{\hat h}^{(t)}\|_2}, \]</span></p>
<p>as the cosine similarity is minimized (at <span class="math inline">\(-1\)</span>) when the two vectors point in opposite directions.</p></li>
<li><p>Since we will scale the predictions of the weak learner by <span class="math inline">\(\beta^{(t)}\)</span> in Step 4, we can assume without loss of generality that <span class="math inline">\(\|\boldsymbol{\hat h}^{(t)}\|_2 = 1\)</span>.</p></li>
<li><p>Minimizing the cosine similarity is thus equivalent to:</p>
<p><span class="math display">\[
\begin{align*}
\min_{\hat h^{(t)}} \frac{\langle \boldsymbol G^{(t)}, \boldsymbol{\hat h}^{(t)} \rangle}{\|\boldsymbol G^{(t)}\|_2 \|\boldsymbol{\hat h}^{(t)}\|_2}
&amp;= \min_{\hat h^{(t)}} \frac{\langle \boldsymbol G^{(t)}, \boldsymbol{\hat h}^{(t)} \rangle}{\|\boldsymbol G^{(t)}\|_2 }
\\
&amp;= \min_{\hat h^{(t)}} \langle \boldsymbol G^{(t)}, \boldsymbol{\hat h}^{(t)} \rangle
\\
&amp;= \min_{\hat h^{(t)}} \sum_{i=1}^n \ell(Y_i, \hat f^{(t-1)}(X_i)) + \langle \boldsymbol G^{(t)}, \boldsymbol{\hat h}^{(t)} \rangle
\end{align*}
\]</span></p>
<p>where the last two equalities hold because neither <span class="math inline">\(\Vert \boldsymbol G^{(t)} \Vert\)</span> nor <span class="math inline">\(\sum_{i=1}^n \ell(Y_i, \hat f^{(t-1)}(X_i))\)</span> depend on <span class="math inline">\(\hat h^{(t)}\)</span>.</p></li>
<li><p>In other words, Step 2 is equivalent to finding <span class="math inline">\(\hat h^{(t)}\)</span> that minimizes the first-order Taylor approximation of the loss around the current ensemble predictions:</p>
<p><span class="math display">\[
\sum_{i=1}^n \ell(Y_i, \hat f^{(t-1)}(X_i) + \hat h^{(t)}(X_i)) \approx \sum_{i=1}^n \ell(Y_i, \hat f^{(t-1)}(X_i)) + \langle \boldsymbol G^{(t)}, \boldsymbol{\hat h}^{(t)} \rangle.
\]</span></p></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Connection to Gradient-Based Optimization">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Connection to Gradient-Based Optimization
</div>
</div>
<div class="callout-body-container callout-body">
<p>For those of you who want to take a mathematical trip, we can view gradient boosting as performing gradient descent in function space. This idea is quite advanced, but if we view the ensemble prediction function <span class="math inline">\(\hat f^{(t)} : \mathbb R^d \to \mathbb R\)</span> as an infinite-dimensional parameter vector, at each iteration we are updating this parameter vector with <span class="math inline">\(\hat h^{(t)} : \mathbb R^d \to \mathbb R\)</span>, which is another infinite-dimensional parameter vector that is aligned with the negative gradient of the loss.</p>
</div>
</div>
</section>
</section>
<section id="properties-of-boosting" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-boosting">Properties of Boosting</h2>
<section id="bias-and-variance" class="level3">
<h3 class="anchored" data-anchor-id="bias-and-variance">Bias and Variance</h3>
<ul>
<li><p><strong>Decreases bias</strong>: Boosting combines many weak (high-bias) learners into a strong (low-bias) learner. As we add more boosting rounds, the ensemble becomes more flexible and can fit more complex functions. The training error typically decreases monotonically (even exponentially fast for AdaBoost) as we add more rounds.</p></li>
<li><p><strong>Can increase variance, but not much if done properly</strong>: Unlike bagging, boosting does not explicitly aim to reduce variance. In fact, boosting can increase variance if we use too many rounds, as the ensemble starts to overfit the training data. However, by using small weak learners and adding them gradually, we can control the variance and prevent overfitting.</p></li>
</ul>
</section>
<section id="advantages-and-disadvantages" class="level3">
<h3 class="anchored" data-anchor-id="advantages-and-disadvantages">Advantages and Disadvantages</h3>
<ul>
<li><p><strong>Much more efficient than bagging/random forests</strong>: Because boosted ensembles use small weak learners (e.g., depth-2 trees) rather than full-depth trees, each component model is much faster to train. A depth-2 tree has at most 4 leaf nodes, while a full-depth tree on a dataset of size <span class="math inline">\(n\)</span> has <span class="math inline">\(n\)</span> leaf nodes!</p></li>
<li><p><strong>Good for anytime learning</strong>: Boosting is inherently sequential, but this can be an advantage for “anytime learning” scenarios. For a given test point, we don’t have to feed the test point through all <span class="math inline">\(m\)</span> weak learners in the ensemble. Instead, we can truncate the ensemble prediction after <span class="math inline">\(k &lt; m\)</span> models to get a quick prediction. Because the weak learners are trained on sequentially smaller residuals, the first few models in the ensemble will typically capture most of the signal, and thus may yield a reasonable prediction.</p>
<p>(“Anytime learning” is a popular approach for early ML systems on resource-constrained devices. It was first used &lt;20 years ago to detect faces on pre-smartphone digital cameras!)</p></li>
<li><p><strong>Sequential nature is a limitation</strong>: Unlike bagging/random forests, where each tree can be trained independently (and thus in parallel), boosting requires sequential training.</p></li>
<li><p><strong>No free uncertainty quantification/risk estimation.</strong> Bagged ensembles were built upon bootstrapped training samples, which allowed us to inherit all the advantages of bootstrapping (e.g.&nbsp;variance estimates/confidence intervals, risk estimates on out-of-bag samples, etc.). Boosted ensembles do not have this property, since all weak learners are trained on the same training data.</p></li>
</ul>
</section>
<section id="risk-of-overfitting" class="level3">
<h3 class="anchored" data-anchor-id="risk-of-overfitting">Risk of Overfitting</h3>
<ul>
<li>Boosting can overfit if we use too many rounds or if the weak learners are too complex.</li>
<li>However, in practice most boosting algorithms have been observed to be relatively resistant to overfitting (sometimes continuing to improve test error even after training error reaches zero), though this is not guaranteed and depends on the dataset and noise characteristics.</li>
</ul>
</section>
</section>
<section id="boosting-vs-bagging" class="level2">
<h2 class="anchored" data-anchor-id="boosting-vs-bagging">Boosting vs Bagging</h2>
<p>Boosting and bagging are both ensemble methods, and frequently methods used to ensemble decision trees. <strong>However, they are not interchangeable!</strong></p>
<ul>
<li><strong>Bagging reduces variance</strong>, and so it is best suited to ensemble low-bias/high-variance models (e.g., full-depth decision trees).</li>
<li><strong>Boosting reduces bias</strong>, and so it is best suited to ensemble high-bias/low-variance models (e.g., shallow decision trees).</li>
</ul>
<section id="can-boosting-rely-on-independent-weak-learners" class="level3">
<h3 class="anchored" data-anchor-id="can-boosting-rely-on-independent-weak-learners">Can Boosting Rely on Independent Weak Learners?</h3>
<ul>
<li><p>In bagging/random forests, we relied on the fact that the component models made <strong>independent errors</strong> (due to being trained on different bootstrap samples) to achieve variance reduction through averaging.</p></li>
<li><p>For boosting high-bias models, can we similarly rely on independent weak learners?</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Intuitive Answer">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Intuitive Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>No.&nbsp;If each weak learner makes systematic errors (e.g., always underpredicting in certain regions), then averaging many independent weak learners will not eliminate these systematic errors. The ensemble will still have high bias.</p>
<p>To reduce bias, we need the weak learners to <strong>correct each other’s errors</strong> in a coordinated way. This requires that the weak learners be trained sequentially, not independently.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Statistical Justification">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Statistical Justification
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Recall that bias is a systematic error: <span class="math inline">\(\text{Bias}[\hat f(X)] = \mathbb{E}[\hat f(X)] - f(X)\)</span>.</p>
<p>If we have <span class="math inline">\(m\)</span> independent weak learners <span class="math inline">\(\hat h^{(1)}, \ldots, \hat h^{(m)}\)</span>, then the ensemble predictor is:</p>
<p><span class="math display">\[
\hat f_\text{ens}(X) = \frac{1}{m} \sum_{j=1}^m \hat h^{(j)}(X)
\]</span></p>
<p>The bias of the ensemble is:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Bias}[\hat f_\text{ens}(X)] &amp;= \mathbb{E}[\hat f_\text{ens}(X)] - \mathbb E[Y \mid X] \\
&amp;= \frac{1}{m} \sum_{j=1}^m \left( \mathbb{E}[\hat h^{(j)}(X)] - \mathbb E[Y \mid X] \right) \\
&amp;= \mathbb{E}[\hat h^{(j)}(X)] - \mathbb E[Y \mid X] = \text{Bias}[\hat h^{(j)}(X)]
\end{aligned}
\]</span></p>
<p>Thus, the bias of the ensemble is the same as the bias of any individual weak learner! Averaging independent weak learners does not reduce bias.</p>
</div>
</div>
</div></li>
</ul>
</section>
<section id="when-to-use-boosting-vs.-baggingrandom-forests" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-boosting-vs.-baggingrandom-forests">When to Use Boosting vs.&nbsp;Bagging/Random Forests</h3>
<ul>
<li><strong>Boosting</strong> (with small trees) is generally preferred when:
<ul>
<li>Computational efficiency is important (faster training, smaller models)</li>
<li>Our computational resources are sequential, not parallel</li>
</ul></li>
<li><strong>Bagging/Random Forests</strong> (with large trees) are generally preferred when:
<ul>
<li>Uncertainty quantification is important</li>
<li>We want risk estimates without cross-validation</li>
<li>We have access to computational resources</li>
</ul></li>
<li>In practice, both methods are extremely powerful, and the choice often depends on the specific problem and priorities (accuracy vs.&nbsp;uncertainty vs.&nbsp;computational cost).</li>
</ul>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<ul>
<li>Boosting is an ensemble method that combines many <strong>weak learners</strong> (high-bias models) into a <strong>strong learner</strong> (low-bias model).</li>
<li>The key insight is to train weak learners <strong>sequentially</strong>, where each new weak learner corrects the errors of the previous ensemble. This is fundamentally different from bagging, which trains models independently to reduce variance.</li>
<li><strong>AdaBoost</strong> is a specific boosting algorithm for binary classification that uses exponential loss and adaptive sample weighting. It has strong theoretical guarantees, driving training error to zero in <span class="math inline">\(O(\log n)\)</span> iterations.</li>
<li><strong>Gradient boosting</strong> is a more general framework that can be applied to any differentiable loss function by training each weak learner to predict the negative gradient of the loss. This can be viewed as gradient descent in function space.</li>
<li>Boosting <strong>reduces bias</strong> (unlike bagging, which reduces variance) and is <strong>computationally efficient</strong>, but does not provide uncertainty quantification or out-of-bag error estimates.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/UBC-STAT\.github\.io\/stat-406\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>This work by <a href="https://geoffpleiss.com">Geoff Pleiss</a>, <a href="https://trevorcampbell.me">Trevor Campbell</a>, and <a href="https://dajmcdon.github.io">Daniel J. McDonald</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0">CC BY-NC 4.0</a><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ubc-stat/stat-406/blob/main/schedule/lectures/lecture_17_boosting.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ubc-stat/stat-406/issues/new/" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/ubc-stat/stat-406/edit/main/schedule/lectures/lecture_17_boosting.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>