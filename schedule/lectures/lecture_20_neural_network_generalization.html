<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Geoff Pleiss">
<meta name="dcterms.date" content="2025-12-11">

<title>Lecture 20: Neural Network Generalization – UBC Stat406 2025 W1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c405cde16e26c16f7328135cb468beb9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><i class="fa-solid fa-chart-column" aria-label="chart-column"></i> UBC Stat406 (2025 W1)</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../schedule/index.html"> 
<span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../computing/index.html"> 
<span class="menu-text">Computing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://ubc-stat.github.io/stat-406-rpackage/"> 
<span class="menu-text">{Rpkg} Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/stat-406-2025"> 
<span class="menu-text"><i class="fa-brands fa-github" aria-label="github"></i> Github</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a></li>
  <li><a href="#capacity-versus-generalization" id="toc-capacity-versus-generalization" class="nav-link" data-scroll-target="#capacity-versus-generalization">Capacity versus Generalization</a>
  <ul class="collapse">
  <li><a href="#recall-from-the-previous-lecture" id="toc-recall-from-the-previous-lecture" class="nav-link" data-scroll-target="#recall-from-the-previous-lecture">Recall from the Previous Lecture:</a></li>
  <li><a href="#what-this-implies" id="toc-what-this-implies" class="nav-link" data-scroll-target="#what-this-implies">What This Implies:</a></li>
  <li><a href="#expected-behavior-biasvariance-tradeoff" id="toc-expected-behavior-biasvariance-tradeoff" class="nav-link" data-scroll-target="#expected-behavior-biasvariance-tradeoff">Expected Behavior: Bias/Variance Tradeoff</a></li>
  </ul></li>
  <li><a href="#the-surprising-phenomenon-double-descent" id="toc-the-surprising-phenomenon-double-descent" class="nav-link" data-scroll-target="#the-surprising-phenomenon-double-descent">The Surprising Phenomenon: Double Descent</a>
  <ul class="collapse">
  <li><a href="#implications-for-modern-neural-networks" id="toc-implications-for-modern-neural-networks" class="nav-link" data-scroll-target="#implications-for-modern-neural-networks">Implications for Modern Neural Networks</a></li>
  </ul></li>
  <li><a href="#understanding-double-descent-insights-from-basis-regression" id="toc-understanding-double-descent-insights-from-basis-regression" class="nav-link" data-scroll-target="#understanding-double-descent-insights-from-basis-regression">Understanding Double Descent: Insights from Basis Regression</a>
  <ul class="collapse">
  <li><a href="#intuition-hand-wavy-explanation" id="toc-intuition-hand-wavy-explanation" class="nav-link" data-scroll-target="#intuition-hand-wavy-explanation">Intuition (Hand-Wavy Explanation)</a></li>
  <li><a href="#the-role-of-minimum-norm-solutions" id="toc-the-role-of-minimum-norm-solutions" class="nav-link" data-scroll-target="#the-role-of-minimum-norm-solutions">The Role of Minimum Norm Solutions</a></li>
  <li><a href="#the-full-theoretical-picture" id="toc-the-full-theoretical-picture" class="nav-link" data-scroll-target="#the-full-theoretical-picture">The Full Theoretical Picture</a></li>
  </ul></li>
  <li><a href="#regularization-in-the-overparameterized-regime" id="toc-regularization-in-the-overparameterized-regime" class="nav-link" data-scroll-target="#regularization-in-the-overparameterized-regime">Regularization in the Overparameterized Regime</a></li>
  <li><a href="#practical-tips-for-using-neural-networks" id="toc-practical-tips-for-using-neural-networks" class="nav-link" data-scroll-target="#practical-tips-for-using-neural-networks">Practical Tips for Using Neural Networks</a>
  <ul class="collapse">
  <li><a href="#when-to-use-neural-networks" id="toc-when-to-use-neural-networks" class="nav-link" data-scroll-target="#when-to-use-neural-networks">When to Use Neural Networks</a></li>
  <li><a href="#transfer-learning-is-the-default-approach" id="toc-transfer-learning-is-the-default-approach" class="nav-link" data-scroll-target="#transfer-learning-is-the-default-approach">Transfer Learning is the Default Approach</a></li>
  <li><a href="#computational-requirements" id="toc-computational-requirements" class="nav-link" data-scroll-target="#computational-requirements">Computational Requirements</a></li>
  <li><a href="#the-design-space-is-huge" id="toc-the-design-space-is-huge" class="nav-link" data-scroll-target="#the-design-space-is-huge">The Design Space is Huge</a></li>
  <li><a href="#getting-started" id="toc-getting-started" class="nav-link" data-scroll-target="#getting-started">Getting Started</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ubc-stat/stat-406/blob/main/schedule/lectures/lecture_20_neural_network_generalization.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ubc-stat/stat-406/issues/new/" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/ubc-stat/stat-406/edit/main/schedule/lectures/lecture_20_neural_network_generalization.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 20: Neural Network Generalization</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Geoff Pleiss </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 11, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="learning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>By the end of this lecture, you should be able to:</p>
<ul>
<li>Explain the phenomenon of double descent, and when it occurs in neural networks.</li>
<li>Identify the key criterion that yields a “classic” bias-variance tradeoff versus double descent.</li>
</ul>
</section>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<ul>
<li>In the previous lecture, we learned how to train neural networks using gradient descent and backpropagation.</li>
<li>However, we left a major question unanswered: why do neural networks generalize well to new data?</li>
<li>We saw part of the answer in the first neural network lecture: they are able to learn hierarchical features that are exponentially more expressive with depth.</li>
<li>However, this predictive power comes at a cost: neural networks may require many parameters to represent these complex functions, making them susceptible to high variance and overfitting.</li>
<li>This lecture will explore why neural networks generalize well despite (or perhaps because of) their large number of parameters. It is perhaps one of the most surprising and important discoveries in modern machine learning!</li>
</ul>
</section>
<section id="capacity-versus-generalization" class="level2">
<h2 class="anchored" data-anchor-id="capacity-versus-generalization">Capacity versus Generalization</h2>
<p>Consider a neural network with <span class="math inline">\(L\)</span> hidden layers, each with <span class="math inline">\(D\)</span> hidden units.</p>
<section id="recall-from-the-previous-lecture" class="level3">
<h3 class="anchored" data-anchor-id="recall-from-the-previous-lecture">Recall from the Previous Lecture:</h3>
<p>From our discussion of width and depth, we established two key facts about this network:</p>
<ul>
<li><strong>Number of piecewise-linear regions</strong>: <span class="math inline">\(O(D^L)\)</span> (exponential in depth!)</li>
<li><strong>Number of parameters</strong>: <span class="math inline">\(O(D^2 L)\)</span> (quadratic in width, linear in depth)</li>
</ul>
</section>
<section id="what-this-implies" class="level3">
<h3 class="anchored" data-anchor-id="what-this-implies">What This Implies:</h3>
<p>These two facts together suggest that:</p>
<ul>
<li>Our neural network is capable of learning extremely complicated functions. With <span class="math inline">\(L\)</span> layers and <span class="math inline">\(D\)</span> units per layer, we can represent <span class="math inline">\(O(D^L)\)</span> different piecewise-linear regions, which grows exponentially with depth.</li>
<li>However, will our network learn the <em>correct</em> function from limited training data? With <span class="math inline">\(O(D^2 L)\)</span> parameters to learn, and typically <span class="math inline">\(D^2 L \gg n\)</span> (i.e., more parameters than training examples), we might expect the network to overfit to the training data.</li>
</ul>
</section>
<section id="expected-behavior-biasvariance-tradeoff" class="level3">
<h3 class="anchored" data-anchor-id="expected-behavior-biasvariance-tradeoff">Expected Behavior: Bias/Variance Tradeoff</h3>
<p>Recall the bias-variance tradeoff we discussed earlier in the course. For decision trees, we saw that as we increase the depth of the tree (and thus the number of parameters), we observe a characteristic U-shaped curve for the test error:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/tree_bias_variance.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Bias/variance tradeoff for trees as a function of depth.</figcaption>
</figure>
</div>
<ul>
<li>When the tree is shallow (few parameters), the model has high bias but low variance.</li>
<li>When the tree is deep (many parameters), the model has low bias but high variance.</li>
<li>The optimal depth is somewhere in the middle, where the bias-variance tradeoff is balanced.</li>
</ul>
<p>Based on this understanding, we would expect a similar bias-variance curve for neural networks as a function of the number of parameters. In particular, we would expect that increasing the number of parameters (either by increasing width or depth) should yield a drop in bias (we can learn a piecewise approximation with more pieces) but an increase in variance (we are more likely to fit noise that is specific to our given training sample).</p>
<p><strong>But this simple tradeoff is not what we observe in practice!</strong></p>
</section>
</section>
<section id="the-surprising-phenomenon-double-descent" class="level2">
<h2 class="anchored" data-anchor-id="the-surprising-phenomenon-double-descent">The Surprising Phenomenon: Double Descent</h2>
<p>In 2019, researchers discovered a surprising empirical phenomenon that challenges our traditional understanding of the bias-variance tradeoff. When we plot the test error of neural networks as a function of the number of parameters, we observe a <strong>double descent</strong> curve:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/double_descent_nn.png" class="img-fluid figure-img" width="1000"></p>
<figcaption>Double descent curve for neural networks. <span class="small">Image credit: Belkin et al., (2019)</span></figcaption>
</figure>
</div>
<p>This curve has several surprising features:</p>
<ul>
<li>Initially (on the left side of the plot), we observe the expected U-shaped bias-variance curve. As we increase the number of parameters, the test error first decreases (as bias decreases), then increases (as variance increases).</li>
<li>However, after the number of parameters exceeds the number of training examples (<span class="math inline">\(n\)</span>), something unexpected happens: the test error <em>decreases again</em> as we continue to add more parameters!</li>
<li>This creates a “double descent” shape, with two distinct regions where test error decreases.</li>
</ul>
<section id="implications-for-modern-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-modern-neural-networks">Implications for Modern Neural Networks</h3>
<ul>
<li>Many modern neural networks have <strong>tons</strong> of parameters, often orders of magnitude more than the number of training examples.</li>
<li>These networks live on the right side of the double descent curve, in the <strong>overparameterized regime</strong> where adding more parameters actually <em>improves</em> generalization.</li>
<li>This explains why neural networks can generalize well despite having so many parameters: they are not in the high-variance regime we would expect from classical statistical theory!</li>
<li>Prior to this discovery, statisticians believed that having more parameters than training examples would always lead to overfitting.</li>
<li>Since 2019, there has been significant theoretical progress in understanding why double descent occurs, though it remains an active area of research.</li>
</ul>
</section>
</section>
<section id="understanding-double-descent-insights-from-basis-regression" class="level2">
<h2 class="anchored" data-anchor-id="understanding-double-descent-insights-from-basis-regression">Understanding Double Descent: Insights from Basis Regression</h2>
<p>To build intuition for why double descent occurs, we will study a much simpler class of models: <strong>basis regression</strong> (i.e., linear models with basis expansions). Remarkably, the double descent phenomenon is not specific to neural networks—we can observe it in basis regression as well!</p>
<p>Consider a basis regression model with an increasing number of basis functions <span class="math inline">\(d\)</span>. As we increase <span class="math inline">\(d\)</span> beyond the number of training examples <span class="math inline">\(n\)</span>, we observe the same double descent curve:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/double_descent_rff.png" class="img-fluid figure-img"></p>
<figcaption>Double descent curve for basis regression. <span class="small">Image credit: Belkin et al., (2019)</span></figcaption>
</figure>
</div>
<p>Notice that:</p>
<ul>
<li><p>The inflection point (where the test error peaks) occurs precisely when the number of basis functions equals the number of training examples: <span class="math inline">\(d = n\)</span>.</p></li>
<li><p>This is the point at which our basis regressor, if trained without any ridge or lasso penalty, is able to perfectly fit the training data (i.e., achieve zero training error).</p></li>
<li><p>Before this point (<span class="math inline">\(d &lt; n\)</span>), the model is <strong>underparameterized</strong> and cannot perfectly fit the training data. In other words, the OLS solution will have a non-zero training error:</p>
<p><span class="math display">\[ \min_{\boldsymbol \beta} \left \Vert \boldsymbol \Phi \boldsymbol \beta - \boldsymbol Y \right\Vert_2^2 &gt; 0. \]</span></p>
<p>where <span class="math inline">\(\boldsymbol \Phi \in \mathbb R^{n \times d}\)</span> is the basis expansion matrix for our <span class="math inline">\(n\)</span> training points.</p></li>
<li><p>After this point (<span class="math inline">\(d &gt; n\)</span>), the model is <strong>overparameterized</strong> and can perfectly fit the training data, but the test error decreases as we add more basis functions!</p></li>
</ul>
<section id="intuition-hand-wavy-explanation" class="level3">
<h3 class="anchored" data-anchor-id="intuition-hand-wavy-explanation">Intuition (Hand-Wavy Explanation)</h3>
<p>To understand why the test error decreases in the overparameterized regime, let’s think about what happens to the learned parameters <span class="math inline">\(\boldsymbol \beta\)</span> as we increase the number of basis functions <span class="math inline">\(d\)</span>.</p>
<p>Now consider what happens as we vary the number of basis functions <span class="math inline">\(d\)</span>:</p>
<p><strong>When <span class="math inline">\(d &lt; n\)</span> (underparameterized regime):</strong></p>
<ul>
<li>The model is <strong>underparameterized</strong>.</li>
<li>There is no <span class="math inline">\(\boldsymbol \beta\)</span> that perfectly explains our training responses given our basis-expanded training inputs.</li>
<li>In other words, even the best possible <span class="math inline">\(\boldsymbol \beta\)</span> will have non-zero training error: <span class="math inline">\(\Vert \boldsymbol \Phi \boldsymbol \beta - \boldsymbol Y \Vert &gt; 0\)</span>.</li>
<li>As we increase <span class="math inline">\(d\)</span> (but still <span class="math inline">\(d &lt; n\)</span>), we can fit the training data better and better, reducing both bias and training error.</li>
</ul>
<p><strong>When <span class="math inline">\(d = n\)</span> (interpolation threshold):</strong></p>
<ul>
<li>At this critical point, there exists a value of <span class="math inline">\(\boldsymbol \beta\)</span> that fits our training data perfectly.</li>
<li>That is, <span class="math inline">\(\Vert \boldsymbol \Phi \boldsymbol \beta - \boldsymbol Y \Vert = 0\)</span>.</li>
<li>However, this means we are fitting both the <em>signal</em> (the true underlying relationship) and the <em>noise</em> (random fluctuations in the training data).</li>
<li>This leads to a high-variance predictor that overfits to the training noise, resulting in poor test performance.</li>
</ul>
<p><strong>When <span class="math inline">\(d &gt; n\)</span> (overparameterized regime):</strong></p>
<ul>
<li>The model is <strong>overparameterized</strong>.</li>
<li>We can still fit the training data (noise + signal) perfectly, but now there are infinitely many solutions that achieve zero training error.</li>
<li>As we increase <span class="math inline">\(d\)</span>, we have more and more features, which means the noise gets “spread out” over more parameters.</li>
<li>Since each parameter only captures “some” of the noise (rather than concentrating it in a few parameters), we are less likely to make predictions based on this noise.</li>
<li>This leads to better generalization performance as <span class="math inline">\(d\)</span> increases!</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>This explanation is overly simplified, and there is a lot more at play. In the next section, we’ll provide a slightly more rigorous explanation of what’s happening in the overparameterized regime.</p>
</div>
</div>
</section>
<section id="the-role-of-minimum-norm-solutions" class="level3">
<h3 class="anchored" data-anchor-id="the-role-of-minimum-norm-solutions">The Role of Minimum Norm Solutions</h3>
<p>The key to understanding double descent in the overparameterized regime is recognizing that, when there are infinitely many solutions to our optimization problem, gradient descent converges to a very special solution: the <strong>minimum norm solution</strong>.</p>
<section id="infinitely-many-solutions" class="level4">
<h4 class="anchored" data-anchor-id="infinitely-many-solutions">Infinitely Many Solutions</h4>
<p>In (unregularized) basis regression, if <span class="math inline">\(d &gt; n\)</span>, then the OLS problem is <strong>underdetermined</strong>. This means there are <strong>infinitely many solutions</strong> <span class="math inline">\(\boldsymbol \beta\)</span> that achieve zero training error (i.e., <span class="math inline">\(\boldsymbol \Phi \boldsymbol \beta = \boldsymbol Y\)</span>).</p>
<p>The question is: which of these infinitely many solutions does gradient descent find, and which is most likely to generalize well?</p>
</section>
<section id="gradient-descent-finds-the-minimum-norm-solution" class="level4">
<h4 class="anchored" data-anchor-id="gradient-descent-finds-the-minimum-norm-solution">Gradient Descent Finds the Minimum Norm Solution</h4>
<p>It turns out that, when there are infinitely many solutions to our optimization problem, gradient descent (when initialized at <span class="math inline">\(\boldsymbol \beta = \boldsymbol 0\)</span>) converges to the <strong>minimum norm solution</strong>:</p>
<p><span class="math display">\[ \hat{\boldsymbol \beta} = \mathrm{argmin}_{\boldsymbol \beta : \boldsymbol \Phi \boldsymbol \beta = \boldsymbol Y} \Vert \boldsymbol \beta \Vert_2^2, \]</span></p>
<p>where <span class="math inline">\(\boldsymbol \Phi \in \mathbb R^{n \times d}\)</span> is our basis expansion matrix.</p>
<p>In other words, gradient descent finds the solution that perfectly fits the training data <em>and</em> has the smallest possible <span class="math inline">\(\ell_2\)</span> norm among all such solutions.</p>
</section>
<section id="visualizing-minimum-norm-solutions" class="level4">
<h4 class="anchored" data-anchor-id="visualizing-minimum-norm-solutions">Visualizing Minimum Norm Solutions</h4>
<p>Consider the following figure, which shows two different basis regression models that both interpolate the training data perfectly:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/minimum_norm_bias.png" class="img-fluid figure-img" width="600"></p>
<figcaption>Two possible solutions to underdetermined basis regression. The solution from a basis regressor with 4000 features is “smoother” than the solution from 40 features. <span class="small">Image credit: Belkin et al., (2019)</span></figcaption>
</figure>
</div>
<ul>
<li>The “rough” looking solution comes from a basis regressor with 40 features.</li>
<li>The “smooth” solution comes from a basis regressor with 4000 features.</li>
<li>Both models interpolate the training data perfectly (i.e., achieve zero training error), but the 4000-feature model produces a much smoother prediction function.</li>
</ul>
<p>This is because the 4000-feature model has access to more basis functions, allowing it to find a lower-norm solution that still interpolates the training data.</p>
</section>
<section id="why-do-more-features-lead-to-smaller-norms" class="level4">
<h4 class="anchored" data-anchor-id="why-do-more-features-lead-to-smaller-norms">Why Do More Features Lead to Smaller Norms?</h4>
<p>We already saw from ridge regression that smaller parameter norms lead to better generalization (lower test error). But why does having more features lead to smaller norms?</p>
<div class="callout callout-style-default callout-tip callout-titled" title="More Features → Smaller Norms?">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>More Features → Smaller Norms?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The key insight is that basis regression models with different numbers of features are <strong>nested models</strong>.</p>
<ul>
<li>The 40-feature basis regressor is a special case of the 4000-feature basis regressor, where we simply set 3960 of the coefficients to zero.</li>
<li>Both the 40-feature and 4000-feature models can interpolate the training data (achieve zero training error).</li>
<li>However, the 4000-feature model is guaranteed to be the minimum-norm interpolator over <em>all</em> 4000-feature linear models.</li>
<li>Since the 40-feature model is just one of these 4000-feature models (with many coefficients set to zero), the 4000-feature model must have smaller (or equal) norm than the 40-feature model.</li>
<li>Thus, as we increase the number of features beyond <span class="math inline">\(n\)</span>, we can learn smoother (i.e., lower norm) interpolating solutions, which generalize better.</li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="the-full-theoretical-picture" class="level3">
<h3 class="anchored" data-anchor-id="the-full-theoretical-picture">The Full Theoretical Picture</h3>
<p>Double descent and the generalization of neural networks are still extremely active areas of research. However, since the initial characterization of this phenomenon in 2019, there has been significant progress in developing a rigorous theoretical understanding of why it occurs.</p>
<p>Fully understanding the theory would require a whole course in itself (and lots of PhD-level math!), but we can at least glimpse at some of the key theoretical results.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="(Advanced): Theoretical Characterization of Double Descent in Overparameterized Basis Regression">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>(Advanced): Theoretical Characterization of Double Descent in Overparameterized Basis Regression
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>(From <a href="https://arxiv.org/abs/1903.08560">Hastie et al., 2020</a>)</p>
<ul>
<li><p><span class="math inline">\(\gamma = D / N\)</span> (ratio of features / data)</p></li>
<li><p><span class="math inline">\(\sigma^2 = \mathbb{V}[Y|X]\)</span> (observational noise)</p></li>
<li><p>When basis features are uncorrelated, we have (asymptotically)</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
  \mathrm{Bias}^2 &amp;= \begin{cases}
    0 &amp; \gamma &lt; 1 \text{ (underparam.)} \\
    1 - \tfrac{1}{\gamma} &amp; \gamma \geq 1 \text{ (overparam.)}
  \end{cases} \\
  &amp; \\
  \mathrm{Var} &amp;= \begin{cases}
    \sigma^2 \tfrac{\gamma}{1 - \gamma} &amp; \gamma &lt; 1 \text{ (underparam.)} \\
    \sigma^2 \tfrac{1}{\gamma - 1} &amp; \gamma \geq 1 \text{ (overparam.)}
  \end{cases} \\
\end{aligned}
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/hastie_double_descent.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-caption="Double descent curve theoretical."></p>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="regularization-in-the-overparameterized-regime" class="level2">
<h2 class="anchored" data-anchor-id="regularization-in-the-overparameterized-regime">Regularization in the Overparameterized Regime</h2>
<p>Now that we understand why neural networks generalize well despite having many parameters, we can revisit other variance reduction techniques that we’ve previously studied to determine whether or not they are necessary.</p>
<p>The most general strategy we’ve studied for variance reduction is <strong>regularization</strong>, i.e.&nbsp;adding a complexity penalty to our optimization objective (think ridge regression, lasso, etc.).</p>
<p><span class="math display">\[ \mathrm{argmin}_{\boldsymbol W^{(1)}, \ldots, \boldsymbol W^{(L)}, \boldsymbol \beta} \sum_{i=1}^n \ell(y_i, \hat f_\mathrm{NN}(\boldsymbol x_i)) \: + \: \text{complexity penalty} \]</span></p>
<p>The most common form of regularization for neural networks is <strong>weight decay</strong> (also called <strong>L2 regularization</strong>):</p>
<p><span class="math display">\[ \text{complexity penalty} = \frac{\lambda}{2} \left( \Vert \boldsymbol \beta \Vert_2^2 + \sum_{\ell=1}^L \Vert \mathrm{vec} (\boldsymbol W^{(\ell)}) \Vert_2^2 \right), \]</span></p>
<p>where <span class="math inline">\(\lambda \geq 0\)</span> is a tuning parameter that controls the strength of the regularization, and <span class="math inline">\(\mathrm{vec}(\boldsymbol W^{(\ell)})\)</span> denotes the vectorization of the weight matrix <span class="math inline">\(\boldsymbol W^{(\ell)}\)</span>. (This penalty is exactly the same as the ridge regression penalty, but now it’s applied to all weight matrices in the neural network.)</p>
<p><strong>Before we understood double descent</strong> (pre-2019):</p>
<ul>
<li>We believed that neural networks with many parameters would suffer from high variance.</li>
<li>Therefore, we thought you needed strong regularization (high <span class="math inline">\(\lambda\)</span>) to combat this high variance.</li>
<li>Researchers invented many sophisticated regularization techniques beyond weight decay, such as dropout, pruning, mixup, and many others.</li>
</ul>
<p><strong>After understanding double descent</strong> (post-2019):</p>
<ul>
<li>We now understand that overparameterized neural networks do not necessarily have high variance, due to the implicit bias towards low-norm solutions provided by gradient descent.</li>
<li>Therefore, heavy regularization is no longer considered necessary for good generalization.</li>
<li>In modern practice, it’s now uncommon to use anything more than light weight decay (small <span class="math inline">\(\lambda\)</span>), and many state-of-the-art models use little to no explicit regularization at all!</li>
</ul>
</section>
<section id="practical-tips-for-using-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="practical-tips-for-using-neural-networks">Practical Tips for Using Neural Networks</h2>
<p>Now that we understand how neural networks work and why they generalize, here are some practical tips for using them in practice:</p>
<section id="when-to-use-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-neural-networks">When to Use Neural Networks</h3>
<ul>
<li>Neural networks are best suited for <strong>unstructured data types</strong> such as images, text, audio, video, etc., though they are best used with slight modifications to the layer architecture that we studied.</li>
<li>If you have <strong>tabular data</strong> (i.e., data in a spreadsheet with rows and columns), you’re often better off using other algorithms like random forests or gradient boosting. Neural networks can work on tabular data, but they typically don’t outperform simpler methods.</li>
</ul>
</section>
<section id="transfer-learning-is-the-default-approach" class="level3">
<h3 class="anchored" data-anchor-id="transfer-learning-is-the-default-approach">Transfer Learning is the Default Approach</h3>
<ul>
<li>Rather than training a neural network from scratch on your dataset, start from a neural network that someone else has <strong>pre-trained</strong> on a larger dataset. This strategy is often called <strong>transfer learning</strong> or <strong>fine-tuning</strong>.</li>
<li>There are many existing pre-trained models for images, video, text, molecules, and other domains freely available online.</li>
<li>This strategy enables neural networks to work well even on extremely small datasets (e.g., <span class="math inline">\(100 \leq n \leq 1000\)</span>), which would be insufficient for training from scratch.</li>
</ul>
</section>
<section id="computational-requirements" class="level3">
<h3 class="anchored" data-anchor-id="computational-requirements">Computational Requirements</h3>
<ul>
<li>Neural networks are computationally expensive to train.</li>
<li>They typically won’t run (efficiently) on your laptop; you’ll need access to a GPU cluster to train them in a reasonable time.</li>
<li>However, once trained, neural networks can often make predictions relatively quickly, even on a CPU.</li>
</ul>
</section>
<section id="the-design-space-is-huge" class="level3">
<h3 class="anchored" data-anchor-id="the-design-space-is-huge">The Design Space is Huge</h3>
<ul>
<li>The design space of neural networks is enormous! There are many different architectures, optimizers, regularizers, learning rate schedules, and other hyperparameters to choose from.</li>
<li>Rather than designing a neural network from scratch, it’s best to start from an existing architecture and codebase that someone has already built for a related problem.</li>
<li>There’s no shortage of good open-source codebases and pre-trained models available online (e.g., on GitHub, Hugging Face, PyTorch Hub, etc.).</li>
</ul>
</section>
<section id="getting-started" class="level3">
<h3 class="anchored" data-anchor-id="getting-started">Getting Started</h3>
<ul>
<li>If you want to play around with neural networks, learn Python and use the <strong>PyTorch</strong> library!</li>
<li>PyTorch is the most popular deep learning framework in research, and has excellent documentation and community support.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/UBC-STAT\.github\.io\/stat-406\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>This work by <a href="https://geoffpleiss.com">Geoff Pleiss</a>, <a href="https://trevorcampbell.me">Trevor Campbell</a>, and <a href="https://dajmcdon.github.io">Daniel J. McDonald</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0">CC BY-NC 4.0</a><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ubc-stat/stat-406/blob/main/schedule/lectures/lecture_20_neural_network_generalization.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ubc-stat/stat-406/issues/new/" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/ubc-stat/stat-406/edit/main/schedule/lectures/lecture_20_neural_network_generalization.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>