<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Geoff Pleiss">
<meta name="dcterms.date" content="2025-10-28">

<title>Lecture 4: Model Selection – UBC Stat406 2025 W1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c405cde16e26c16f7328135cb468beb9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><i class="fa-solid fa-chart-column" aria-label="chart-column"></i> UBC Stat406 (2025 W1)</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../schedule/index.html"> 
<span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../computing/index.html"> 
<span class="menu-text">Computing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://ubc-stat.github.io/stat-406-rpackage/"> 
<span class="menu-text">{Rpkg} Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/stat-406-2025"> 
<span class="menu-text"><i class="fa-brands fa-github" aria-label="github"></i> Github</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-objective" id="toc-learning-objective" class="nav-link active" data-scroll-target="#learning-objective">Learning Objective</a></li>
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a></li>
  <li><a href="#defining-the-best-model" id="toc-defining-the-best-model" class="nav-link" data-scroll-target="#defining-the-best-model">Defining “The Best Model”</a>
  <ul class="collapse">
  <li><a href="#possible-metrics-for-best-model" id="toc-possible-metrics-for-best-model" class="nav-link" data-scroll-target="#possible-metrics-for-best-model">Possible Metrics for “Best Model”</a></li>
  <li><a href="#in-a-perfect-world-which-metric-should-we-use" id="toc-in-a-perfect-world-which-metric-should-we-use" class="nav-link" data-scroll-target="#in-a-perfect-world-which-metric-should-we-use">In a Perfect World, Which Metric Should We Use?</a></li>
  </ul></li>
  <li><a href="#estimating-risk" id="toc-estimating-risk" class="nav-link" data-scroll-target="#estimating-risk">Estimating Risk</a>
  <ul class="collapse">
  <li><a href="#bad-idea-training-error" id="toc-bad-idea-training-error" class="nav-link" data-scroll-target="#bad-idea-training-error">Bad Idea: Training Error</a></li>
  <li><a href="#ideal-solution-many-samples-of-training-data-one-test-point" id="toc-ideal-solution-many-samples-of-training-data-one-test-point" class="nav-link" data-scroll-target="#ideal-solution-many-samples-of-training-data-one-test-point">Ideal Solution: Many Samples of Training Data + One Test Point</a></li>
  <li><a href="#practical-solution-cross-validation" id="toc-practical-solution-cross-validation" class="nav-link" data-scroll-target="#practical-solution-cross-validation">Practical Solution: Cross-Validation</a></li>
  </ul></li>
  <li><a href="#model-selection-finally" id="toc-model-selection-finally" class="nav-link" data-scroll-target="#model-selection-finally">Model Selection (Finally!)</a>
  <ul class="collapse">
  <li><a href="#example-variable-selection" id="toc-example-variable-selection" class="nav-link" data-scroll-target="#example-variable-selection">Example: Variable Selection</a></li>
  <li><a href="#connection-to-the-algorithmic-perspective" id="toc-connection-to-the-algorithmic-perspective" class="nav-link" data-scroll-target="#connection-to-the-algorithmic-perspective">Connection to the Algorithmic Perspective</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ubc-stat/stat-406/blob/main/schedule/lectures/lecture_04_model_selection.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ubc-stat/stat-406/issues/new/" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/ubc-stat/stat-406/edit/main/schedule/lectures/lecture_04_model_selection.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 4: Model Selection</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Geoff Pleiss </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 28, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="learning-objective" class="level2">
<h2 class="anchored" data-anchor-id="learning-objective">Learning Objective</h2>
<p>By the end of this lecture, you should be able to:</p>
<ol type="1">
<li>Define and differentiate between testing error, expected test error, and risk</li>
<li>Choose amongst metrics and estimators for model selection on a variety of problems</li>
<li>Identify when a validation-set estimator of risk is biased or (nearly) unbiased</li>
<li>Perform cross-validation to perform variable selection in linear regression</li>
</ol>
</section>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<p>We are now going to fill in the remaining steps of the learning procedure from a statistical perspective. We’ve already covered defining the statistical model, estimation, and prediction.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 5%">
<col style="width: 20%">
<col style="width: 34%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>CS Perspective</th>
<th>Statistical Perspective</th>
<th>Example: Linear Regression</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Split data into train/test/val</td>
<td>???</td>
<td>???</td>
</tr>
<tr class="even">
<td>2</td>
<td>Hypothesis Class</td>
<td>Statistical Model</td>
<td><span class="math inline">\(\mathbb{E}[Y \mid X = x] = x^\top \beta\)</span></td>
</tr>
<tr class="odd">
<td>3</td>
<td>Training</td>
<td>Estimation</td>
<td><span class="math inline">\(\hat{\beta}_\mathrm{MLE/OLS} = (\boldsymbol{X}^\top \boldsymbol{X})^{-1} \boldsymbol{X}^\top \boldsymbol{Y}\)</span></td>
</tr>
<tr class="even">
<td>4</td>
<td>Validation</td>
<td>???</td>
<td>???</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Iteration</td>
<td>???</td>
<td>???</td>
</tr>
<tr class="even">
<td>6</td>
<td>Testing (Inference)</td>
<td>Prediction</td>
<td><span class="math inline">\(\hat{Y}_\mathrm{new} = X_\mathrm{new}^\top \hat{\beta}\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li>From a statistical perspective, steps 1, 4, and 5 blur together in a procedure we call <strong>model selection.</strong></li>
<li>At a high level, the purpose of these three steps is to <strong>choose the best statistical model given our training data.</strong></li>
</ul>
</section>
<section id="defining-the-best-model" class="level2">
<h2 class="anchored" data-anchor-id="defining-the-best-model">Defining “The Best Model”</h2>
<section id="possible-metrics-for-best-model" class="level3">
<h3 class="anchored" data-anchor-id="possible-metrics-for-best-model">Possible Metrics for “Best Model”</h3>
<ol type="1">
<li><p><strong>Test error</strong></p>
<ul>
<li><p>On (almost) every learning task, we usually withhold some test data <span class="math inline">\(\left\{ (X_j, Y_j) \right\}_{j=1}^t\)</span>, assumed to be i.i.d. from the same distribution as our training data.</p></li>
<li><p>Given our training set <span class="math inline">\(\mathcal D = \left\{ (X_i, Y_i) \right\}_{i=1}^n\)</span>, the test error is:</p>
<p><span class="math display">\[ \widehat{\mathrm{Err}}_\mathcal{D} := \frac{1}{t} \sum_{j=1}^t L(Y_j, f_\mathcal{D}(X_j)) \]</span></p></li>
<li><p>I.e. we train our model <span class="math inline">\(\hat f\)</span> on <span class="math inline">\(\mathcal D\)</span>, and then compute its average loss on the test dataset.</p></li>
</ul></li>
<li><p><strong>Expected test error</strong></p>
<ul>
<li><p>As <span class="math inline">\(t \to \infty\)</span>, <span class="math inline">\(\widehat{\mathrm{Err}}_\mathcal{D}\)</span> converges (by the law of large numbers) to: <span class="math display">\[ \mathrm{Err}_\mathcal{D} := \mathbb E \left[ L(Y, \hat f_\mathcal{D}(X)) \mid \mathcal D \right] \]</span></p></li>
<li><p>We call this the <strong>expected test error</strong>.</p></li>
<li><p>Note that the training set <span class="math inline">\(\mathcal D\)</span> is fixed.</p>
<details>
<summary>
<p>Why?</p>
</summary>
<p>We are assuming that the number of test samples <span class="math inline">\(t\)</span> goes to infinity, but we’re assuming the training set doesn’t change. So we’re averaging over the randomness in the test point <span class="math inline">\((X, Y)\)</span> only, but not the randomness in the training set <span class="math inline">\(\mathcal D\)</span>.</p>
</details></li>
<li><p><strong>Intuition:</strong> your boss hands you training set <span class="math inline">\(\mathcal D\)</span>, and you train a <span class="math inline">\(\hat f_\mathcal{D}\)</span> that’s going to be deployed for a very very long time. <span class="math inline">\(\mathrm{Err}_\mathcal{D}\)</span> estimates the error you’ll get on the many many predictions that will be made by your model.</p></li>
</ul></li>
<li><p><strong>Risk</strong></p>
<ul>
<li><p><strong>Risk</strong>, which is one level more abstract than expected test error, averages over <em>all sources of randomness</em>: <span class="math display">\[ \mathcal R := \mathbb E \left[ L \left( Y, \hat f_{\mathcal D}(X) \right) \right] \]</span></p></li>
<li><p>Note that <em>all sources of randomness</em> includes the test datapoint <span class="math inline">\((X, Y)\)</span> as well as the training dataset <span class="math inline">\(\mathcal D\)</span>.</p></li>
<li><p>We can relate <span class="math inline">\(\mathcal R\)</span> to the expected test error via:</p>
<p><span class="math display">\[ \mathcal R = \mathbb E \left[ \mathrm{Err}_\mathcal{D} \right] \]</span></p>
<details>
<summary>
<p>Why?</p>
</summary>
<p><strong>Tower rule!!!</strong></p>
<p><span class="math display">\[\begin{align*}
    \mathcal R &amp;= \mathbb E \left[ L \left( Y, \hat f_{\mathcal D}(X) \right) \right] \\
    &amp;= \mathbb E \left[ \mathbb E \left[ L \left( Y, \hat f_{\mathcal D}(X) \right)  \mid \mathcal D \right] \right] \\
    &amp;= \mathbb E \left[ \mathrm{Err}_\mathcal{D} \right]
  \end{align*}\]</span></p>
</details></li>
<li><p><strong>Intuition:</strong> if you were to get a new training set <span class="math inline">\(\mathcal D'\)</span> and retrain your model, how well would it perform on average?</p></li>
</ul></li>
</ol>
</section>
<section id="in-a-perfect-world-which-metric-should-we-use" class="level3">
<h3 class="anchored" data-anchor-id="in-a-perfect-world-which-metric-should-we-use">In a Perfect World, Which Metric Should We Use?</h3>
<ul>
<li><p>Let’s ignore the fact that we have access to limited amounts of data, and pretend that we happened to know all three of these metrics exactly. Which one should we use?</p></li>
<li><p>Test error is out. There’s nothing special about the particular test set we happened to withhold. We’d much rather know the average error over all possible points, so expected test error is strictly better.</p></li>
<li><p>Regarding expected test error vs.&nbsp;risk, there’s some debate. In general I would argue that risk is actually the metric we care most about.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Expected Test Error vs. Risk">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Expected Test Error vs.&nbsp;Risk
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Reasons to prefer expected test error</strong></p>
<ul>
<li>In practice, we only have one training set <span class="math inline">\(\mathcal D\)</span>.</li>
<li>Expected test error tells us how well our model will perform on the <em>particular training set</em> we are given.</li>
</ul>
<p><strong>Reasons to prefer risk</strong></p>
<ul>
<li>In practice, we might get new data to retrain our model on; we don’t want a metric that’s dependent on a particular training set.</li>
<li>If we’re trying to select a “best” model, we’d ideally like one that’s not too sensitive to the particular training set we happened to get.</li>
<li>As we will see next lecture, risk is easier to analyze theoretically.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>In 75% of scenarios, it doesn’t matter if we target risk or expected test error. (In practice, most estimators of risk are also estimators of expected test error, and vice versa.) However, we’ll see some cases (e.g.&nbsp;on Homework 2) where the distinction matters.</li>
</ul>
</section>
</section>
<section id="estimating-risk" class="level2">
<h2 class="anchored" data-anchor-id="estimating-risk">Estimating Risk</h2>
<section id="bad-idea-training-error" class="level3">
<h3 class="anchored" data-anchor-id="bad-idea-training-error">Bad Idea: Training Error</h3>
<ul>
<li><p>A common mistake is to use <strong>training error</strong> as an estimator of risk:</p>
<p><span class="math display">\[ \widehat{\mathrm{Err}}_\mathrm{train} := \frac{1}{n} \sum_{i=1}^n L(Y_i, f_\mathcal{D}(X_i)) \]</span></p></li>
<li><p>Training error is almost always a <strong>severely biased</strong> estimator of risk, and should never be used for model selection.</p>
<details>
<summary>
<p>Why?</p>
</summary>
<ul>
<li>The training error is computed on the same data that was used to train the model.
<ul>
<li>Therefore, the model has “seen” this data before, and has likely fit it quite well.</li>
<li>In contrast, risk is computed on new, unseen data.</li>
<li>As a result, training error underestimates the true risk of the model.</li>
</ul>
<strong>Example</strong>: consider a dataset with <span class="math inline">\(p\)</span> points and a linear model with <span class="math inline">\(p\)</span> parameters. Running OLS on this dataset will result in zero training error, but the risk of this model will be much higher than zero on new data!</li>
</ul>
</details></li>
<li><p>(Training error does indeed have its uses; we’ll see one example next lecture!)</p></li>
</ul>
</section>
<section id="ideal-solution-many-samples-of-training-data-one-test-point" class="level3">
<h3 class="anchored" data-anchor-id="ideal-solution-many-samples-of-training-data-one-test-point">Ideal Solution: Many Samples of Training Data + One Test Point</h3>
<ul>
<li><p>Imagine we had access to a generator that produces random <span class="math inline">\(\left\{ (X_i, Y_i) \right\}_{i=1}^{n+1}\)</span> samples, where the <span class="math inline">\(n+1\)</span> pairs are i.i.d.</p></li>
<li><p>We could estimate risk by:</p>
<ol type="1">
<li><p>Generating <span class="math inline">\(m\)</span> samples <span class="math inline">\(\left\{ \left\{ (X_i^{(j)}, Y_i^{(j)} \right\}_{i=1}^{n+1} \right\}_{j=1}^{m}\)</span></p></li>
<li><p>Estimate risk as: <span class="math display">\[ \hat{\mathcal R} \approx \frac{1}{m} \sum_{i=1}^m L_j,
  \quad L_j = L\left( Y_{n+1}^{(j)}, f_{\mathcal D^{(j)}}( X^{(j)}_{n+1}) \right),
  \quad \mathcal D^{(j)} = \left\{ (X_i^{(j)}, Y_i^{(j)}) \right\}_{i=1}^n.
  \]</span></p></li>
</ol>
<ul>
<li>In other words, for each of the <span class="math inline">\(m\)</span> samples, we train a model on the first <span class="math inline">\(n\)</span> data points, and compute its loss on the <span class="math inline">\(n+1^\mathrm{th}\)</span> datapoint we withhold from training.</li>
</ul></li>
<li><p>By the law of large numbers, as <span class="math inline">\(m \to \infty\)</span> we have:</p>
<p><span class="math display">\[\hat{\mathcal R} \to \mathbb E[ L( Y_{n+1}, \hat f_\mathcal{D}( X_{n+1}) )] = \mathcal R\]</span></p></li>
</ul>
</section>
<section id="practical-solution-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="practical-solution-cross-validation">Practical Solution: Cross-Validation</h3>
<ul>
<li>In practice, we only have access to a single dataset <span class="math inline">\(\mathcal D = \left\{ (X_i, Y_i) \right\}_{i=1}^n\)</span> with <span class="math inline">\(n\)</span> data points.</li>
<li>Nevertheless: we can approximate the ideal solution above using <strong>leave-one-out cross-validation (LOO-CV)</strong>.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Cross Validation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Cross Validation
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Given: a single dataset <span class="math inline">\(\mathcal D = \left\{ (X_i, Y_i) \right\}_{i=1}^n\)</span></li>
<li>For each <span class="math inline">\(i = 1, \ldots, n\)</span>:
<ol type="1">
<li>Train a model <span class="math inline">\(\hat f_{\mathcal D_{-i}}\)</span> on the dataset with the <span class="math inline">\(i^\mathrm{th}\)</span> point removed: <span class="math inline">\(\mathcal D_{-i} := \left\{ (X_j, Y_j) \right\}_{j \neq i}\)</span></li>
<li>Compute the loss on the withheld point: <span class="math inline">\(L_i := L(Y_i, \hat f_{\mathcal D_{-i}}(X_i))\)</span></li>
<li>Estimate risk as: <span class="math inline">\(\hat{\mathcal R}_\mathrm{LOOCV} := \frac{1}{n} \sum_{i=1}^n L_i\)</span></li>
</ol></li>
</ul>
</div>
</div>
<section id="why-does-loo-cv-work" class="level4">
<h4 class="anchored" data-anchor-id="why-does-loo-cv-work">Why Does LOO-CV Work?</h4>
<ul>
<li><p>Each <span class="math inline">\(L_i\)</span> is an unbiased estimate of risk on a training set of size <span class="math inline">\(n-1\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  \mathbb E[L_i] &amp;= \mathbb E \left[ L(Y_i, \hat f_{\mathcal D_{-i}}(X_i)) \right] =: \mathcal R_{n-1} \\
\end{align*}\]</span></p></li>
<li><p>By <em>linearity of expectation</em>, we also have that <span class="math inline">\(\hat{\mathcal R}_\mathrm{LOOCV}\)</span> is an unbiased estimate of risk on a training set of size <span class="math inline">\(n-1\)</span>:</p>
<details>
<summary>
<p>Derivation:</p>
</summary>
<p><span class="math display">\[\begin{align*}
    \mathbb E[\hat{\mathcal R}_\mathrm{LOOCV}] = \mathbb E \left[ \frac{1}{n} \sum_{i=1}^n L_i \right]
    = \frac{1}{n} \sum_{i=1}^n \mathbb E[L_i] = \mathcal R_{n-1}
  \end{align*}\]</span></p>
</details></li>
<li><p>Unlike our “ideal estimator” above, the <span class="math inline">\(L_i\)</span> are not independent, and therefore we can’t apply the law of large numbers to conclude that <span class="math inline">\(\hat{\mathcal R}_\mathrm{LOOCV}\)</span> converges to <span class="math inline">\(\mathcal R\)</span>.</p></li>
<li><p>In practice, however, <span class="math inline">\(\hat{\mathcal R}_\mathrm{LOOCV}\)</span> is often a good estimator of risk.</p></li>
</ul>
</section>
<section id="a-more-efficient-solution-k-fold-cross-validation" class="level4">
<h4 class="anchored" data-anchor-id="a-more-efficient-solution-k-fold-cross-validation">A More Efficient Solution: K-Fold Cross Validation</h4>
<ul>
<li>LOO-CV requires training <span class="math inline">\(n\)</span> separate models, which can be very expensive.</li>
<li>A more efficient alternative is <strong>K-fold cross validation (K-CV)</strong>:</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="K-Fold Cross Validation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>K-Fold Cross Validation
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Given: a single dataset <span class="math inline">\(\mathcal D = \left\{ (X_i, Y_i) \right\}_{i=1}^n\)</span></li>
<li>Randomly split <span class="math inline">\(\mathcal D\)</span> into <span class="math inline">\(K\)</span> (roughly) equal-sized “folds”: <span class="math inline">\(\mathcal D_1, \ldots, \mathcal D_K\)</span></li>
<li>For each <span class="math inline">\(k = 1, \ldots, K\)</span>:
<ol type="1">
<li>Train a model <span class="math inline">\(\hat f_{\mathcal D_{-k}}\)</span> on the dataset with the <span class="math inline">\(k^\mathrm{th}\)</span> fold removed: <span class="math inline">\(\mathcal D_{-k} := \bigcup_{j \neq k} \mathcal D_j\)</span></li>
<li>Compute the loss on the withheld fold: <span class="math inline">\(L_k := \frac{1}{|\mathcal D_k|} \sum_{(X_i, Y_i) \in \mathcal D_k} L(Y_i, \hat f_{\mathcal D_{-k}}(X_i))\)</span></li>
<li>Estimate risk as: <span class="math inline">\(\hat{\mathcal R}_\mathrm{K-CV} := \frac{1}{K} \sum_{k=1}^K L_k\)</span></li>
</ol></li>
</ul>
</div>
</div>
<ul>
<li><p>Decreasing <span class="math inline">\(K\)</span> decreases the number of models we need to train.</p></li>
<li><p>However, decreasing <span class="math inline">\(K\)</span> also results in a worse estimator of risk.</p>
<details>
<summary>
<p>Why?</p>
</summary>
<p><strong>Intuitively</strong>: as <span class="math inline">\(K\)</span> decreases, each model is trained on less data, and we’re trying to estimate the risk of a model trained on all <span class="math inline">\(n\)</span> data points.</p>
<p><strong>Formally</strong>: each <span class="math inline">\(L_k\)</span> is an unbiased estimate of risk on a training set of size <span class="math inline">\(n - n/K\)</span>, but the difference between <span class="math inline">\(\mathcal R_n\)</span> and <span class="math inline">\(\mathcal R_{n - n/K}\)</span> can be significant for small <span class="math inline">\(K\)</span>.</p>
</details></li>
</ul>
</section>
</section>
</section>
<section id="model-selection-finally" class="level2">
<h2 class="anchored" data-anchor-id="model-selection-finally">Model Selection (Finally!)</h2>
<p>Now that we’ve chosen <em>risk</em> as our metric for “the best model,” <strong>model selection</strong> amounts to choosing the statistical model with the best risk.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Model Selection">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Model Selection
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Given: a single dataset <span class="math inline">\(\mathcal D\)</span></li>
<li>for however long you have,
<ol type="1">
<li>Propose a statistical model (e.g.&nbsp;linear regression, decision tree, neural network, etc.)</li>
<li>Estimate its parameters on <span class="math inline">\(\mathcal D\)</span> to get <span class="math inline">\(\hat f_\mathcal{D}\)</span></li>
<li>Estimate its risk <span class="math inline">\(\hat{\mathcal R}\)</span> using K-CV (or some other method)</li>
</ol></li>
<li>Choose the model with the lowest estimated risk <span class="math inline">\(\hat{\mathcal R}\)</span></li>
</ul>
</div>
</div>
<section id="example-variable-selection" class="level3">
<h3 class="anchored" data-anchor-id="example-variable-selection">Example: Variable Selection</h3>
<p>Consider the following synthetic dataset, where we have:</p>
<p><span class="math display">\[ Y = 3 X_1 + \frac{1}{3} X_2 + \epsilon, \quad \epsilon \sim \mathcal N(0, 0.5^2) \]</span></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>( <span class="co"># like data.frame, but columns can be functions of preceding</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(n),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">x3 =</span> <span class="fu">rexp</span>(n, <span class="at">rate =</span> <span class="dv">1</span>),</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">x4 =</span> x2 <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> .<span class="dv">1</span>), <span class="co"># correlated with x2</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> x1 <span class="sc">*</span> <span class="dv">3</span> <span class="sc">+</span> x2 <span class="sc">/</span> <span class="dv">3</span> <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.5</span>) <span class="co"># function of x1 and x2 only</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Note that <span class="math inline">\(Y\)</span> is a function of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> only, and <span class="math inline">\(X_3\)</span> and <span class="math inline">\(X_4\)</span> are irrelevant to predicting <span class="math inline">\(Y\)</span>.</p>
<p>We might consider the following statistical models (here written as linear regression models), in all cases assuming <span class="math inline">\(\epsilon \sim \mathcal N(0, \sigma^2)\)</span> for some <span class="math inline">\(\sigma &gt; 0\)</span>:</p>
<ol type="1">
<li><strong>Model 1</strong>: <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + \epsilon\)</span></li>
<li><strong>Model 2</strong>: <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon\)</span></li>
<li><strong>Model 3</strong>: <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \epsilon\)</span></li>
<li><strong>Model 4</strong>: <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4 + \epsilon\)</span></li>
</ol>
<div class="callout callout-style-default callout-important callout-titled" title="Variable Selection is a Specific Instance of Model Selection">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Variable Selection is a Specific Instance of Model Selection
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>You might recognize this setup as a <strong>variable selection</strong> problem. (Even more specifically, these model choices may remind you of <em>forward stepwise selection</em> from STAT 306).</p>
<p>Adding covariates to our regression changes the set of distributions that we are considering to represent our data (i.e.&nbsp;it changes our statistical model).</p>
<p>Note that model selection is a much broader concept than variable selection. For example, we might also consider:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4 + \beta_5 X_1^2 + \epsilon\]</span></p>
<p>This model doesn’t add any new covariates, but it does change the set of distributions we are considering.</p>
</div>
</div>
</div>
<p>Let’s use 5-fold cross validation to estimate the risk of each of these models:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cv) <span class="co"># </span><span class="al">NOTE</span><span class="co">: you can't use this package on Homework 1</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>            <span class="co"># but for sure use it on your own projects!</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> df)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> df)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> df)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>model4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3 <span class="sc">+</span> x4, <span class="at">data =</span> df)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>risks <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> <span class="fu">c</span>(<span class="st">"Model 1"</span>, <span class="st">"Model 2"</span>, <span class="st">"Model 3"</span>, <span class="st">"Model 4"</span>),</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">risk =</span> <span class="fu">c</span>(</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cvInfo</span>(<span class="fu">cv</span>(model1, <span class="at">k =</span> <span class="dv">5</span>, <span class="at">criterion =</span> mse)),</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cvInfo</span>(<span class="fu">cv</span>(model2, <span class="at">k =</span> <span class="dv">5</span>, <span class="at">criterion =</span> mse)),</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cvInfo</span>(<span class="fu">cv</span>(model3, <span class="at">k =</span> <span class="dv">5</span>, <span class="at">criterion =</span> mse)),</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cvInfo</span>(<span class="fu">cv</span>(model4, <span class="at">k =</span> <span class="dv">5</span>, <span class="at">criterion =</span> mse))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>risks <span class="sc">%&gt;%</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> model, <span class="at">y =</span> risk)) <span class="sc">+</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Estimated Risk by Model"</span>, <span class="at">y =</span> <span class="st">"Estimated Risk (MSE)"</span>, <span class="at">x =</span> <span class="st">"Model"</span>) <span class="sc">+</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture_04_model_selection_files/figure-html/variable-selection-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Based on our model selection procedure (using 5-fold CV to estimate risk), we would choose <strong>Model 2</strong>, which—in this case—is indeed the correct model!</p>
</section>
<section id="connection-to-the-algorithmic-perspective" class="level3">
<h3 class="anchored" data-anchor-id="connection-to-the-algorithmic-perspective">Connection to the Algorithmic Perspective</h3>
<ul>
<li><strong>Step 1</strong> train/test/val split: the train/val split is implicit in K-fold CV, and the test set is used only at the very end to estimate test error of the final model. (<strong>Do not touch the test set until the very end!</strong>)</li>
<li><strong>Step 4</strong> validation: here is where we actually estimate risk using K-fold CV.</li>
<li><strong>Step 5</strong> iteration: we iterate over different statistical models, estimating their risk using K-fold CV, and performing model selection along the way (i.e.&nbsp;refining our statistical model in ways to reduce risk).</li>
</ul>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<ul>
<li>Model selection is the process of choosing the “best statistical model” given our training data.</li>
<li>We can define “best” in terms of expected test error, or risk. In practice, risk is often the most appropriate metric.</li>
<li>We can estimate risk using cross-validation. (We will see other estimators later in the course.)</li>
<li><strong>Never use training error to select models!</strong></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/UBC-STAT\.github\.io\/stat-406\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>This work by <a href="https://geoffpleiss.com">Geoff Pleiss</a>, <a href="https://trevorcampbell.me">Trevor Campbell</a>, and <a href="https://dajmcdon.github.io">Daniel J. McDonald</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0">CC BY-NC 4.0</a><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ubc-stat/stat-406/blob/main/schedule/lectures/lecture_04_model_selection.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/ubc-stat/stat-406/issues/new/" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/ubc-stat/stat-406/edit/main/schedule/lectures/lecture_04_model_selection.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>