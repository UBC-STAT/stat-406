<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>03 The regression function</title>
    <meta charset="utf-8" />
    <meta name="author" content="STAT 406" />
    <meta name="author" content="Daniel J. McDonald" />
    <script src="materials/libs/header-attrs/header-attrs.js"></script>
    <script src="https://kit.fontawesome.com/ae71192e04.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="materials/xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="materials/slides-style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# 03 The regression function
### STAT 406
### Daniel J. McDonald
### Last modified - 2021-09-15

---







class: middle, center
background-image: url("https://upload.wikimedia.org/wikipedia/commons/6/6d/Activemarker2.PNG")
background-size: cover

.secondary[.larger[Module]] .huge-orange-number[1]

.secondary[.large[selecting models]]

---

## Mean squared error (MSE)

Let's look at the population version, and let's forget about the linear model.


Suppose we think that there is __some__ function which relates `\(y\)` and `\(x\)`.

Let's call this function `\(f\)` for the moment.

How do we estimate `\(f\)`?

What is `\(f\)`?

$$
\newcommand{\E}{E}
\newcommand{\Expect}[1]{\E\left[ #1 \right]}
\newcommand{\Var}[1]{\mathrm{Var}\left[ #1 \right]}
\newcommand{\Cov}[2]{\mathrm{Cov}\left[#1,\ #2\right]}
\newcommand{\given}{\ \vert\ }
\newcommand{\X}{\mathbf{X}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
$$



---

## Minimizing MSE

Let's try to minimize the __expected__ sum of squared errors (MSE)

`\begin{aligned}
\Expect{(Y-f(X))^2}
&amp;= \Expect{\Expect{(Y-f(X))^2 \ \vert\  X }}\\
&amp;= \Expect{\Var{Y\ \vert\  X} + 
  \Expect{(Y-f(X)) \ \vert\  X}^2}\\
&amp;= \Expect{\Var{Y\ \vert\  X}} + 
  \Expect{\Expect{(Y-f(X)) \ \vert\  X}^2}\\
\end{aligned}`


The first part doesn't depend on `\(f\)`, it's constant, and we toss it.

--

To minimize the rest, take derivatives and set to 0.

`\begin{aligned}
0 &amp;=\frac{\partial}{\partial f} \Expect{\Expect{(Y-f(X))^2 \ \vert\  X}}\\
  &amp;=-\Expect{\Expect{ 2(Y - f(X)) \ \vert\  X}}\\
&amp;\Rightarrow 2\Expect{f(X) \ \vert\  X} = 2\Expect{Y \ \vert\  X}\\
&amp;\Rightarrow f(X) = \Expect{Y \ \vert\  X}
\end{aligned}`


---

## The regression function

We call this solution:


`$$\mu(X) = \Expect{Y \ \vert\  X}$$`


the regression function.

If we __assume__ that `\(\mu(x) = \Expect{Y \ \vert\  X=x} = x^\top \beta\)`, then we get back exactly OLS.

--

But why should we assume `\(\mu(x) = x^\top \beta\)`?

---

## The regression function


In mathematics: `\(\mu(x) = \Expect{Y \ \vert\  X=x}\)`.

In words: 

__Regression is really about estimating the mean.__

1. If `\(Y\sim \textrm{N}(\mu, 1)\)`, our best guess for a __new__ `\(Y\)` is `\(\mu\)`.  

2. For regression, we let the mean `\((\mu)\)` __depend__ on `\(X\)`.  
3. Think of `\(Y\sim \textrm{N}(\mu(X), 1)\)`, then conditional on `\(X=x\)`, our best guess for a __new__ `\(Y\)` is `\(\mu(x)\)` 

[whatever this function `\(\mu\)` is]

---

## Anything strange?

For any two variables `\(Y\)` and `\(X\)`, we can __always__ write

`$$Y \ \vert\  X = \mu(X) + \eta(X)$$`

such that `\(\Expect{\eta(X)}=0\)`.

--

* Suppose, `\(\mu(X)=\mu_0\)` (constant in `\(X\)`), are `\(Y\)` and `\(X\)` independent?

--

* Suppose `\(Y\)` and `\(X\)` are independent, is `\(\mu(X)=\mu_0\)`?

--

* For more practice on this see the "Fun Worksheet on Theory" in Module 1 on Canvas.
* I do not expect you to do this math, but understanding and explaining it is important.

---
class: inverse, center, middle

# Making predictions

---

## What do we mean by good predictions?


We make observations and then attempt to "predict" new, unobserved data.

Sometimes this is the same as estimating the mean. 
  
Mostly, we observe `\((y_1,x_1),\ldots,(y_n,x_n)\)`, and we want some way to predict `\(Y\)` from `\(X\)`.

---

## Evaluating predictions


Of course, both `\(Y\)` and `\(\widehat{Y}\)` are __random__

I want to know how well I can predict __on average__

Let `\(\widehat{f}\)` be some way of making predictions `\(\widehat{Y}\)` of `\(Y\)` using covariates `\(X\)`

In fact, suppose I observe a dataset `\(\{(y_1,x_1,),\ldots,(y_n,x_n)\}\)`.  

Then I want to __choose__ some `\(\widehat{f}\)` using the data

Is `\(\widehat{f}\)` good on average?
  
  
---

## Evaluating predictions

  
Choose some __loss function__ that measures prediction quality.

We predict `\(y\)` with `\(\widehat{y}\)`

--

Examples:

* __Squared-error:__   
`\(\ell(y,\widehat{y}) = (y-\widehat{y})^2\)`

* __Absolute-error:__  
`\(\ell(y,\widehat{y}) = |y-\widehat{y}|\)`

* __Zero-One:__         
`\(\ell(y,\widehat{y}) = I(y\neq\widehat{y})=\begin{cases} 0 &amp; y=\widehat{y}\\1 &amp; \mbox{else}\end{cases}\)`

--
  
Can be generalized to `\(y\)` in arbitrary spaces.

---

## Expected test MSE 


For __regression__ applications, we will use squared-error loss:

`\(R_n(\widehat{f}) = \Expect{(Y-\widehat{f}(X))^2}\)`

--

I'm giving this a name, `\(R_n\)` for ease. 

Different than text.

This is __expected test MSE__.


---

## Example: Estimating the mean


Suppose we know that we want to predict a quantity `\(Y\)`, 

where `\(\Expect{Y}= \mu \in \mathbb{R}\)` and `\(\Var{Y} = 1\)`.  


Our data is `\(\{y_1,\ldots,y_n\}\)`

We want to estimate `\(\mu\)` 

---

## Estimating the mean

* Let `\(\widehat{Y}=\overline{Y}_n\)` be the sample mean.  
* We can ask about the __estimation risk__ (since we're estimating `\(\mu\)`):

.pull-left[
  
`\begin{aligned}
    R_n(\overline{Y}_n; \mu) 
    &amp;= \E[(\overline{Y}_n-\mu)^2] \\ 
    &amp;= \E[\overline{Y}_n^2]
    -2\mu\E[\overline{Y}_n] + \mu^2 \\ 
    &amp;= \mu^2 + \frac{1}{n} - 2\mu^2 +
    \mu^2\\ &amp;= \frac{1}{n}
\end{aligned}`
]

--

.pull-right[
**Useful trick**

For any `\(Z\)`,

`\(\Var{Z} = \Expect{X^2} - \Expect{X}^2\)`.

Therefore:

`\(\Expect{X^2} = \Var{X} + \Expect{X}^2\)`.

]
  

---

## Predicting new Y's

  
* Let `\(\widehat{Y}=\overline{Y}_n\)` be the sample mean.

* What is the __prediction risk__ of `\(\overline{Y}\)`?

.pull-left[

`\begin{aligned}
    R_n(\overline{Y}_n) &amp;= \E[(\overline{Y}_n-Y)^2]\\ &amp;= \E[\overline{Y}_n^2]
    -2\E[\overline{Y}_n Y] + \E[Y^2] \\ &amp;= \mu^2 + \frac{1}{n} - 2\mu^2 + \mu^2 +
    1 \\ &amp;= 1 + \frac{1}{n} 
\end{aligned}`
]

--

.pull-right[
**Tricks:**

* Used the variance thing again.

* If `\(X\)` and `\(Z\)` are independent, then `\(\Expect{XZ} = \Expect{X}\Expect{Z}\)`

]

---

## Predicting new Y's

  
* What is the prediction risk of guessing `\(Y=0\)`?

* You can probably guess that this is a stupid idea.

* Let's show why it's stupid.

`\begin{aligned}
        R_n(0) &amp;= \E[(0-Y)^2] = 1 + \mu^2
\end{aligned}`


---

## Predicting new Y's


What is the prediction risk of guessing `\(Y=\mu\)`?


This is a great idea, but we don't know `\(\mu\)`.

Let's see what happens anyway.

`\begin{aligned}
        R_n(\mu) &amp;= \E[(Y-\mu)^2]= 1
\end{aligned}`


---

## Estimating the mean

  
Prediction risk: `\(R(\overline{Y}_n) = 1 + \frac{1}{n}\)`    

Estimation risk: `\(R(\overline{Y}_n;\mu) =  \frac{1}{n}\)`  

There is actually a nice interpretation here:
1. The common `\(1/n\)` term is `\(\Var{\overline{Y}_n}\)`  
2. The extra factor of `\(1\)` in the prediction risk is __irreducible error__ 
  * `\(Y\)` is a random variable, and hence noisy. 
  * We can never eliminate it's intrinsic variance.  
  * In other words, even if we knew `\(\mu\)`, we could never get closer than `\(1\)`, on average.

Intuitively, `\(\overline{Y}_n\)` is the obvious thing to do.
 
But what about unintuitive things...

---
class: inverse, center, middle

# Next time...

Trading bias and variance
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="materials/macros.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
