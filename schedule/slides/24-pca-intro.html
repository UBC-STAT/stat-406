<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>24 Principal components, introduction</title>
    <meta charset="utf-8" />
    <meta name="author" content="STAT 406" />
    <meta name="author" content="Daniel J. McDonald" />
    <script src="materials/libs/header-attrs/header-attrs.js"></script>
    <script src="materials/libs/fabric/fabric.min.js"></script>
    <link href="materials/libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="materials/libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#e98a15"],"pen_size":3,"eraser_size":30,"palette":["#2c365e","#e98a15","#0a8754","#a8201a","#E41A1C","#377EB8","#4DAF4A","#984EA3","#FF7F00","#FFFF33"]}) })</script>
    <link href="materials/libs/panelset/panelset.css" rel="stylesheet" />
    <script src="materials/libs/panelset/panelset.js"></script>
    <script src="materials/libs/clipboard/clipboard.min.js"></script>
    <link href="materials/libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="materials/libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"Press Ctrl+C to Copy"})</script>
    <link href="materials/libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="materials/libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <script src="https://kit.fontawesome.com/ae71192e04.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="materials/xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="materials/slides-style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# 24 Principal components, introduction
]
.author[
### STAT 406
]
.author[
### Daniel J. McDonald
]
.date[
### Last modified - 2022-11-28
]

---


class: middle, center
background-image: url(rmd_gfx/23-nnets-other/embeddings-1.svg)
background-size: cover

`$$\newcommand{\Expect}[1]{\mathbb{E}\left[ #1 \right]}
\newcommand{\Var}[1]{\mathrm{Var}\left[ #1 \right]}
\newcommand{\Cov}[2]{\mathrm{Cov}\left[#1,\ #2\right]}
\newcommand{\given}{\ \vert\ }
\newcommand{\argmin}{\arg\min}
\newcommand{\argmax}{\arg\max}
\newcommand{\R}{\mathbb{R}}
\newcommand{\P}{P}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\renewcommand{\hat}{\widehat}
\newcommand{\tr}[1]{\mbox{tr}(#1)}
\newcommand{\X}{\mathbf{X}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\U}{\mathbf{U}}
\newcommand{\D}{\mathbf{D}}
\newcommand{\V}{\mathbf{V}}$$`





.primary[.larger[Module]] .huge-orange-number[5]

.primary[.larger[pca, clustering]]

---


<style>.panelset{--panel-tab-active-foreground: #2c365e;--panel-tab-hover-foreground: #e98a15;}</style>


## Unsupervised learning

In Machine Learning, rather than calling `\(\y\)` the .hand[response], people call it the .hand[supervisor]

So .hand[unsupervised] learning means .hand[learning without] `\(\y\)`

The only data you get are the .hand[features] `\(\{x_1,\ldots,x_n\}\)`.

This type of analysis is more often .hand[exploratory]

We're not necessarily using this for prediction (but we could)

So now, we get `\(\X\)`

The two main activities are __representation learning__ and __clustering__

---


## Representation learning

Representation learning is the idea that performance of ML methods is
highly dependent on the choice of representation


For this reason, much of ML is geared towards transforming the data into
the relevant features and then using these as inputs


This idea is as old as statistics itself, really,

However, the idea is constantly revisited in a variety of fields and
contexts


Commonly, these learned representations capture low-level information
like overall shapes



It is possible to quantify this intuition for PCA at least

--

.hand[Goal:] Transform `\(\mathbf{X}\in \R^{n\times p}\)` into `\(\mathbf{Z} \in \R^{n \times ?}\)`

?-dimension can be bigger (feature creation) or smaller (dimension reduction) than `\(p\)`


---

## You've done this already!

* You added transformations as predictors in regression

* You "expanded" `\(\mathbf{X}\)` using a basis `\(\Phi\)` (polynomials, splines, etc.)

* You used Neural Nets to do a "feature map"

--

This is the same, just no `\(Y\)` around

---

## PCA

Principal components analysis (PCA) is an (unsupervised) dimension
reduction technique


It solves various equivalent optimization problems

(Maximize variance, minimize `\(\ell_2\)` distortions, find closest subspace of a given rank, `\(\ldots\)`)

At its core, we are finding linear combinations of the original
(centered) covariates `$$z_{ij} = \alpha_j^{\top} x_i$$`


This is expressed via the SVD. 

`$$\X  = \U\D\V^{\top}$$`

--

.secondary[Warning:] We assume throughout that `\(\X - \mathbf{11^\top}\overline{x} = 0\)` (we center the columns)

--

Then our new features are

`$$\mathbf{Z} = \X \V = \U\D$$`

---

## Short SVD aside (reminder from Ridge Regression)

* Any `\(n\times p\)` matrix can be decomposed into `\(\mathbf{UDV}^\top\)`.

* These have properties:

1. `\(\mathbf{U}^\top \mathbf{U} = \mathbf{I}_n\)`
2. `\(\mathbf{V}^\top \mathbf{V} = \mathbf{I}_p\)`
3. `\(\mathbf{D}\)` is diagonal (0 off the diagonal)

--

Almost all the methods for we'll talk about for representation learning use the SVD of some matrix.


---
class: inverse

## Why?

1. Given `\(\X\)`, find a projection `\(\mathbf{P}\)` onto `\(\R^M\)` with `\(M \leq p\)` 
that minimizes the reconstruction error
$$
`\begin{aligned}
\min_{\mathbf{P}} &amp;\,\, \lVert \mathbf{X} - \mathbf{X}\mathbf{P} \rVert^2_F \,\,\, \textrm{(sum all the elements)}\\
\textrm{subject to} &amp;\,\, \textrm{rank}(\mathbf{P}) = M,\, \mathbf{P} = \mathbf{P}^T,\, \mathbf{P} = \mathbf{P}^2
\end{aligned}`
$$
The conditions ensure that `\(\mathbf{P}\)` is a projection matrix onto `\(M\)` dimensions.

2. Maximize the variance explained by an orthogonal transformation `\(\mathbf{A} \in \R^{p\times M}\)`
$$
`\begin{aligned}
\max_{\mathbf{A}} &amp;\,\, \textrm{trace}\left(\frac{1}{n}\mathbf{A}^\top \X^\top \X \mathbf{A}\right)\\
\textrm{subject to} &amp;\,\, \mathbf{A}^\top\mathbf{A} = \mathbf{I}_M
\end{aligned}`
$$

* In case one, the minimizer is `\(\mathbf{P} = \mathbf{V}_M\mathbf{V}_M^\top\)`
* In case two, the maximizer is `\(\mathbf{A} = \mathbf{V}_M\)`.


---

## Lower dimensional embeddings

Suppose we have predictors `\(\x_1\)` and `\(\x_2\)`

-   We more faithfully preserve the structure of this data by keeping
    `\(\x_1\)` and setting `\(\x_2\)` to zero than the opposite

&lt;img src="rmd_gfx/24-pca-intro/unnamed-chunk-1-1.svg" style="display: block; margin: auto;" /&gt;

---

## Lower dimensional embeddings

An important feature of the previous example is that `\(\x_1\)` and `\(\x_2\)` aren't
correlated

What if they are?

&lt;img src="rmd_gfx/24-pca-intro/unnamed-chunk-2-1.svg" style="display: block; margin: auto;" /&gt;

We lose a lot of structure by setting either `\(\x_1\)` or `\(\x_2\)` to zero


---

## Lower dimensional embeddings


The only difference is the first is a rotation of the second

&lt;img src="rmd_gfx/24-pca-intro/unnamed-chunk-3-1.svg" style="display: block; margin: auto;" /&gt;

---

## PCA

.pull-left[
If we knew how to rotate our data, then we could more easily retain the structure.

__PCA__ gives us exactly this rotation

]

.pull-right[

.emphasis[
1. Center (+scale?) the data matrix `\(\X\)`
2. Compute the SVD of `\(\X = \U\D \V^\top\)` or `\(\X\X^\top = \U\D^2\U^\top\)` or `\(\X^\top \X = \V\D^2 \V^\top\)`
3. Return `\(\U_M\D_M\)`, where `\(\D_M\)` is the largest `\(M\)`
    eigenvalues of `\(\X\)`
]]


```r
leaf &lt;- readRDS("data/leaf.rds")
X &lt;- leaf %&gt;% dplyr::select(Eccentricity:Entropy)
pca &lt;- prcomp(X, scale = TRUE) ## DON'T USE princomp()
```



&lt;img src="rmd_gfx/24-pca-intro/pca-leaf-plot-1.svg" style="display: block; margin: auto;" /&gt;

---
class: middle, inverse, center

# Next time...

When does PCA work?

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="materials/macros.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
