---
lecture: "28 Hierarchical clustering"
format: revealjs
metadata-files: 
  - _metadata.yml
---

{{< include _titleslide.qmd >}}

## From $K$-means to hierarchical clustering


::: flex
::: w-50

[K-means]{.secondary}


1.  It fits exactly $K$ clusters.

2.  Final clustering assignments depend on the chosen initial cluster
    centers.

[Hierarchical clustering]{.secondary}

1.  No need to choose the number of clusters before hand.

2.  There is no random component (nor choice of starting point).


There is a catch: we need to choose a way to measure the distance
between clusters, called the [linkage]{.secondary}.
:::

::: w-50

Same data as the K-means example:

```{r, fig.height=5,fig.width=5,fig.align='center', echo=FALSE}
library(mvtnorm)
set.seed(406406406)
X1 <- rmvnorm(50, c(-1, 2), sigma = matrix(c(1, .5, .5, 1), 2))
X2 <- rmvnorm(40, c(2, -1), sigma = matrix(c(1.5, .5, .5, 1.5), 2))
X3 <- rmvnorm(40, c(4, 4))
```

```{r}
#| code-fold: true
#| fig-width: 8
#| fig-height: 6
#| fig-align: center
# same data as K-means "Dumb example"
heatmaply::ggheatmap(
  as.matrix(dist(rbind(X1, X2, X3))),
  showticklabels = c(FALSE, FALSE), hide_colorbar = TRUE
)
```
:::
:::

## Hierarchical clustering

::: flex
::: w-50
```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 7
#| fig-align: center
heatmaply::ggheatmap(
  as.matrix(dist(rbind(X1, X2, X3))),
  showticklabels = c(FALSE, FALSE), hide_colorbar = TRUE
)
```
:::
::: w-50
* Given the linkage, hierarchical clustering produces a sequence of
clustering assignments.
* At one end, all points are in their [own]{.secondary}
cluster.
* At the other, all points are in [one]{.secondary}
cluster.
* In the middle, there are [nontrivial]{.secondary}
solutions.
:::
:::

## Agglomeration


::: flex
::: w-50
```{r, fig.height=3,fig.width=3,echo=FALSE}
set.seed(1)
x1 <- runif(7)
x1[1:3] <- x1[1:3] + 1
x2 <- runif(7, 0, 2)
tiny <- tibble(x1 = x1, x2 = x2) |> arrange(x2)
tiny$true <- factor(c(2, 2, 2, 1, 1, 1, 1))
g <- ggplot(tiny, aes(x = x1, y = x2)) +
  geom_point(aes(color = true), size = 3) +
  theme(legend.position = "none") +
  scale_color_manual(values = c(orange, blue))
g + geom_text(label = 1:7, nudge_x = .1, nudge_y = .1)
```

* Given these data points, an agglomerative algorithm chooses a cluster sequence by combining the points into groups.
* We can also represent the sequence of clustering assignments as a
dendrogram
* Cutting the dendrogram horizontally partitions the data points
into clusters

:::
::: w-50
* Notation: Define $x_1,\ldots, x_n$ to be the data

* Let the dissimiliarities be $d_{ij}$ between
each pair $x_i, x_j$

* At any level, clustering assignments can be expressed by sets
$G = \{ i_1, i_2, \ldots, i_r\}$ giving the
indicies of points in this group. Define
$|G|$ to be the size of $G$.


Linkage
: The function $d(G,H)$ that takes
two groups $G,\ H$ and returns the linkage
distance between them.

:::
:::

## Agglomerative clustering, given the linkage


1. Start with each point in its own group
2. Until there is only one cluster, repeatedly merge the two groups
$G,H$ that minimize $d(G,H)$.


::: callout-important
$d$ measures the distance between GROUPS.
:::


## Single linkage

In [single linkage]{.secondary} (a.k.a nearest-neighbor
linkage), the linkage distance between $G,\ H$ is the smallest
dissimilarity between two points in different groups:
$$d_{\textrm{single}}(G,H) = \min_{i \in G, \, j \in H} d_{ij}$$


```{r, fig.height=4, echo = FALSE, fig.align='center'}
seg <- function(a, b) {
  o <- bind_cols(tiny[a, 1:2], tiny[b, 1:2])
  names(o) <- c("x", "y", "xend", "yend")
  o
}
g + geom_segment(aes(x = x, y = y, xend = xend, yend = yend), data = seg(3, 4)) +
  geom_text(label = 1:7, nudge_x = .02, nudge_y = .1)
```


## Complete linkage

In [complete linkage]{.secondary} (i.e. farthest-neighbor
linkage), linkage distance between $G,H$ is the
largest dissimilarity between two points in
different clusters:
$$d_{\textrm{complete}}(G,H) = \max_{i \in G,\, j \in H} d_{ij}.$$


```{r, fig.height=4, echo = FALSE, fig.align='center'}
g + geom_segment(aes(x = x, y = y, xend = xend, yend = yend), data = seg(2, 5)) +
  geom_text(label = 1:7, nudge_x = .02, nudge_y = .1)
```



## Average linkage

In [average linkage]{.secondary}, the linkage distance
between $G,H$ is the average dissimilarity
over all points in different clusters:
$$d_{\textrm{average}}(G,H) = \frac{1}{|G| \cdot |H| }\sum_{i \in G, \,j \in H} d_{ij}.$$


```{r, fig.height=4, echo=FALSE, fig.align='center'}
g + geom_segment(aes(x = x, y = y, xend = xend, yend = yend),
  data = seg(rep(1:3, times = 4), rep(4:7, each = 3))
) +
  geom_text(label = 1:7, nudge_x = .02, nudge_y = .1)
```



## Common properties

[Single]{.secondary}, [complete]{.secondary}, and [average]{.secondary} linkage share the following:

-   They all operate on the dissimilarities $d_{ij}$. 
    
    This means that
    the points we are clustering can be quite general (number of
    mutations on a genome, polygons, faces, whatever).

-   Running agglomerative clustering with any of these linkages produces
    a dendrogram with no inversions


- "No inversions" means that the linkage distance between merged clusters
only [increases]{.secondary} as we run the algorithm.


In other words, we can draw a proper dendrogram, where the height of a
parent is always higher than the height of either daughter.

(We'll return to this again shortly)



## Centroid linkage

[Centroid linkage]{.secondary} is 
relatively new. We need
$x_i \in \mathbb{R}^p$.



$\overline{x}_G$ and $\overline{x}_H$ are group averages

$d_{\textrm{centroid}} = ||\overline{x}_G - \overline{x}_H||_2^2$


```{r, fig.height=4, echo=FALSE, fig.align='center'}
tf <- tiny |>
  group_by(true) |>
  summarize(mx = mean(x1), my = mean(x2))
tff <- bind_cols(tf[1, 2:3], tf[2, 2:3])
names(tff) <- c("x", "y", "xend", "yend")
g + geom_segment(aes(x = x, y = y, xend = xend, yend = yend), data = tff) +
  geom_point(data = tf, aes(x = mx, y = my, color = true), shape = 1, size = 5) +
  geom_text(label = 1:7, nudge_x = .02, nudge_y = .1)
```


## Centroid linkage

::: flex
::: w-50

Centroid linkage is

-   ... quite intuitive

-   ... nicely analogous to $K$-means.

-   ... very related to average linkage (and much, much faster)

However, it may introduce inversions.

```{r, fig.height=4, echo=FALSE}
tt <- seq(0, 2 * pi, len = 50)
tt2 <- seq(0, 2 * pi, len = 75)
c1 <- data.frame(x = cos(tt), y = sin(tt), grp = 1)
c2 <- data.frame(x = 1.5 * cos(tt2), y = 1.5 * sin(tt2), grp = 2)
circles <- bind_rows(c1, c2)
di <- dist(circles[, 1:2])
hc <- hclust(di, method = "centroid")
g1 <- ggplot(circles, aes(x = x, y = y, color = as.factor(grp))) +
  geom_point() +
  scale_color_manual(values = c(orange, blue)) +
  ylab("x2") +
  xlab("x1") +
  theme(legend.position = "none")
```


```{r, fig.width=3,fig.height=3,echo=FALSE,fig.align='center'}
g1
```
:::

::: w-50


```{r}
#| code-fold: true
#| fig-height: 8
#| fig-width: 6
tt <- seq(0, 2 * pi, len = 50)
tt2 <- seq(0, 2 * pi, len = 75)
c1 <- tibble(x = cos(tt), y = sin(tt))
c2 <- tibble(x = 1.5 * cos(tt2), y = 1.5 * sin(tt2))
circles <- bind_rows(c1, c2)
di <- dist(circles[, 1:2])
hc <- hclust(di, method = "centroid")
par(mar = c(.1, 5, 3, .1))
plot(hc, xlab = "")
```

:::
:::


## Shortcomings of some linkages

Single
: 👎 chaining --- a single pair of close points merges two clusters.  $\Rightarrow$ clusters can be too spread out, not compact

Complete linkage
: 👎 crowding --- a point can be closer to points in other clusters than to points in its own cluster.$\Rightarrow$ clusters are compact, not far enough apart.

Average linkage
: tries to strike a balance these  
: 👎 Unclear what properties the resulting clusters have when we cut an average linkage tree.  
: 👎 Results change with a monotone increasing transformation of the dissimilarities   

Centroid linkage
: 👎 same monotonicity problem  
: 👎 and inversions
    
All linkages
: ⁇ where do we cut?


## Distances

Note how all the methods depend on the distance function

Can do lots of things besides Euclidean

This is very important

```{r fig.height=4, fig.width=4, echo=FALSE}
g1
```



# Next time...



No more slides.  All done. 

`r fontawesome::fa('face-grin-stars', height = "6em", fill = blue)`

. . .

FINAL EXAM!! 

`r fontawesome::fa('skull-crossbones', height = "6em", red)`
