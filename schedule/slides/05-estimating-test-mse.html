<!DOCTYPE html>
<html lang="en-CA"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.39">

  <meta name="author" content="Geoff Pleiss, Trevor Campbell">
  <title>UBC Stat406 2024W – estimating-test-mse</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-c2ad62cf6c6f8f5a98be1da8d9e2c7a3.css">
  <link rel="stylesheet" href="tachyons-minimal.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="section" class="slide level2 large" data-background-image="gfx/smooths.svg" data-background-opacity="0.3">
<h2>05 Estimating Risk and Test Error</h2>
<p><span class="secondary">Stat 406</span></p>
<p><span class="secondary">Geoff Pleiss, Trevor Campbell</span></p>
<p>Last modified – 23 September 2024</p>
<p><span class="math display">\[
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\minimize}{minimize}
\DeclareMathOperator*{\maximize}{maximize}
\DeclareMathOperator*{\find}{find}
\DeclareMathOperator{\st}{subject\,\,to}
\newcommand{\E}{E}
\newcommand{\Expect}[1]{\E\left[ #1 \right]}
\newcommand{\Var}[1]{\mathrm{Var}\left[ #1 \right]}
\newcommand{\Cov}[2]{\mathrm{Cov}\left[#1,\ #2\right]}
\newcommand{\given}{\ \vert\ }
\newcommand{\X}{\mathbf{X}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\P}{\mathcal{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\snorm}[1]{\lVert #1 \rVert}
\newcommand{\tr}[1]{\mbox{tr}(#1)}
\newcommand{\brt}{\widehat{\beta}^R_{s}}
\newcommand{\brl}{\widehat{\beta}^R_{\lambda}}
\newcommand{\bls}{\widehat{\beta}_{ols}}
\newcommand{\blt}{\widehat{\beta}^L_{s}}
\newcommand{\bll}{\widehat{\beta}^L_{\lambda}}
\newcommand{\U}{\mathbf{U}}
\newcommand{\D}{\mathbf{D}}
\newcommand{\V}{\mathbf{V}}
\]</span></p>
</section>
<section id="last-time" class="slide level2">
<h2>Last time</h2>
<ol type="1">
<li>What is a model (formal definition)?</li>
<li>Evaluating models (risk/loss functions)</li>
<li>Decomposing risk (bias, variance, irreducible error)</li>
</ol>
</section>
<section id="what-is-a-model" class="slide level2">
<h2>What is a model?</h2>
<p>A model is a set of distributions that explain data <span class="math inline">\(\{ Z = (X, Y) \}\)</span>, i.e.</p>
<p><span class="math display">\[\mathcal{P} = \{ P: \quad Y \mid X \sim \mathcal N( f(X), \sigma^2) \quad \text{for some ``smooth'' }f \}\]</span></p>
<p><span class="secondary">(Why do we have to specify that <span class="math inline">\(f\)</span> is smooth? Why can’t it be any function?)</span><br>
</p>
<h3 id="goal-of-learning">Goal of learning</h3>
<p>Choose the <span class="math inline">\(P \in \mathcal P\)</span> that makes the “best” predictions on new <span class="math inline">\(X, Y\)</span> pairs.</p>
<p><span class="secondary">(Next slide: how do we formalize “best”?)</span></p>
</section>
<section id="how-do-we-evaluate-models" class="slide level2">
<h2>How do we evaluate models?</h2>
<p><span class="math display">\[\mathcal{P} = \{ P: \quad Y \mid X \sim \mathcal N( f(X), \sigma^2) \quad \text{for some ``smooth'' f} \}\]</span></p>
<ol type="1">
<li><p>Specify how a <span class="math inline">\(P \in \mathcal P\)</span> makes <strong>predictions</strong> <span class="math inline">\(\hat Y\)</span> on new inputs <span class="math inline">\(X\)</span>.<br>
<span class="secondary">(E.g.: <span class="math inline">\(\hat Y = f(X)\)</span> for <span class="math inline">\(P = \mathcal N(f(X), \sigma^2)\)</span>.)</span></p></li>
<li><p>Introduce a <strong>loss</strong> function <span class="math inline">\(\ell(Y, \hat{Y})\)</span> (a datapoint-level function).<br>
<span class="secondary">(E.g.: <span class="math inline">\(\ell(Y, \hat Y) = (Y - \hat Y)^2\)</span>)</span></p></li>
<li><p>Define the <strong>test error</strong> of <span class="math inline">\(P \in \mathcal P\)</span> as the expected loss (a population-level function):<br>
<span class="secondary"><span class="math inline">\(T_n(P) = E[\ell(Y, \hat Y)] = E[(Y - f(X))^2]\)</span></span></p></li>
<li><p>The <strong>best</strong> model is the one that minimizes the test error<br>
<span class="secondary">(<span class="math inline">\(P^* = \argmin_{P \in \mathcal P} T_n(P)\)</span>)</span></p></li>
</ol>
</section>
<section class="slide level2">

<p>Last time: when <span class="math inline">\(\ell(Y, \hat Y) = (Y - \hat Y)^2\)</span>, we showed that the <strong>regression function</strong> is the best model:</p>
<div class="fragment">
<p><span class="math display">\[
\text{Regression function } \triangleq E[Y \mid X] = \argmin_{P \in \mathcal P} T_n(P) = \argmin_{P \in \mathcal P} E[\ell(Y, \hat Y)]
\]</span></p>
<p><span class="secondary">Are we done? Have we solved learning?</span></p>
</div>
<div class="fragment">
<p>No! We don’t know what <span class="math inline">\(E[Y \mid X]\)</span> is! We have to <em>estimate it from data!</em></p>
<p><span class="math display">\[
\hat f(X) \approx E[Y \mid X]
\]</span></p>
<p>(We’ll discuss various methods for producing <span class="math inline">\(\hat f(X)\)</span> estimators throughout this course.)</p>
</div>
</section>
<section id="risk-expected-test-error-and-its-decomposition" class="slide level2">
<h2>Risk (Expected Test Error) and its Decomposition</h2>
<p>Our estimator <span class="math inline">\(\hat f\)</span> is a random variable (it depends on training sample).<br>
So let’s consider the <em>risk</em> (the <em>expected test error</em>):</p>
<p><span class="math display">\[
R_n = E_{\hat f} \left[ T_n(\hat f) \right] = E_{\hat f, X, Y} \left[ \ell(Y, \hat f(X)) \right]
\]</span></p>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>Test error is a metric for a fixed <span class="math inline">\(\hat f\)</span>. It averages over all possible test points, but assumes a fixed training set.</p>
<p>Risk averages over <strong>everything</strong> that is random: (1) the test data point sampled from our population, and (2) the training data that produces <span class="math inline">\(\hat f\)</span></p>
</div>
</div>
</div>
</div>
</section>
<section id="risk-expected-test-error-and-its-decomposition-1" class="slide level2">
<h2>Risk (Expected Test Error) and its Decomposition</h2>
<p>When <span class="math inline">\(\ell(Y, \hat Y) = (Y - \hat Y)^2\)</span>, the prediction risk of <span class="math inline">\(\hat f(X)\)</span> decomposes into two factors:</p>
<p><span class="math display">\[
R_n \quad = \quad \underbrace{E_{\hat f, X, Y} \left[ \: \left( E[Y\mid X] - \hat f(X) \right)^2 \right]}_{(1)} \quad + \quad \underbrace{E_{X, Y} \left[ \: \left( Y - E[Y\mid X] \right)^2 \right]}_{(2)}
\]</span></p>
<div class="fragment">
<ol type="1">
<li><strong>Estimation error</strong> (or “reducible error”)</li>
<li><strong>Irreducible error</strong> (or “noise”)</li>
</ol>
</div>
</section>
<section class="slide level2">

<p>The <strong>estimation error term</strong> further reduces into two components:</p>
<p><span class="math display">\[
\begin{aligned}
\underbrace{E_{\hat f, X, Y} \left[ \: \left( E[Y\mid X] -\hat f(X) \right)^2 \right]}_{\text{Estimation error}} \quad &amp;= \quad \underbrace{ E_{X, Y} \left[ \left( E[Y\mid X] - E \left[\hat f(X) \mid X\right] \right)^2 \right]}_{(A)} \quad \\
&amp;+ \quad \underbrace{E_{\hat f, X} \left[ \: \left( E \left[\hat f(X) \mid X\right] -\hat f(X) \right)^2 \right]}_{(B)}
\end{aligned}
\]</span></p>
<div class="fragment">
<ol type="A">
<li><strong>Bias</strong>^2</li>
<li><strong>Variance</strong></li>
</ol>
</div>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>Analogous decompositions hold for other loss/risk functions.</p>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2">

<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a>cols <span class="ot">=</span> <span class="fu">c</span>(blue, red, green, orange)</span>
<span id="cb1-2"><a></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">bty =</span> <span class="st">"n"</span>, <span class="at">ann =</span> <span class="cn">FALSE</span>, <span class="at">xaxt =</span> <span class="st">"n"</span>, <span class="at">yaxt =</span> <span class="st">"n"</span>, </span>
<span id="cb1-3"><a></a>    <span class="at">family =</span> <span class="st">"serif"</span>, <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb1-4"><a></a><span class="fu">library</span>(mvtnorm)</span>
<span id="cb1-5"><a></a>mv <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="sc">-</span>.<span class="dv">5</span>, <span class="sc">-</span>.<span class="dv">5</span>, <span class="sc">-</span>.<span class="dv">5</span>, <span class="sc">-</span>.<span class="dv">5</span>), <span class="dv">4</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-6"><a></a>va <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(.<span class="dv">02</span>, .<span class="dv">02</span>, .<span class="dv">1</span>, .<span class="dv">1</span>, .<span class="dv">02</span>, .<span class="dv">02</span>, .<span class="dv">1</span>, .<span class="dv">1</span>), <span class="dv">4</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-7"><a></a></span>
<span id="cb1-8"><a></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb1-9"><a></a>  <span class="fu">plot</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">42</span>, </span>
<span id="cb1-10"><a></a>       <span class="at">col =</span> blue, <span class="at">ann =</span> <span class="cn">FALSE</span>, <span class="at">pty =</span> <span class="st">"s"</span>)</span>
<span id="cb1-11"><a></a>  <span class="fu">points</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">30</span>, <span class="at">col =</span> <span class="st">"white"</span>)</span>
<span id="cb1-12"><a></a>  <span class="fu">points</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">18</span>, <span class="at">col =</span> green)</span>
<span id="cb1-13"><a></a>  <span class="fu">points</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">6</span>, <span class="at">col =</span> orange)</span>
<span id="cb1-14"><a></a>  <span class="fu">points</span>(<span class="fu">rmvnorm</span>(<span class="dv">20</span>, <span class="at">mean =</span> mv[i, ], <span class="at">sigma =</span> <span class="fu">diag</span>(va[i, ])), <span class="at">cex =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb1-15"><a></a>  <span class="cf">switch</span>(i,</span>
<span id="cb1-16"><a></a>    <span class="st">"1"</span> <span class="ot">=</span> {</span>
<span id="cb1-17"><a></a>      <span class="fu">mtext</span>(<span class="st">"low variance"</span>, <span class="dv">3</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb1-18"><a></a>      <span class="fu">mtext</span>(<span class="st">"low bias"</span>, <span class="dv">2</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb1-19"><a></a>    },</span>
<span id="cb1-20"><a></a>    <span class="st">"2"</span> <span class="ot">=</span> <span class="fu">mtext</span>(<span class="st">"high variance"</span>, <span class="dv">3</span>, <span class="at">cex =</span> <span class="dv">2</span>),</span>
<span id="cb1-21"><a></a>    <span class="st">"3"</span> <span class="ot">=</span> <span class="fu">mtext</span>(<span class="st">"high bias"</span>, <span class="dv">2</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb1-22"><a></a>  )</span>
<span id="cb1-23"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="05-estimating-test-mse_files/figure-revealjs/unnamed-chunk-1-1.svg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="sources-of-bias-and-variance" class="slide level2">
<h2>Sources of bias and variance</h2>
<h3 id="what-conditions-give-rise-to-a-high-bias-estimator">What conditions give rise to a high bias estimator?</h3>
<div class="fragment">
<ul>
<li>Not enough covariates (small <span class="math inline">\(p\)</span>)</li>
<li>Model is too simple</li>
<li>Model is <em>misspecified</em> (doesn’t accurately represent the data generating process)</li>
<li>Bad training algorithm</li>
</ul>
</div>
<h3 id="what-conditions-give-rise-to-a-high-variance-estimator">What conditions give rise to a high variance estimator?</h3>
<div class="fragment">
<ul>
<li>Not enough training samples (small <span class="math inline">\(n\)</span>)</li>
<li>Model is too complicated</li>
<li>Lots of irreducible noise in training data (if my model has power to fit noise, it will)</li>
</ul>
</div>
</section>
<section>
<section id="how-do-we-estimate-r_n" class="title-slide slide level1 center">
<h1>How do we estimate <span class="math inline">\(R_n\)</span>?</h1>
<p><br>
<span class="math inline">\(R_n\)</span> is a theoretical construct.<br>
We can never know the true <span class="math inline">\(R_n\)</span> for a given <span class="math inline">\(\hat f\)</span>. We also have to estimate it from data.</p>
</section>
<section id="dont-use-training-error" class="slide level2">
<h2>Don’t use training error</h2>
<p>The training error in regression is</p>
<p><span class="math display">\[\widehat{R}_n(\widehat{f}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{f}(x_i))^2\]</span></p>
<p>Here, the <span class="math inline">\(n\)</span> is doubly used (annoying, but simple): <span class="math inline">\(n\)</span> observations to create <span class="math inline">\(\widehat{f}\)</span> and <span class="math inline">\(n\)</span> terms in the sum.</p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>We also call <span class="math inline">\(\hat R_n(\hat f)\)</span> the <strong>empirical risk</strong>.</p>
</div>
</div>
</div>
<div class="fragment">
<p><span class="math inline">\(\hat R_n(\hat f)\)</span> is a bad estimator for <span class="math inline">\(R_n\)</span>.<br>
So we should <span class="secondary"><strong>never</strong></span> use it.</p>
</div>
</section>
<section id="why-is-hat-r_n-a-bad-estimator-of-r_n" class="slide level2">
<h2>Why is <span class="math inline">\(\hat R_n\)</span> a bad estimator of <span class="math inline">\(R_n\)</span>?</h2>
<div class="fragment">
<ol type="1">
<li><p>It doesn’t say anything about predictions on new data.<br>
<span class="secondary">(It’s a measure of how well the model fits a <strong>fixed set</strong> of training data.)</span></p></li>
<li><p>It can be made <strong>arbitrarily small</strong> by making your model more complex.</p></li>
</ol>
</div>
</section>
<section id="it-doesnt-say-anything-about-predictions-on-new-data." class="slide level2">
<h2><span class="small">1. It doesn’t say anything about predictions on new data.</span></h2>
<p>These all have the same <span class="math inline">\(R^2\)</span> and Training Error</p>
<div class="flex">
<div class="w-50">
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a></a>ans <span class="ot">&lt;-</span> anscombe <span class="sc">|&gt;</span></span>
<span id="cb2-2"><a></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="fu">c</span>(<span class="st">".value"</span>, <span class="st">"set"</span>), </span>
<span id="cb2-3"><a></a>               <span class="at">names_pattern =</span> <span class="st">"(.)(.)"</span>)</span>
<span id="cb2-4"><a></a><span class="fu">ggplot</span>(ans, <span class="fu">aes</span>(x, y)) <span class="sc">+</span> </span>
<span id="cb2-5"><a></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> orange, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span> </span>
<span id="cb2-6"><a></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> blue, <span class="at">linewidth =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-7"><a></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>set, <span class="at">labeller =</span> label_both)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="05-estimating-test-mse_files/figure-revealjs/unnamed-chunk-2-1.svg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="w-50">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a></a>ans <span class="sc">%&gt;%</span> </span>
<span id="cb3-2"><a></a>  <span class="fu">group_by</span>(set) <span class="sc">|&gt;</span> </span>
<span id="cb3-3"><a></a>  <span class="fu">summarise</span>(</span>
<span id="cb3-4"><a></a>    <span class="at">R2 =</span> <span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x))<span class="sc">$</span>r.sq, </span>
<span id="cb3-5"><a></a>    <span class="at">train_error =</span> <span class="fu">mean</span>((y <span class="sc">-</span> <span class="fu">predict</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x)))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb3-6"><a></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb3-7"><a></a>  kableExtra<span class="sc">::</span><span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">set</th>
<th style="text-align: right;">R2</th>
<th style="text-align: right;">train_error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1.25</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1.25</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1.25</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1.25</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</section>
<section id="it-can-be-made-arbitrarily-small-by-making-your-model-more-complex." class="slide level2">
<h2>2. It can be made <strong>arbitrarily small</strong> by making your model more complex.</h2>
<p>Adding “junk” predictors increases <span class="math inline">\(R^2\)</span> and decreases Training Error</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb4-2"><a></a>p <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb4-3"><a></a>q <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span></span>
<span id="cb4-4"><a></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> (p <span class="sc">+</span> <span class="fu">max</span>(q))), <span class="at">nrow =</span> n)</span>
<span id="cb4-5"><a></a>y <span class="ot">&lt;-</span> x[, <span class="dv">1</span><span class="sc">:</span>p] <span class="sc">%*%</span> <span class="fu">c</span>(<span class="dv">5</span><span class="sc">:</span><span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb4-6"><a></a></span>
<span id="cb4-7"><a></a>regress_on_junk <span class="ot">&lt;-</span> <span class="cf">function</span>(q) {</span>
<span id="cb4-8"><a></a>  x <span class="ot">&lt;-</span> x[, <span class="dv">1</span><span class="sc">:</span>(p <span class="sc">+</span> q)]</span>
<span id="cb4-9"><a></a>  mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb4-10"><a></a>  <span class="fu">tibble</span>(<span class="at">R2 =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>r.sq,  <span class="at">train_error =</span> <span class="fu">mean</span>((y <span class="sc">-</span> <span class="fu">predict</span>(mod))<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb4-11"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a></a><span class="fu">map</span>(q, regress_on_junk) <span class="sc">|&gt;</span> </span>
<span id="cb5-2"><a></a>  <span class="fu">list_rbind</span>() <span class="sc">|&gt;</span></span>
<span id="cb5-3"><a></a>  <span class="fu">mutate</span>(<span class="at">q =</span> q) <span class="sc">|&gt;</span></span>
<span id="cb5-4"><a></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>q) <span class="sc">|&gt;</span></span>
<span id="cb5-5"><a></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(q, value, <span class="at">colour =</span> name)) <span class="sc">+</span></span>
<span id="cb5-6"><a></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"train_error"</span>) <span class="sc">+</span></span>
<span id="cb5-7"><a></a>  <span class="fu">scale_colour_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(blue, orange), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb5-8"><a></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> name, <span class="at">scales =</span> <span class="st">"free_y"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="05-estimating-test-mse_files/figure-revealjs/unnamed-chunk-5-1.svg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="other-things-you-cant-use" class="slide level2">
<h2>Other things you can’t use</h2>
<p>You should not use <code>anova</code></p>
<p>or the <span class="math inline">\(p\)</span>-values from the <code>lm</code> output for this purpose.</p>
<div class="fragment">
<blockquote>
<p>These things are to determine whether those <em>parameters</em> are different from zero if you were to repeat the experiment many times, if the model were true, etc. etc.</p>
</blockquote>
<p>In other words, they are useful for <em>inference problems</em>.</p>
<p>This is not the same as being useful for <em>prediction problems</em> (i.e.&nbsp;how to get small <span class="math inline">\(R_n\)</span>).</p>
</div>
</section>
<section id="dont-use-training-error-the-formal-argument" class="slide level2">
<h2>Don’t use training error: the formal argument</h2>
<p>Our training error <span class="math inline">\(\hat R_n(\hat f)\)</span> is an <strong>estimator</strong> of <span class="math inline">\(R_n\)</span>.</p>
<p>So we can ask “is <span class="math inline">\(\widehat{R}_n(\hat{f})\)</span> a good estimator for <span class="math inline">\(R_n\)</span>?”</p>
</section>
<section id="the-error-of-our-risk-estimator" class="slide level2">
<h2>The error of our risk estimator</h2>
<p>Let’s measure the <strong>error</strong> of our empirical risk estimator:</p>
<!--
::: flex

::: w-50
![](https://images.squarespace-cdn.com/content/v1/59a53195ff7c50210a2c6b8b/1510207623511-BT2MBPENJOJXZNE0SCSQ/inceptius-meme-generator-we-have-to-go-deeper-014848.jpg){fig-alt="meme"}
:::

::: w-50
![](https://i.imgflip.com/93xy4g.jpg){fig-alt="meme" width="380px"}
:::

:::
-->
<p><span class="math display">\[E[(R_n - \hat R_n(\hat f))^2]\]</span> <span class="secondary">(What is the expectation with respect to?)</span></p>
</section>
<section id="the-error-of-our-risk-estimator-1" class="slide level2">
<h2>The error of our risk estimator</h2>
<p><span class="math display">\[E[(R_n - \hat R_n(\hat f))^2]\]</span></p>
<ul>
<li><span class="math inline">\(R_n\)</span> is deterministic (we average over test data and training data)</li>
<li><span class="math inline">\(\hat R_n(\hat f)\)</span> also only depends on training data</li>
<li>So the expectation is with respect to our training dataset</li>
</ul>
<div class="fragment">
<p>As before, we can decompose the error of our risk estimator into <strong>bias</strong> and <strong>variance</strong></p>
<p><span class="math display">\[
E[(R_n - \hat R_n(\hat f))^2] = \underbrace{( R_n - E[\hat R_n(\hat f)])^2}_{\text{bias}} + \underbrace{E[( \hat R_n(\hat f) - E[\hat R_n(\hat f)])^2]}_{\text{variance}}
\]</span></p>
<h3 id="is-the-bias-of-hat-r_nhat-f-small-or-large-why">Is the bias of <span class="math inline">\(\hat R_n(\hat f)\)</span> small or large? Why?</h3>
</div>
</section>
<section id="is-the-bias-of-hat-r_nhat-f-small-or-large-why-1" class="slide level2">
<h2>Is the bias of <span class="math inline">\(\hat R_n(\hat f)\)</span> small or large? Why?</h2>
<ul>
<li>Assume we have a very complex model capable of (nearly) fitting our training data
<ul>
<li>I.e. <span class="math inline">\(\hat R_n(\hat f) \approx 0\)</span></li>
</ul></li>
<li><span class="math inline">\(\text{Bias} = ( R_n - E[\hat R_n(\hat f)])^2 \approx ( R_n - 0 ) = R_n\)</span></li>
<li>(That’s the worst bias we could get! 😔)</li>
</ul>
</section>
<section id="formalizing-why-hat-r_nhat-f-is-a-bad-estimator-of-r_n" class="slide level2">
<h2>Formalizing why <span class="math inline">\(\hat R_n(\hat f)\)</span> is a bad estimator of <span class="math inline">\(R_n\)</span></h2>
<p>Consider an alternative estimator built from <span class="math inline">\(\{ (X_j, Y_j) \}_{j=1}^m\)</span> that was not part of the training set. <span class="math display">\[\tilde R_m(\hat f) = {\textstyle \frac{1}{m} \sum_{j=1}^m} \ell(Y_j, \hat f(X_j)),
\]</span> The error of this estimator can also be decompsed into <strong>bias</strong> and <strong>variance</strong> <span class="math display">\[
E[(R_n - \tilde R_m(\hat f))^2] = \underbrace{( R_n - E_{\hat f,X_j,Y_j}[\tilde R_m(\hat f)])^2}_{\text{bias}} + \underbrace{E_{\hat f,X_j,Y_j}[( \tilde R_m(\hat f) - E_{\hat f,X_j,Y_j}[\tilde R_m(\hat f)])^2]}_{\text{variance}}
\]</span></p>
<h3 id="is-the-bias-of-tilde-r_mhat-f-small-or-large-why">Is the bias of <span class="math inline">\(\tilde R_m(\hat f)\)</span> small or large? Why?</h3>
</section>
<section id="is-the-bias-of-tilde-r_mhat-f-small-or-large-why-1" class="slide level2">
<h2>Is the bias of <span class="math inline">\(\tilde R_m(\hat f)\)</span> small or large? Why?</h2>
<p><span class="math inline">\(\tilde R_m(\hat f)\)</span> has <em>zero</em> bias!</p>
<p><span class="math display">\[
\begin{aligned}
E_{\hat f,X_j,Y_j} \left[ \tilde R_m(\hat f) \right]
&amp;= E_{\hat f,X_j,Y_j} \left[ \frac{1}{m} \sum_{j=1}^m \ell(Y_j, \hat f(X_j)) \right] \\
&amp;= \frac{1}{m} \sum_{j=1}^m E_{\hat f,X_j,Y_j} \left[ \ell(Y_j, \hat f(X_j)) \right]
= R_n
\end{aligned}
\]</span></p>
</section></section>
<section>
<section id="how-to-properly-estimate-r_n" class="title-slide slide level1 center">
<h1>How to properly estimate <span class="math inline">\(R_n\)</span></h1>

</section>
<section id="holdout-sets" class="slide level2">
<h2>Holdout sets</h2>
<p>One option is to have a separate “holdout” or “validation” dataset.</p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>This option follows the logic on the previous slide.<br>
If we randomly “hold out” <span class="math inline">\(\{ (X_j, Y_j) \}_{j=1}^m\)</span> from the training set, we can use this data to get an (nearly) unbiased estimator of <span class="math inline">\(R_n\)</span>. <span class="math display">\[
R_n \approx \tilde R_m(\hat f) \triangleq {\textstyle{\frac 1 m \sum_{j=1}^m \ell ( Y_j - \hat Y_j(X_j))}}
\]</span></p>
</div>
</div>
</div>
<div class="fragment">
<p>👍 Estimates the test error</p>
<p>👍 Fast computationally</p>
<p>🤮 Estimate is random</p>
<p>🤮 Estimate has high variance (depends on 1 choice of split)</p>
<p>🤮 Estimate has a little bias (because we aren’t estimating <span class="math inline">\(\hat f\)</span> from all of the training data)</p>
</div>
</section>
<section id="aside" class="slide level2" data-background-color="#97D4E9">
<h2>Aside</h2>
<p>In my experience, CS has particular definitions of “training”, “validation”, and “test” data.</p>
<p>I think these are not quite the same as in Statistics.</p>
<ul>
<li><span class="secondary">Test data</span> - Hypothetical data you don’t get to see, ever. Infinite amounts drawn from the population.
<ul>
<li><em>Expected test error</em> or <em>Risk</em> is an expected value over this distribution. It’s <em>not</em> a sum over some data kept aside.</li>
</ul></li>
<li>Sometimes I’ll give you “test data”. You pretend that this is a good representation of the expectation and use it to see how well you did on the training data.</li>
<li><span class="secondary">Training data</span> - This is “holdout” data that you get to touch.</li>
<li><span class="secondary">Validation set</span> - Often, we need to <em>choose models</em>. One way to do this is to split off some of your training data and pretend that it’s like a “Test Set”.</li>
</ul>
<p>When and how you split your training data can be very important.</p>
</section></section>
<section id="announcements-sept-24" class="title-slide slide level1 center">
<h1>Announcements Sept 24</h1>
<ul>
<li>Lab Section 03 on monday next week: it’s a holiday. Your lab will be due Friday instead.</li>
<li>Everyone else’s lab: same time as usual.</li>
</ul>
</section>

<section>
<section id="review-of-risk-estimation" class="title-slide slide level1 center">
<h1>Review of Risk (Estimation)</h1>
<p>We fixed a bunch of subtle issues in the Sept 19 Risk Estimation slides.</p>
<p>And I’ve noticed some related confusion in my office hours, so it’s <em>review time</em>!</p>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>After this lecture, make sure to review the whole Risk Estimation slide deck to see all the fixed terminology/definitions/examples.</p>
</div>
</div>
</div>
</div>
</section>
<section id="risk-vs.-test-error" class="slide level2">
<h2>Risk vs.&nbsp;Test Error</h2>
<ul>
<li><strong>Risk</strong> (<span class="math inline">\(R_n\)</span>): expected error when the training data <em>have not yet been observed</em> <strong>(random!)</strong>
<ul>
<li>depends on true data distribution, predictor</li>
</ul></li>
<li><strong>Test Error</strong> (<span class="math inline">\(T_n\)</span>): expected error when the training data <em>have been observed</em> <strong>(fixed!)</strong>
<ul>
<li>depends on true data distribution, predictor, training data</li>
</ul></li>
<li><span class="math inline">\(R_n = \E[T_n]\)</span></li>
</ul>
<div class="fragment">
<ul>
<li>we mostly care about <strong>risk</strong> when <em>designing</em> a new predictor / estimator
<ul>
<li>we want to know how well it will work on <em>future training and test data</em></li>
</ul></li>
<li>we mostly care about <strong>test error</strong> when we’ve <em>fit</em> a predictor / estimator
<ul>
<li>we want to know how well it will work on <em>future test data</em></li>
</ul></li>
</ul>
</div>
</section>
<section id="an-important-clarification" class="slide level2">
<h2>An important clarification</h2>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>In previous lectures, we’ve used <span class="math inline">\(R_n(\hat f)\)</span> to denote risk.</p>
<p>Confusing: the <span class="math inline">\(\hat \mu\)</span> argument looks like a <em>trained predictor</em>, so <span class="math inline">\(R_n(\hat f)\)</span> looks like a function of <em>training data</em>. <strong>Not true!</strong></p>
<p>We will just avoid this confusion from now on and use <span class="math inline">\(R_n\)</span> for risk.</p>
</div>
</div>
</div>
</section>
<section id="risk-vs.-test-error-warmup-in-1d" class="slide level2">
<h2>Risk vs.&nbsp;Test Error: Warmup in 1D</h2>
<ul>
<li>Model: <span class="math inline">\(\mathcal{P} = \{ P: \quad Y \sim \mathcal N(\mu, 1), \quad \mu\in\R\}\)</span>, loss <span class="math inline">\(\ell(y,\hat y) = (y-\hat y)^2\)</span></li>
<li>Training Data: <span class="math inline">\(Y_i\in\R\)</span> from some unknown “true” <span class="math inline">\(P_0 \in \mathcal{P}\)</span> (i.e., “true” <span class="math inline">\(\mu_0\)</span>)</li>
<li>Predictor: <em>function of training data</em> <span class="math inline">\(\hat\mu : \R^n \to \R\)</span>
<ul>
<li>e.g., scaled empirical average <span class="math inline">\(\hat\mu(Y_{1:n}) = \alpha\frac{1}{n}\sum_{n=1}^N Y_n\)</span> for <span class="math inline">\(\alpha &gt; 0\)</span></li>
</ul></li>
</ul>
<div class="fragment">
<ul>
<li><strong>Risk</strong> <span class="math inline">\(R_n\)</span>: expected loss over <em>both</em> training and test data <span class="math inline">\(R_n = E[\ell(Y,\hat\mu(Y_{1:n}))]\)</span>
<ul>
<li>function of true dist <span class="math inline">\(P_0\)</span> and predictor <em>function</em> <span class="math inline">\(\hat\mu(\cdot)\)</span></li>
<li>averages over randomness in training data</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Test Error</strong> <span class="math inline">\(T_n\)</span>: expected loss over <em>only</em> test data <span class="math inline">\(T_n(\hat\mu) = E[\ell(Y,\hat\mu(Y_{1:n})) | Y_{1:n}]\)</span>
<ul>
<li>function of true dist <span class="math inline">\(P_0\)</span>, predictor <em>function</em> <span class="math inline">\(\hat\mu(\cdot)\)</span>, <strong>and training data</strong></li>
<li>training data (and trained predictor) are known/fixed</li>
</ul></li>
</ul>
</div>
</section>
<section id="risk-vs.-test-error-warmup-in-1d-1" class="slide level2">
<h2>Risk vs.&nbsp;Test Error: Warmup in 1D</h2>
<ul>
<li>Model: <span class="math inline">\(\mathcal{P} = \{ P: \quad Y \sim \mathcal N(\mu, 1), \quad \mu\in\R\}\)</span>, loss <span class="math inline">\(\ell(y,\hat y) = (y-\hat y)^2\)</span></li>
<li>Training Data: <span class="math inline">\(Y_i\in\R\)</span> from some unknown “true” <span class="math inline">\(P_0 \in \mathcal{P}\)</span> (i.e., “true” <span class="math inline">\(\mu_0\)</span>)</li>
<li>Predictor: scaled empirical average <span class="math inline">\(\hat\mu(Y_{1:n}) = \alpha \frac{1}{n}\sum_{i=1}^n Y_i\)</span> for a fixed <span class="math inline">\(\alpha &gt; 0\)</span></li>
</ul>
<p><span class="secondary">(What can the risk and test error depend on?)</span></p>
<div class="fragment">
<p><span class="math display">\[ R_n = E[(Y - \hat\mu(Y_{1:n}))^2] = \underbrace{1}_{\text{irr.}} + \underbrace{\mu^2_0(\alpha-1)^2}_{\text{bias}^2}+\underbrace{\alpha^2/n}_{\text{variance}}\]</span></p>
</div>
<div class="fragment">
<p><span class="math display">\[ T_n = E[(Y - \hat\mu(Y_{1:n}))^2 |Y_{1:n}] = 1 + \left(\mu_0 - \alpha \frac{1}{n}\sum_{i=1}^n Y_i\right)^2\]</span></p>
</div>
<div class="fragment">
<ul>
<li><span class="math inline">\(R_n\)</span> is a function of the true distribution (<span class="math inline">\(\mu_0\)</span>) and predictor (<span class="math inline">\(\alpha\)</span>); not training data!</li>
<li><span class="math inline">\(T_n\)</span> is a function of <span class="math inline">\(\mu_0\)</span>, <span class="math inline">\(\alpha\)</span> <em>and</em> training data</li>
</ul>
</div>
</section>
<section id="risk-vs.-test-error-regression" class="slide level2">
<h2>Risk vs.&nbsp;Test Error: Regression</h2>
<ul>
<li>Model: <span class="math inline">\(\mathcal{P} = \{ P: \quad Y \mid X \sim \mathcal N( f(X), 1), \quad f(x)=ax, \, \text{for } a\in\R \}\)</span></li>
<li>Training Data: <span class="math inline">\(X_i,Y_i\in\R\)</span> pairs from some unknown “true” <span class="math inline">\(P_0 \in \mathcal{P}\)</span> (“true” <span class="math inline">\(a_0\)</span>)</li>
<li>Predictor: a <em>function of the training data and a new test input</em> <span class="math inline">\(\hat f : \R^n\times \R^{n} \times \R \to \R\)</span>
<ul>
<li>e.g., the function <span class="math inline">\(\hat f(X_{1:n},Y_{1:n},x) = \beta \frac{Y_2 - Y_1}{X_2 - X_1} x\)</span> for <span class="math inline">\(\beta &gt; 0\)</span></li>
</ul></li>
</ul>
<div class="fragment">
<ul>
<li><strong>Risk</strong> <span class="math inline">\(R_n\)</span>: avg loss over <em>both</em> training and test data <span class="math inline">\(R_n = E[\ell(Y, \hat f(X_{1:n}, Y_{1:n}, X))]\)</span></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Test Error</strong> <span class="math inline">\(T_n\)</span>: avg loss over <em>only</em> test data <span class="math inline">\(T_n = E[\ell(Y, \hat f(Y_{1:n}, X_{1:n},X)) | Y_{1:n},X_{1:n}]\)</span>
<ul>
<li>training data fixed/known</li>
</ul></li>
</ul>
</div>
</section>
<section id="risk-vs.-test-error-regression-1" class="slide level2">
<h2>Risk vs.&nbsp;Test Error: Regression</h2>
<ul>
<li>Model: <span class="math inline">\(\mathcal{P} = \{ P: \quad Y \mid X \sim \mathcal N( f(X), 1), \quad f(x)=ax, \, \text{for } a\in\R \}\)</span> (“true” value <span class="math inline">\(a_0\)</span>)</li>
<li>Predictor: the function <span class="math inline">\(\hat f(X_{1:n}, Y_{1:n}, x) = \beta \frac{Y_2 - Y_1}{X_2 - X_1} x\)</span></li>
</ul>
<p><span class="secondary">(What can the risk and test error depend on?)</span></p>
<div class="fragment">
<p><span class="math display">\[
\begin{aligned}
R_n = E[(Y - \hat f(X))^2]
%= E[(Y - a_0X)^2] + E[(a_0X - \hat f(X))^2]\\
%&amp;= 1 +  E\left[\left(a_0X - \beta\frac{Y_2 - Y_1}{X_2-X_1}X\right)^2\right]\\
&amp;= \text{annoying algebra...}\\
% &amp;= 1 +  E[X^2]E\left[\left(a_0 - \beta\frac{Y_2 - Y_1}{X_2-X_1}\right)^2\right]\\
% &amp;= 1 +  E[X^2]E\left[\left(a_0 - \beta\frac{a_0 X_2 + Z_2 - a_0 X_1 - Z_1}{X_2-X_1}\right)^2\right]\\
&amp;= \underbrace{1}_{\text{irr.}} +  \underbrace{a_0^2(1-\beta)^2E[X^2]}_{\text{bias}^2} + \underbrace{2\beta^2E\left[(X_2-X_1)^{-2}\right]E[X^2]}_{\text{variance}}.
\end{aligned}
\]</span></p>
</div>
<div class="fragment">
<p><span class="math display">\[ T_n = E[(Y - \hat f(X))^2|X_{1:n},Y_{1:n}] = 1 +  E[X^2]\left(a_0 - \beta\frac{Y_2 - Y_1}{X_2-X_1}\right)^2 \]</span></p>
</div>
<div class="fragment">
<ul>
<li>Risk <span class="math inline">\(R_n\)</span> depends only on <span class="math inline">\(a_0, \beta\)</span> and <span class="math inline">\(X\)</span>-marginal distribution</li>
<li>Test error <span class="math inline">\(T_n\)</span> depends on training data too!</li>
</ul>
</div>
</section>
<section id="estimating-risk" class="slide level2">
<h2>Estimating risk</h2>
<p>We can’t compute <span class="math inline">\(R_n\)</span> in practice (we don’t know the true data distribution)</p>
<p>Can we estimate risk (<span class="math inline">\(\hat R_n\)</span>) with data? How do we measure the quality of our estimate?</p>
<div class="fragment">
<p><span class="math display">\[E[(R_n - \hat R_n)^2]\]</span> <span class="secondary">(What is the expectation with respect to?)</span></p>
</div>
<div class="fragment">
<ul>
<li><span class="math inline">\(R_n\)</span> is just a fixed value (we already averaged over test data and training data)</li>
<li><span class="math inline">\(\hat R_n\)</span> depends only on training data</li>
<li>So the expectation is with respect to our training dataset</li>
</ul>
</div>
<div class="fragment">
<p>As before, we can decompose the error of our risk estimator into <strong>bias</strong> and <strong>variance</strong></p>
<p><span class="math display">\[
E[(R_n - \hat R_n)^2] = \underbrace{( R_n - E[\hat R_n])^2}_{\text{bias}} + \underbrace{E[( \hat R_n - E[\hat R_n])^2]}_{\text{variance}}
\]</span></p>
</div>
</section>
<section id="estimating-risk-empirical-risk" class="slide level2">
<h2>Estimating risk: empirical risk</h2>
<p><span class="math display">\[
\text{Recall: }E[(R_n - \hat R_n)^2] = \underbrace{( R_n - E[\hat R_n])^2}_{\text{bias}} + \underbrace{E[( \hat R_n - E[\hat R_n])^2]}_{\text{variance}}
\]</span></p>
<ul>
<li><strong>Empirical risk:</strong> just use the training loss <span class="math inline">\(\hat R_n = \frac{1}{n}\sum_{i=1}^n \ell(Y_i, \hat f(X_i))\)</span></li>
</ul>
<p><span class="secondary">(What is the bias and variance with a <em>really flexible model</em>?)</span></p>
<div class="fragment">
<ul>
<li>If our model is so flexible that it can nearly fit all data always, then <span class="math inline">\(\hat R_n \approx 0\)</span></li>
<li><span class="math inline">\(\text{Variance} = E[( \hat R_n - E[\hat R_n])^2] \approx E[(0 - 0)^2] = 0\)</span></li>
<li><span class="math inline">\(\text{Bias}^2 = ( R_n - E[\hat R_n(\hat f)])^2 \approx ( R_n - 0 ) = R_n\)</span></li>
</ul>
</div>
<div class="fragment">
<p><span class="secondary">(Is that good or bad?)</span></p>
</div>
</section>
<section id="estimating-risk-holdout-sets" class="slide level2">
<h2>Estimating risk: holdout sets</h2>
<p><span class="math display">\[
\text{Recall: }E[(R_n - \hat R_n)^2] = \underbrace{( R_n - E[\hat R_n])^2}_{\text{bias}} + \underbrace{E[( \hat R_n - E[\hat R_n])^2]}_{\text{variance}}
\]</span> <strong>Holdout:</strong> train <span class="math inline">\(\hat f\)</span> with <span class="math inline">\(n-m\)</span> data, estimate with <span class="math inline">\(m\)</span> data: <span class="math inline">\(\hat R_n = \frac{1}{m}\sum_{j=1}^{m} \ell(Y_j, \hat f(X_j))\)</span></p>
<div class="fragment">
<ul>
<li>bias <span class="secondary">(increasing, decreasing, or either with <span class="math inline">\(m\)</span>?)</span> <span class="math display">\[
\text{Bias}^2 = (R_n - R_{n-m})^2
\]</span></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>variance <span class="secondary">(increasing, decreasing, or either with <span class="math inline">\(m\)</span>?)</span></li>
</ul>
<p><span class="math display">\[
\text{Variance}
= \underbrace{\frac{1}{m}E[(\tilde \ell - E[\tilde\ell| \hat f])^2]}_{\text{estimation variance}}
+ \underbrace{E[(E[\tilde \ell| \hat f] - R_{n-m})^2]}_{\text{training variance}} \quad \text{where }\tilde \ell = \ell(Y_1, \hat f(X_1))
\]</span></p>
<!-- 
= \underbrace{E[(\hat R_n - E[\hat R_n | \hat f])^2]}_{\text{estimation variance}}  + \underbrace{E[(E[ \hat R_n | \hat f] - E[\hat R_n])^2]}_{\text{training variance}}
-->
</div>
</section>
<section id="estimating-risk-leave-one-out-cross-val.-loo-cv" class="slide level2">
<h2>Estimating risk: leave-one-out cross-val. (LOO-CV)</h2>
<ul>
<li><strong>LOO-CV estimate:</strong> <span class="math inline">\(\hat R_n = \frac{1}{n} \sum_{i=1}^n \tilde R_i\)</span>, where:
<ul>
<li>Remove the first observation and train (<span class="math inline">\(\hat f_1\)</span>), estimate <span class="math inline">\(\tilde R_1 = \ell(Y_1, \hat f_1(X_1))\)</span></li>
<li>Remove the second observation and train (<span class="math inline">\(\hat f_2\)</span>), estimate <span class="math inline">\(\tilde R_2 = \ell(Y_2, \hat f_2(X_2))\)</span></li>
<li>Wash, rinse, repeat…</li>
</ul></li>
</ul>
<div class="fragment">
<p><span class="secondary">(Bias? Hint: if we train with <span class="math inline">\(n-m\)</span>, we get <span class="math inline">\((R_n - R_{n-m})^2\)</span>…)</span></p>
</div>
<div class="fragment">
<ul>
<li>Bias is <span class="math inline">\((R_n - R_{n-1})^2\)</span> – quite small!</li>
<li>Variance is small too! Roughly: <span class="math inline">\(E[( \hat R_n - E[\hat R_n])^2]\approx \frac{1}{n} E[(\tilde R_1 - R_{n-1})^2]\)</span>
<ul>
<li>assumption: ignoring <span class="math inline">\(\tilde R_j\)</span>, <span class="math inline">\(\tilde R_k\)</span> covariance for <span class="math inline">\(j\neq k\)</span></li>
<li>reasonable if <span class="math inline">\(n\)</span> large enough that one data point doesn’t influence <span class="math inline">\(\hat f\)</span> too much</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>major downside:</strong> have to train <span class="math inline">\(n\)</span> models (<em>super</em> expensive!)</li>
</ul>
</div>
</section></section>
<section>
<section id="picking-up-from-last-time" class="title-slide slide level1 center">
<h1>Picking up from last time…</h1>
<!--
## Cross Validation

One reason that $\widehat{R}_n(\widehat{f})$ is bad is that we are using the same data to pick $\widehat{f}$ __AND__ to estimate $R_n$.

"Validation set" fixes this, but holds out a particular, fixed block of data we pretend mimics the "test data"

Our validation error $\tilde{R}_m(\widehat{f})$ is a random estimator.\
[(The split we use to divide our data into training versus validation is random.)]{.secondary}

. . .

\
A random estimator has _variance_.
We can reduce this variance by averageing over multiple splits.


## Cross Validation Example

What if we set aside one observation, say the first one $(y_1, x_1)$:

- We estimate $\widehat{f}^{(1)}$ without using the first observation.
- We estimate $\widetilde{R}_1(\widehat{f}^{(1)})$ using the held-out first observation.

$$\widetilde{R}_1(\widehat{f}^{(1)}) = (y_1 -\widehat{f}^{(1)}(x_1))^2.$$
[(Why the notation $\widetilde{R}_1$? Because we're estimating the risk with 1 observation. )]{.secondary}

---

But that was only one data point $(y_1, x_1)$. Why stop there?

Do the same with $(y_2, x_2)$!

$$\widetilde{R}_1(\widehat{f}^{(2)}) = (y_2 -\widehat{f}^{(2)}(x_2))^2.$$
We can keep doing this until we try it for every data point.

. . .

$$\mbox{LOO-CV} = \frac{1}{n}\sum_{i=1}^n \widetilde{R}_1(\widehat{f}^{(i)}) = \frac{1}{n}\sum_{i=1}^n 
(y_i - \widehat{f}^{(i)}(x_i))^2$$
This is [__leave-one-out cross validation__]{.secondary}

## Problems with LOO-CV

🤮 Each held out set is small $(n=1)$. Therefore, the variance of the Squared Error of each prediction is high.

🤮 The training sets overlap. This is bad. 

- Usually, averaging reduces variance: $\Var{\overline{X}} = \frac{1}{n^2}\sum_{i=1}^n \Var{X_i} = \frac{1}{n}\Var{X_1}.$
- But only if the variables are independent. If not, then $\Var{\overline{X}} = \frac{1}{n^2}\Var{ \sum_{i=1}^n X_i} = \frac{1}{n}\Var{X_1} + \frac{1}{n^2}\sum_{i\neq j} \Cov{X_i}{X_j}.$
- Since the training sets overlap a lot, that covariance can be pretty big.
    
🤮 We have to estimate this model $n$ times.

🎉 Bias is low because we used almost all the data to fit the model: $E[\mbox{LOO-CV}] = R_{n-1}$ 

-->
</section>
<section id="k-fold-cv" class="slide level2">
<h2>K-fold CV</h2>
<p><span class="math inline">\(K\)</span>-fold cross validation finds a <em>decent</em> tradeoff between these options.</p>
<p>The idea of <span class="math inline">\(K\)</span>-fold CV is</p>
<ol type="1">
<li>Divide the data into <span class="math inline">\(K\)</span> groups.</li>
<li>Leave one group out and train with the remaining <span class="math inline">\(K-1\)</span> groups.</li>
<li>Test on the held-out group. Calculate an average risk over these <span class="math inline">\(\sim n/K\)</span> data.</li>
<li>Repeat for all <span class="math inline">\(K\)</span> groups.</li>
<li>Average the average risks.</li>
</ol>
</section>
<section id="k-fold-cv-illustration" class="slide level2">
<h2>K-fold CV: illustration</h2>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb6-2"><a></a><span class="fu">plot</span>(<span class="cn">NA</span>, <span class="cn">NA</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">bty =</span> <span class="st">"n"</span>, <span class="at">yaxt =</span> <span class="st">"n"</span>, <span class="at">xaxt =</span> <span class="st">"n"</span>)</span>
<span id="cb6-3"><a></a><span class="fu">rect</span>(<span class="dv">0</span>, .<span class="dv">1</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="dv">10</span>, .<span class="dv">9</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="at">col =</span> blue, <span class="at">density =</span> <span class="dv">10</span>)</span>
<span id="cb6-4"><a></a><span class="fu">rect</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">9</span>), <span class="fu">rev</span>(.<span class="dv">1</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)), <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">10</span>), </span>
<span id="cb6-5"><a></a>     <span class="fu">rev</span>(.<span class="dv">9</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)), <span class="at">col =</span> red, <span class="at">density =</span> <span class="dv">10</span>)</span>
<span id="cb6-6"><a></a><span class="fu">points</span>(<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>), <span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span> <span class="sc">/</span> <span class="dv">4</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb6-7"><a></a><span class="fu">text</span>(.<span class="dv">5</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">9</span>), .<span class="dv">5</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="st">"1"</span>, <span class="st">"2"</span>, <span class="st">"3"</span>, <span class="st">"K"</span>), <span class="at">cex =</span> <span class="dv">3</span>, </span>
<span id="cb6-8"><a></a>     <span class="at">col =</span> red)</span>
<span id="cb6-9"><a></a><span class="fu">text</span>(<span class="dv">6</span>, <span class="fl">4.5</span>, <span class="st">"Training data"</span>, <span class="at">cex =</span> <span class="dv">3</span>, <span class="at">col =</span> blue)</span>
<span id="cb6-10"><a></a><span class="fu">text</span>(<span class="dv">2</span>, <span class="fl">1.5</span>, <span class="st">"Validation data"</span>, <span class="at">cex =</span> <span class="dv">3</span>, <span class="at">col =</span> red)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="05-estimating-test-mse_files/figure-revealjs/unnamed-chunk-6-1.svg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="k-fold-cv-vs.-loo-cv" class="slide level2">
<h2>K-fold CV vs.&nbsp;LOO CV</h2>
<ul>
<li>🎉 Less costly than LOO CV (i.e., actually possible; only need to train <span class="math inline">\(K\)</span> times)</li>
<li>💩 K-fold CV has higher sq. bias <span class="math inline">\((R_n - R_{n(1-1/K)})^2\)</span> than LOO CV <span class="math inline">\((R_n - R_{n-1})^2\)</span></li>
<li>a bit painful to compare variance…
<ul>
<li>I hereby invoke the sacred incantation: “this exercise is left to the reader”</li>
</ul></li>
</ul>
<p>The overall risk <span class="math inline">\(R_n\)</span> depends on <span class="math inline">\(n\)</span>.</p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>In practice, most people just default to using 5-fold or 10-fold. This is probably fine in most cases.</p>
</div>
</div>
</div>
</section>
<section id="k-fold-cv-code" class="slide level2">
<h2>K-fold CV: Code</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7" data-code-line-numbers="11-13|14-16|"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a></a><span class="co">#' @param data The full data set</span></span>
<span id="cb7-2"><a></a><span class="co">#' @param estimator Function. Has 1 argument (some data) and fits a model. </span></span>
<span id="cb7-3"><a></a><span class="co">#' @param predictor Function. Has 2 args (the fitted model, the_newdata) and produces predictions</span></span>
<span id="cb7-4"><a></a><span class="co">#' @param error_fun Function. Has one arg: the test data, with fits added.</span></span>
<span id="cb7-5"><a></a><span class="co">#' @param kfolds Integer. The number of folds.</span></span>
<span id="cb7-6"><a></a>kfold_cv <span class="ot">&lt;-</span> <span class="cf">function</span>(data, estimator, predictor, error_fun, <span class="at">kfolds =</span> <span class="dv">5</span>) {</span>
<span id="cb7-7"><a></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(data)</span>
<span id="cb7-8"><a></a>  fold_labels <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>kfolds, <span class="at">length.out =</span> n))</span>
<span id="cb7-9"><a></a>  errors <span class="ot">&lt;-</span> <span class="fu">double</span>(kfolds)</span>
<span id="cb7-10"><a></a>  <span class="cf">for</span> (fold <span class="cf">in</span> <span class="fu">seq_len</span>(kfolds)) {</span>
<span id="cb7-11"><a></a>    test_rows <span class="ot">&lt;-</span> fold_labels <span class="sc">==</span> fold</span>
<span id="cb7-12"><a></a>    train <span class="ot">&lt;-</span> data[<span class="sc">!</span>test_rows, ]</span>
<span id="cb7-13"><a></a>    test <span class="ot">&lt;-</span> data[test_rows, ]</span>
<span id="cb7-14"><a></a>    current_model <span class="ot">&lt;-</span> <span class="fu">estimator</span>(train)</span>
<span id="cb7-15"><a></a>    test<span class="sc">$</span>.preds <span class="ot">&lt;-</span> <span class="fu">predictor</span>(current_model, test)</span>
<span id="cb7-16"><a></a>    errors[fold] <span class="ot">&lt;-</span> <span class="fu">error_fun</span>(test)</span>
<span id="cb7-17"><a></a>  }</span>
<span id="cb7-18"><a></a>  <span class="fu">mean</span>(errors)</span>
<span id="cb7-19"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8" data-code-line-numbers="2-4|"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a></a>somedata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">z =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>), <span class="at">x1 =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>), <span class="at">x2 =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>))</span>
<span id="cb8-2"><a></a>est <span class="ot">&lt;-</span> <span class="cf">function</span>(dataset) <span class="fu">lm</span>(z <span class="sc">~</span> ., <span class="at">data =</span> dataset)</span>
<span id="cb8-3"><a></a>pred <span class="ot">&lt;-</span> <span class="cf">function</span>(mod, dataset) <span class="fu">predict</span>(mod, <span class="at">newdata =</span> dataset)</span>
<span id="cb8-4"><a></a>error_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(testdata) <span class="fu">mutate</span>(testdata, <span class="at">errs =</span> (z <span class="sc">-</span> .preds)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(errs) <span class="sc">|&gt;</span> <span class="fu">mean</span>()</span>
<span id="cb8-5"><a></a><span class="fu">kfold_cv</span>(somedata, est, pred, error_fun, <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8928686</code></pre>
</div>
</div>
<!--
## Trick

__For certain "nice" models__ of the form
$$\widehat{y}_i = h_i(\mathbf{X})^\top \mathbf{y}$$
for some vector $h_i$, one can show 

$$\mbox{LOO-CV} = \frac{1}{n} \sum_{i=1}^n \frac{(y_i -\widehat{y}_i)^2}{(1-[\boldsymbol h_i(x_i)]_{i})^2}.$$
(Proof: tedious algebra. QED)

which I wouldn't wish on my worst enemy, but might - in a fit of rage - assign as homework to belligerent students.) 

. . .

* This trick means that you only have to fit the model once rather than $n$ times!




::: {.cell layout-align="center"}

```{.r .cell-code}
cv_nice <- function(mdl) mean( (residuals(mdl) / (1 - hatvalues(mdl)))^2 )
```
:::




-->
</div>
</section></section>
<section id="next-time" class="title-slide slide level1 center">
<h1>Next time…</h1>
<p>LOO tricks and “hatvalues”</p>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>UBC Stat 406 - 2024</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 720,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/UBC-STAT\.github\.io\/stat-406\/");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
              // target, if specified
              link.setAttribute("target", "_blank");
              if (link.getAttribute("rel") === null) {
                link.setAttribute("rel", "noopener");
              }
              // default icon
              link.classList.add("external");
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>