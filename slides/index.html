<p>This page allows you to look at the slides for the video lectures. Simply
click the appropriate link below.</p>

<p><strong>Note:</strong> If you want to see additional slides/videos, check out those made by the authors on <a href="https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/">YouTube</a>. Unfortunately for you, 
the quizzes and exams cover my material, not theirs.</p>

<p><strong>Another Note:</strong> If you want to see all the <code class="language-plaintext highlighter-rouge">R</code> code for these slides, go <a href="https://github.com/UBC-STAT/stat-406/tree/master/lecture-code">here</a>.</p>

<h2 id="0-introduction-and-review">0 Introduction and Review</h2>

<ul>
  <li><a href="lecture-slides/00-intro-to-class.html">Intro to class</a></li>
  <li><a href="lecture-slides/01-lm-review.html">Linear model review</a></li>
  <li><a href="lecture-slides/02-lm-example.html">Linear model example</a></li>
</ul>

<h2 id="1-model-accuracy">1 Model Accuracy</h2>

<ul>
  <li><a href="lecture-slides/03-regression-function.html">The regression function</a></li>
  <li><a href="lecture-slides/04-bias-variance.html">Bias and variance</a></li>
  <li><a href="lecture-slides/05-estimating-test-mse.html">Estimating test MSE</a></li>
  <li><a href="lecture-slides/06-information-criteria.html">Information criteria</a></li>
  <li><a href="lecture-slides/07-greedy-selection.html">Greedy variable selection</a></li>
</ul>

<h2 id="2-regularization-smoothing-and-trees">2 Regularization, smoothing, and trees</h2>

<ul>
  <li><a href="lecture-slides/08-ridge-regression.html">Ridge regression</a></li>
  <li><a href="lecture-slides/09-l1-penalties.html">l1 penalties</a></li>
  <li><a href="lecture-slides/10-basis-expansions.html">Basis expansions</a></li>
  <li><a href="lecture-slides/11-kernel-smoothers.html">Kernel smoothers</a></li>
  <li><a href="lecture-slides/12-why-smooth.html">To smooth or not to smooth</a></li>
  <li><a href="lecture-slides/13-gams-trees.html">GAMs and Trees</a></li>
</ul>

<h2 id="3-classification">3 Classification</h2>

<ul>
  <li><a href="lecture-slides/14-classification-intro.html">Introduction to classification</a></li>
  <li><a href="lecture-slides/15-LDA-and-QDA.html">LDA and QDA</a></li>
  <li><a href="lecture-slides/00-gradient-descent.html">Aside on gradient descent</a></li>
  <li><a href="lecture-slides/16-logistic-regression.html">Logistic regression</a></li>
  <li><a href="lecture-slides/17-nonlinear-classifiers.html">Nonlinear classifiers</a></li>
</ul>

<h2 id="4-modern-techniques">4 Modern techniques</h2>

<ul>
  <li><a href="lecture-slides/18-the-bootstrap.html">The bootstrap</a></li>
  <li><a href="lecture-slides/19-bagging-and-rf.html">Bagging and random forests</a></li>
  <li><a href="lecture-slides/20-boosting.html">Boosting</a></li>
  <li><a href="lecture-slides/21-nnets-intro.html">Intro to neural nets</a></li>
  <li><a href="lecture-slides/22-nnets-estimation.html">Estimating neural nets</a></li>
  <li><a href="lecture-slides/23-nnets-other.html">Neural nets wrapup</a></li>
</ul>

<p><a href="lecture-slides/module4-poll-qs.pdf"><strong>Zoom Poll Q/As</strong></a></p>

<h2 id="5-unsupervised-learning">5 Unsupervised learning</h2>

<ul>
  <li><a href="lecture-slides/24-pca-intro.html">Intro to PCA</a></li>
  <li><a href="lecture-slides/25-pca-issues.html">Issues with PCA</a></li>
  <li><a href="lecture-slides/00-pca-v-kpca.html">PCA v KPCA</a></li>
  <li><a href="lecture-slides/26-manifolds.html">Manifold learning</a></li>
  <li><a href="lecture-slides/27-kmeans.html">K means clustering</a></li>
  <li><a href="lecture-slides/28-hclust.html">Hierarchical clustering</a></li>
</ul>
