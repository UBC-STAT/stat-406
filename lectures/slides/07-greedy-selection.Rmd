---
title: "07 Greedy selection"
author: 
  - "STAT 406"
  - "Daniel J. McDonald"
date: 'Last modified - `r Sys.Date()`'
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
source("rmd_config.R")
library(cowplot)
```

```{r css-extras, file="css-extras.R", echo=FALSE}
```



## Selecting predictors

.pull-left[

Suppose we have a pile of predictors.

We estimate models with different subsets of predictors and use CV / Cp / AIC 
/ BIC to decide which is preferred.

Sometimes you might have a few plausible subsets. Easy enough to choose with our criterion.

Sometimes you might just have a bunch of predictors, then what do you do?
]

--

.pull-right[
__All subsets__: estimate model based on every possible subset of size $|\mathcal{S}| \leq \min\{n, p\}$, use one with 
lowest risk estimate

__Forward selection__: start with $\mathcal{S}=\varnothing$, add predictors greedily

__Backward selection__: start with $\mathcal{S}=\{1,\ldots,p\}$, remove greedily

__Hybrid__: combine forward and backward smartly
]

---

## Costs and benefits


__All subsets__: 

`r pro` estimates each subset

`r con` takes $2^p$ model fits when $p<n$. If $p=50$, this is about $10^{15}$ models. 

__Forward selection__: 

`r pro` computationally feasible

`r con` ignores some models, correlated predictors means bad performance

__Backward selection__: 

`r pro` computationally feasible

`r con` ignores some models, correlated predictors means bad performance

`r con` doesn't work if $p>n$

__Hybrid__: 

`r pro` visits more models than forward/backward

`r con` slower

---

## Synthetic example

```{r data-setup}
set.seed(123)
n <- 406
df <- tibble( # like data.frame, but columns can be functions of preceding
  x1 = rnorm(n),
  x2 = rnorm(n, mean = 2, sd = 1),
  x3 = rexp(n, rate = 1),
  x4 = x2 + rnorm(n, sd = .1), # correlated with x2
  x5 = x1 + rnorm(n, sd = .1), # correlated with x1
  x6 = x1 - x2 + rnorm(n, sd = .1), # correlated with x2 and x1 (and others)
  x7 = x1 + x3 + rnorm(n, sd = .1), # correlated with x1 and x3 (and others)
  y = x1 * 3 + x2 / 3 + rnorm(n, sd = 2.2) # function of x1 and x2 only
)
```

--

$\mathbf{x}_1$ and $\mathbf{x}_2$ are the true predictors

But the rest are correlated with them

---

## Full model

```{r full-model}
full <- lm(y ~ ., data = df)
```

```{r full-table, echo=FALSE}
summary(full)
```

---

## True model

```{r true-model}
truth <- lm(y ~ x1 + x2, data = df)
```

```{r true-table, echo=FALSE}
summary(truth)
```

---

## All subsets

```{r try-them-all}
library(leaps)
trythemall <- regsubsets(y ~ ., data = df)
summary(trythemall)
```

---

## BIC and Cp

.pull-left[
```{r more-all-subsets1}
infocrit <- tibble(
  BIC = summary(trythemall)$bic, 
  Cp = summary(trythemall)$cp,
  size = 1:7)
```

```{r more-all-subsets2, echo=TRUE, dev="svg"}
info_plot <- infocrit %>% 
  pivot_longer(-size, names_to="crit") %>%
  ggplot(aes(size, value, color=crit)) + 
  geom_point() + 
  geom_line() + 
  facet_wrap(~crit, 2, scales = "free_y") + 
  scale_color_brewer(palette = "Set1") +
  theme(axis.title.y = element_blank(), 
        legend.position = "none")
```

]

.pull-right[
```{r more-all-subsets3, echo=FALSE, dev="svg"}
info_plot
```
]

---

## Forward stepwise

```{r step-forward}
stepup <- regsubsets(y ~ ., data = df, method = "forward")
summary(stepup)
```

---

## BIC and Cp

```{r more-step-forward, echo=FALSE, dev="svg", fig.width=10, fig.height=5, fig.align="center"}
infocrit2 = tibble(
  BIC = summary(stepup)$bic, 
  Cp = summary(stepup)$cp,
  size = 1:7)
infocrit2 %>% 
  pivot_longer(-size, names_to="crit") %>%
  ggplot(aes(size, value, color=crit)) + 
  geom_point() + 
  geom_line() + 
  facet_wrap(~crit, 1, scales = "free_y") +
  scale_color_brewer(palette = "Set1") +
  theme(axis.title.y=element_blank(), legend.position = "none")
```

---

## Backward selection

```{r step-backward}
stepdown <- regsubsets(y ~ ., data = df, method = "backward")
summary(stepdown)
```

---

## BIC and Cp

```{r more-step-backward, echo=FALSE, dev="svg", fig.width=10, fig.height=5, fig.align="center"}
infocrit3 = tibble(
  BIC = summary(stepdown)$bic, 
  Cp = summary(stepdown)$cp,
  size = 1:7)
infocrit3 %>% 
  pivot_longer(-size, names_to="crit") %>%
  ggplot(aes(size, value, color=crit)) + 
  geom_point() + 
  geom_line() + 
  facet_wrap(~crit, 1, scales = "free_y") +
  scale_color_brewer(palette = "Set1") +
  theme(axis.title.y=element_blank(), legend.position = "none")
```

---
class: middle

.emphasis[
<br>
## somehow, for this seed, everything is the same
<br>
]


---

## Randomness and prediction error

All of that was for one data set

If we want to know how they compare, we should repeat many times
  1. Generate training data
  1. Estimate with different algorithms
  1. Predict held-out set data
  1. Examine prediction MSE (on held-out set)
  
--

I'm not going to do all subsets, just the truth, forward selection, backward, and the full model

For forward/backward selection, I'll use Cp to choose the final model

This Cp is using the training set.

---

## Code for simulation

... Annoyingly, no predict method for `regsubsets`, so we make one.
```{r predict-regsubsets}
predict.regsubsets <- function(object, newdata, risk_estimate = c("cp", "bic"), ...) {
  risk_estimate <- match.arg(risk_estimate)
  chosen <- coef(object, which.min(summary(object)[[risk_estimate]]))
  predictors <- names(chosen)
  if (object$intercept) predictors <- predictors[-1]
  X <- newdata[, predictors]
  if (object$intercept) X <- cbind2(1, X)
  drop(as.matrix(X) %*% chosen)
}
```

---

```{r replication-exercise, cache=TRUE}
simulate_and_estimate_them_all <- function(n = 406) {
  N <- 2 * n # generate 2x the amount of data (half train, half test)
  df <- tibble( # generate data
    x1 = rnorm(N), 
    x2 = rnorm(N, mean = 2), 
    x3 = rexp(N),
    x4 = x2 + rnorm(N, sd = .1), 
    x5 = x1 + rnorm(N, sd = .1),
    x6 = x1 - x2 + rnorm(N, sd = .1), 
    x7 = x1 + x3 + rnorm(N, sd = .1),
    y = x1 * 3 + x2 / 3 + rnorm(N, sd = 2.2)
  )
  train <- df[1:n, ] # half the data for training
  test <- df[(n + 1):N, ] # half the data for evaluation
  
  oracle <- lm(y ~ x1 + x2 - 1, data = train) # knowing the right model, not the coefs
  full <- lm(y ~ ., data = train)
  stepup <- regsubsets(y ~ ., data = train, method = "forward")
  stepdown <- regsubsets(y ~ ., data = train, method = "backward")
  
  tibble(
    y = test$y,
    oracle = predict(oracle, newdata = test),
    full = predict(full, newdata = test),
    stepup = predict(stepup, newdata = test),
    stepdown = predict(stepdown, newdata = test),
    truth = drop(as.matrix(test[, c("x1", "x2")]) %*% c(3, 1/3))
  )
}

set.seed(12345)
our_sim <- purrr::map_dfr(1:50, ~ simulate_and_estimate_them_all(406), .id = "sim")
```

---

## What is "Oracle"

.pull-left-wide[
<a title="Helen Simonsson, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Delfi_Apollons_tempel.jpg"><img width="800" alt="Delfi Apollons tempel" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Delfi_Apollons_tempel.jpg/512px-Delfi_Apollons_tempel.jpg"></a>
]

.pull-right-narrow[
![:scale 80%](https://www.worldhistory.org/img/r/p/750x750/186.jpg.webp?v=1628028003)
]


---

## Results

.pull-left[

```{r synth-results, eval=FALSE}
our_sim2 <- our_sim %>%
  group_by(sim) %>%
  summarise(across(oracle:truth, ~ mean((y - .)^2)), 
            .groups = "drop") %>%
  transmute(across(oracle:stepdown, ~ . / truth - 1))
  
our_sim2 %>%
  pivot_longer(everything(), 
               names_to = "method", 
               values_to = "mse") %>%
  ggplot(aes(method, mse, fill = method)) +
  geom_boxplot(notch = TRUE) +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "none") +
  scale_y_continuous(labels = scales::label_percent())+
  ylab("% increase in mse relative\n to the truth")
```
]


.pull-right[

```{r synth-results-plot, echo=FALSE, ref.label="synth-results", fig.width=5, fig.height=5, fig.align="center"}
```

]


---
class: middle, center
background-image: url("https://disher.com/wp-content/uploads/2017/02/Product-Constraints.jpg")
background-size: cover

.primary[.larger[Next time...]]

.primary[.larger[Module]] .huge-blue-number[2]

.primary[regularization, constraints, and nonparametrics]
